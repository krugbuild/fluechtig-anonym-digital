{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Fl\u00fcchtig, Anonym &amp; Digital","text":""},{"location":"index.html#versuch-einer-genuin-digitalen-quellenkritik-am-beispiel-von-akteursanalysen-in-der-wikipedia","title":"Versuch einer genuin digitalen Quellenkritik am Beispiel von Akteursanalysen in der Wikipedia","text":"<p>Alexandra Krug \u00dcberarbeitete Fassung der Masterarbeit vom 29.05.2024</p>"},{"location":"index.html#einleitung","title":"Einleitung","text":"<p>Im vergangenen Jahr berichteten verschiedene Newsportale \u00fcber voraussichtlich politisch motivierte Eingriffe in Wikipediaartikel. So wurde Taiwan nicht mehr als Inselstaat in Ostasien beschrieben, sondern als Provinz in der Volksrepublik China. In der Beschreibung der Proteste in Hong Kong wechselten sich die Bezeichnungen Demonstranten und Randalierer wiederholt ab und die Tiananmenplatz-Proteste wurden zu konterrevolution\u00e4ren Aufst\u00e4nden erkl\u00e4rt. <sup>1</sup></p> <p>Diese politisch wie historisch relevanten Ereignisse h\u00e4tten sich noch vor drei\u00dfig Jahren vermutlich in gedruckten Zeitungsartikeln, B\u00fcchern und anderen stofflichen Quellen niedergeschlagen, die von HistorikerInnen sp\u00e4ter mit gewohntem Handwerkszeug untersucht worden w\u00e4ren. Die Wikipedia als Austragungsort dieser Konfrontation hat jedoch keine k\u00f6rperliche Entsprechung und droht trotz ihrer offenkundig bedeutsamen Rolle sich der Bearbeitung durch die klassische Geschichtswissenschaft zu entziehen. Methodische Analogien zum klassischen Lexikon zu ziehen mag nahe liegen, doch sind die quellenkundlichen Eigenheiten rein elektronisch erzeugter und somit fl\u00fcchtiger Untersuchungsgegenst\u00e4nde schwerlich mit denen klassischer Quellen zu vergleichen. <sup>2</sup> Die kollaborative und anonyme Gestalt der Autorschaft stellt historisch Forschende vor weitere Herausforderungen. Die so erzeugten Texte sind mit den Mitteln der klassischen Autorenkritik schwerlich zu bewerten. Es scheint somit geboten zu sein, die M\u00f6glichkeiten einer genuin digitalen Quellenkritik zu evaluieren. Die vorliegende Arbeit folgt daher der Frage: Wie k\u00f6nnen fl\u00fcchtige, anonyme und digitale Quellen geschichtswissenschaftlich untersucht werden?</p> <p>Um dieses umfangreiche Thema einzugrenzen, wird als Fallbeispiel die bereits erw\u00e4hnte Wikipedia dienen. Hierbei konzentriert sich die Arbeit insbesondere auf die Artikel als digitale Objekte und die zugeh\u00f6rigen Autorengruppen als Gegenstand der Autorenkritik. Die \u00fcbergeordnete Frage wird folglich durch Teilfragen pr\u00e4zisiert:</p> <ol> <li>Wie sollte eine \u00e4u\u00dfere Quellenkritik genuin digitaler Quellen gestaltet sein, um die Validit\u00e4t der untersuchten Daten belastbar bewerten zu k\u00f6nnen?</li> <li>Wie k\u00f6nnen anonyme Autorengruppen in einem kollaborativem System im Rahmen einer Autorenkritik untersucht werden, um Aussagen \u00fcber deren Tendenz treffen zu k\u00f6nnen?</li> </ol> <p>Die vorliegende Arbeit ist, neben Einleitung und Fazit, dreigeteilt. Das erste Kapitel widmet sich zun\u00e4chst der Rolle der Digital History und illustriert den aktuellen Mangel einer digitalhistorischen Quellenkritik. Weiterhin wird der aktuelle Forschungsstand er\u00f6rtert. Als Beispiel f\u00fcr ein bemerkenswertes genuin digitales Forschungsgebiet wird die Wikipedistik vorgestellt. Im zweiten Kapitel werden die Probleme und L\u00f6sungsans\u00e4tze f\u00fcr eine \u00e4u\u00dfere Quellenkritik genuin digitaler Daten sowie die Autorenkritik als Akteursanalyse von anonymen Autorengruppen diskutiert. Das dritte Kapitel \u00fcbertr\u00e4gt diesen Ansatz auf ein konkretes Fallbeispiel und f\u00fchrt die Quellenkritik exemplarisch durch. Dabei wird die Nutzung automatisierter Methoden erl\u00e4utert und die Resultate diskutiert.</p> <ol> <li> <p>Siehe Nikolic, Isabella: China and Taiwan go to war over Wikipedia edits as hundreds of changes to description of the island territory are uncovered, in: Mail Online, 05.10.2019. Online: https://www.dailymail.co.uk/news/article-7540755/China-Taiwan-war-Wikipedia-edits-hundreds-changes-uncovered.html, Stand: 20.11.2019.Siehe Miller, Carl: China and Taiwan clash over Wikipedia edits, in: BBC News, 05.10.2019. Online: https://www.bbc.com/news/technology-49921173, Stand: 20.11.2019.\u00a0\u21a9</p> </li> <li> <p>Die Eigenheiten genuin digitaler Quellen werden im Kapitel 2 - Ans\u00e4tze einer digitalen Quellenkritik diskutiert.\u00a0\u21a9</p> </li> </ol>"},{"location":"Anhang_Literatur.html","title":"Literatur","text":"<p>Ban, Kristina; Perc, Matja\u017e; Levnaji\u0107, Zoran: Robust clustering of languages across Wikipedia growth, in: Royal Society Open Science 4 (10), Royal Society, 18.10.2017, S. 12. Online: https://doi.org/10.1098/rsos.171217.</p> <p>Becker, Kim-Bj\u00f6rn: Internetzensur in China: Aufbau und Grenzen des chinesischen Kontrollsystems, Wiesbaden 2011.</p> <p>Bilic, Pasko; Bulian, Luka: Lost in Translation: Contexts, Computing, Disputing on Wikipedia, in, Berlin 2014. Online: https://doi.org/10.9776/14027.</p> <p>Dogunke, Swantje: Was hei\u00dft \u00bbDigital Humanities\u00ab?, Blog | Klassik Stiftung Weimar, 17.06.2015, https://blog.klassik-stiftung.de/digital-humanities/, Stand: 06.08.2020.</p> <p>Fickers, Andreas: Update f\u00fcr die Hermeneutik. Geschichtswissenschaft auf dem Weg zur digitalen Forensik?, in: Zeithistorische Forschungen 17 (1), ZZF \u2013 Centre for Contemporary History: Zeithistorische Forschungen, 2020, S. 157\u2013168. Online: https://doi.org/10.14765/ZZF.DOK-1765.</p> <p>F\u00f6hr, Pascal: Historische Quellenkritik im Digitalen Zeitalter, Dissertation, Universit\u00e4t Basel, Basel 2018.</p> <p>Ford, Heather: The Missing Wikipedians, in: Lovink, Geert; Tkacz, Nathaniel (Hg.): Critical Point of View: A Wikipedia Reader, Amsterdam 2011, S. 258\u2013268. Online: https://networkcultures.org/blog/publication/critical-point-of-view-a-wikipedia-reader/.</p> <p>Geiger, R. Stuart: The Lives of Bots, in: Lovink, Geert; Tkacz, Nathaniel (Hg.): Critical Point of View: A Wikipedia Reader, Amsterdam 2011, S. 78\u201393. Online: https://networkcultures.org/blog/publication/critical-point-of-view-a-wikipedia-reader/.</p> <p>Gredel, Eva: Digitale Diskurse und Wikipedia. Wie das Social Web Interaktion im digitalen Zeitalter verwandelt, T\u00fcbingen 2018.</p> <p>Hafner, Urs: Der Irrtum der Zeitmaschinisten | NZZ, Neue Z\u00fcrcher Zeitung, 27.05.2016, https://www.nzz.ch/feuilleton/zeitgeschehen/digital-history-historiografie-des-zeitpfeils-ld.85000, Stand: 13.06.2020.</p> <p>Hecht, Brent; Gergle, Darren: The tower of Babel meets web 2.0: user-generated content and its applications in a multilingual context, in: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, Atlanta, Georgia 2010, S. 291\u2013300. Online: https://doi.org/10.1145/1753326.1753370.</p> <p>Heinrich, Horst-Alfred; Gilowsky, Julia: Wie wird kommunikatives zu kulturellem Ged\u00e4chtnis? Aushandlungsprozesse auf den Wikipedia-Diskussionsseiten am Beispiel der Wei\u00dfen Rose, in: Sebald, Gerd; D\u00f6bler, Marie-Kristin (Hg.): (Digitale) Medien und soziale Ged\u00e4chtnisse, Wiesbaden 2018 (Soziales Ged\u00e4chtnis, Erinnern und Vergessen \u2013 Memory Studies), S. 143\u2013168. Online: https://doi.org/10.1007/978-3-658-19513-7.</p> <p>Hiltmann, Torsten: Hilfswissenschaften in Zeiten der Digitalisierung, in: Historische Grundwissenschaften und die digitale Herausforderung, Bd. 18, 2016 (Historisches Forum), S. 79\u201383.</p> <p>Hoeres, Peter: Hierarchien in der Schwarmintelligenz. Geschichtsvermittlung auf Wikipedia, in: Wozniak, Thomas; Nemitz, J\u00fcrgen; Rohwedder, Uwe (Hg.): Wikipedia und Geschichtswissenschaft, Berlin/Boston 2015, S. 15\u201331.</p> <p>Hollstein, Betina: Qualitative Methoden und Netzwerkanalyse - ein Widerspruch?, in: Qualitative Netzwerkanalyse: Konzepte, Methoden, Anwendungen, 2007.</p> <p>Keupp, Jan: Die digitale Herausforderung: Kein Reservat der Hilfswissenschaften, in: Historische Grundwissenschaften und die digitale Herausforderung, Bd. 18, 2016 (Historisches Forum), S. 89\u201392.</p> <p>Kim, Suin; Park, Sungjoon; Hale, Scott A. u. a.: Understanding Editing Behaviors in Multilingual Wikipedia, in: PLOS ONE 11 (5), 12.05.2016. Online: https://doi.org/10.1371/ journal.pone.0155305.</p> <p>Kirschenbaum, Matthew: The .txtual Condition: Digital Humanities, Born-Digital Archives, and the Future Literary, in: Digital Humanities Quarterly 7 (1), 01.07.2013.</p> <p>Kleinke, Sonja; Schultz, Julia: Ist \u201eNation\u201c gleich \u201enation\u201c? Zwei Wikipedia-Artikel im Sprach- und Kulturvergleich, in: Diskurse \u2013 digital 1 (1), 19.02.2019, S. 62\u201397. Online: https://doi.org/10.25521/diskurse-digital.2019.61.</p> <p>Krajewski, Markus: Programmieren als Kulturtechnik, in: Historische Grundwissenschaften und die digitale Herausforderung, Bd. 18, 2016 (Historisches Forum), S. 37\u201340.</p> <p>Krug, Alexandra: Zensur in Bildern. Verlauf der Zensur der chinesischen Wikipedia in den 2010er Jahren in Bildern, in, 28.02.2020. Online: https://doi.org/10.5281/zenodo.3711513, Stand: 15.03.2020.</p> <p>Matzner, Tobias; Ochs, Carsten: Sorting Things Out Ethically. Privacy as a Research Issue beoyond the Individual, in: Zimmer, Michael; Kinder-Kurlanda, Katharina E. (Hg.): Internet research ethics for the social age: new challenges, cases, and context, New York 2017, S. 39\u201352. Online: . <p>Prinz, Claudia; Schlotheuber, Eva; Hohls, R\u00fcdiger: Vorwort der Redaktion, in: Historische Grundwissenschaften und die digitale Herausforderung, Bd. 18, 2016 (Historisches Forum), S. 1\u20135.</p> <p>Rehbein, Malte: Digitalisierung braucht Historiker/innen, die sie beherrschen, nicht beherrscht, in: Historische Grundwissenschaften und die digitale Herausforderung, Bd. 18, 2016 (Historisches Forum), S. 45\u201351.</p> <p>Richter, Klaus: Wikipedia als Objekt der Nationalismusforschung \u2013 das Beispiel der Stadt Vilnius/Wilno, in: Wozniak, Thomas; Nemitz, J\u00fcrgen; Rohwedder, Uwe (Hg.): Wikipedia und Geschichtswissenschaft, Berlin/Boston 2015, S. 149\u2013154.</p> <p>Sahle, Patrick; Henny, Ulrike: Klios Algorithmen: Automatisierte Auswertung von Wikipedia-Inhalten als Faktenbasis und Diskursraum, in: Wozniak, Thomas; Nemitz, J\u00fcrgen; Rohwedder, Uwe (Hg.): Wikipedia und Geschichtswissenschaft, Berlin/Boston 2015, S. 113\u2013148.</p> <p>Schmale, Wolfgang: Historische Grundwissenschaften international, in: Historische Grundwissenschaften und die digitale Herausforderung, Bd. 18, 2016 (Historisches Forum), S. 23\u201325.</p> <p>Shirk, Susan L.: China: Fragile Superpower, New York 2008.</p> <p>Weller, Kathrin; Kinder-Kurlanda, Katharina E.: To Share or Not to Share. Ethical Challanges in Sharing Social Media-based Research Data, in: Zimmer, Michael; Kinder-Kurlanda, Katharina E. (Hg.): Internet research ethics for the social age: new challenges, cases, and context, New York 2017, S. 115\u2013129. Online: . <p>Wozniak, Thomas: Wikipedia in Forschung und Lehre \u2013 eine \u00dcbersicht, in: Wozniak, Thomas; Nemitz, J\u00fcrgen; Rohwedder, Uwe (Hg.): Wikipedia und Geschichtswissenschaft, Berlin/Boston 2015, S. 33\u201352.</p> <p>Wozniak, Thomas: Zitierpflicht f\u00fcr Wikipediaartikel \u2013 und wenn ja, f\u00fcr welche und wie?, Billet, Mittelalter, https://mittelalter.hypotheses.org/3721, Stand: 14.06.2020.</p> <p>Wozniak, Thomas; Nemitz, J\u00fcrgen; Rohwedder, Uwe (Hg.): Wikipedia und Geschichtswissenschaft, Berlin/Boston 2015. Online: https://doi.org/10.1515/9783110376357.</p> <p>Wurthmann, Nicola; Schmidt, Christoph: Digitale Quellenkunde. Zukunftsaufgaben der Historischen Grundwissenschaften, in: Zeithistorische Forschungen 17 (1), ZZF \u2013 Centre for Contemporary History: Zeithistorische Forschungen, 2020, S. 169\u2013178. Online: https://doi.org/10.14765/ZZF.DOK-1764.</p> <p>Yasseri, Taha; Speorri, Anselm; Graham, Mark u. a.: The Most Controversial Topics in Wikipedia. A Multilingual and Geographical Aalysis, in: Global Wikipedia: International and Cross-Cultural Issues in Online Collaboration, Lanham 2014, S. 25\u201348. Online: http://arxiv.org/abs/1305.5566.</p> <p>Zosel, Ralf: Im Namen des Volkes: Gerichte zitieren Wikipedia, in: JurPC Web-Dok 140/2009, 07.07.2009. Online: https://doi.org/10.7328/jurpcb/2009247123.</p>"},{"location":"Anhang_Quelltext.html","title":"Quelltext","text":""},{"location":"Anhang_Quelltext.html#python-skripte","title":"Python Skripte","text":"<p>Im Folgenden werden Ausz\u00fcge des f\u00fcr diese Untersuchungen geschriebenen Quelltextes aufgelistet. Die Auswahl beschr\u00e4nkt sich dabei auf zentrale Bestandteile der Funktionslogik. Ausschlie\u00dflich unterst\u00fctzende Teile wie Konstruktoren oder getter und setter werden nicht aufgef\u00fchrt. Der vollst\u00e4ndige Quelltext liegt liegt als usernetwork.py der Arbeit bei. Der Quelltext wurde in Python 3.6 unter Verwendung von Spyder 3.2.6 geschrieben.</p>"},{"location":"Anhang_Quelltext.html#class-usernetwork","title":"class UserNetwork","text":"<p>Klasse zur Datenerhebung- und -verarbeitung von Usernetzwerken in der Wikipedia. Dient als Grundlage f\u00fcr Netzwerkvisualisierungen und -analysen.</p> <pre><code># Exemplarischer Aufruf:\n# Initialisierung und Abruf der letzten 500 Versionen einer Artikelhistorie:\nusrntwrk = UserNetwork()\nusrntwrk.add_article_data(\"https://en.wikipedia.org/w/index.php?title=Coronavirus_disease_2019&amp;offset=&amp;limit=500&amp;action=history\")\n\n# Sicherung der Ergebnismenge als .csv unter Angabe von Titel und Tiefe.\nusrntwrk.write_csv(\"_corona_500\")\n\n# Abruf der letzten 50 Edits f\u00fcr jeden User der abgerufenen Historie in allen definierten Sprachen (self.cont_languages). Zuordnung von Sprachen zu Nutzern gem\u00e4\u00df Usercontributions.\nusrntwrk.add_usercontributions(\"50\")\nusrntwrk.compute_language\n\n# Entfernen aller Artikel mit weniger als 5 referenzierten Versionen und Zusammenfassen von gleichartigen Edges (selbe Relation)\nusrntwrk.delete_articles_by_count(edgeCount = 5)\nusrntwrk.condense_edges()\n\n# Visualisierung der Sprachverteilung mittels Sprachknoten.\nusrntwrk.create_language_network()\n\n</code></pre>"},{"location":"Anhang_Quelltext.html#def-_get_xml_dataself-url-stylesheet","title":"def _get_xml_data<code>(self, url, stylesheet)</code>","text":"<p>Ruft eine Seite ab und transformiert diese nach XML.</p> <pre><code># url:          parametrisierte URL der Artikelhistorie oder User contributions\n# stylesheet:   xslt zur Transformation der abzurufenden Daten\n# returns:      etree-Objekt mit XML\n\ndatadir = \"data/\"\nlang = urlparse(url).netloc.split(\".\")[0] + \"_\"\n\n# Dateiname wird aus Query-Teil der URL und Endung .xml gebildet\nif urlparse(url).query:\n    file = urlparse(url).query + \".xml\"\n\n# Falls kein Queryteil vorhanden, letzter Pfadteil +.xml\nelse:\n    file = str(urlparse(url).path.rsplit(\"/\")[-1]) + \".xml\"\n\n# vollst\u00e4ndiger Pfad aus Verzeichnis/Sprachversion_Dateiname.xml\nfile = datadir + lang + file\n\n# Wenn XML bereits vorhanden, die verwenden\nif os.path.exists(file):\n    xml = etree.parse(open(file, \"r\"))\n\n# HTML abrufen, mittels Schema transformieren und lokal speichern\nelse:\n    html = requests.get(url).content\n    tree = etree.fromstring(html, parser = etree.XMLParser(recover=True))\n    xml = etree.XSLT(etree.parse(stylesheet))(tree)\n    with open(file, \"w\") as f:\n        f.write(str(xml))\n\nreturn xml\n</code></pre>"},{"location":"Anhang_Quelltext.html#def-add_article_dataself-url","title":"def add_article_data<code>(self, url)</code>","text":"<p>L\u00e4dt eine via URL definierte Artikelhistorie der Wikipedia herunter oder l\u00e4dt ein lokales Abbild und tr\u00e4gt den Artikel sowie die zugeh\u00f6rigen Benutzer in <code>nodes[]</code> und <code>edges[]</code> ein.</p> <pre><code># url:  Parametrisierte URL der Artikelhistorie in der Form: https://en.wikipedia.org/w/index.php?title=TITLE&amp;limit=LIMIT&amp;action=history\n\n# article XML beziehen bzw. lokale Kopie laden\narticle = self._get_xml_data(url, \"history.xsl\")\n\n# article Sprache ermitteln\narticle_lang = article.xpath('/article/language')[0].text\n\n# article-node zusammenstellen\narticle_node = self.nodes_append(article.xpath('/article/title')[0].text.rsplit(\": \", 1)[0], 'article', article_lang, 1)\n\nfor version in article.xpath('/article/versions/version'):\n    user_node = self.nodes_append(version.xpath('./user')[0].text, 'user', '')\n\n    # version als edge hinzuf\u00fcgen\n    self.edges_append(user_node[0],\n        article_node[0],\n        version.xpath('./timestamp')[0].text,\n        version.xpath('./id',)[0].text,\n        article_lang)\n</code></pre>"},{"location":"Anhang_Quelltext.html#def-compute_languageself","title":"def compute_language<code>(self)</code>","text":"<p>Ermittelt \u00fcber die User Contributions die Sprachen und deren absolute H\u00e4ufigkeit je User.</p> <pre><code># NB: Vor condense_edges() und delete_nodes_by_count() ausf\u00fchren.\n\n# aus nodes[] _alle_ Artikel und deren Sprache (z.B. {\"en\":1}) auflisten\narticles = [[name, lang] for [name, lang, type] in self.nodes if type == 'article']\nfor node in self.nodes:\n    if node[2] == 'user':\n\n        # alle Artikel-User-Relationen f\u00fcr den aktuellen User aus edges[]\n        edits = [article for [user, article, timestamp, vid, lang] in self.edges if user == node[0]]\n\n        # f\u00fcr die ermittelten Artikel die Sprache{} ermitteln\n        # languages ist also: [{},]\n        languages = [lang for [name, lang] in articles if name in edits]\n\n        # node[1] = Sprachen, sollte bei einem User ein leeres dict sein\n        if type(node[1]) != type(dict()):\n            node[1] = dict()\n\n        # f\u00fcr jedes {} in languages wird dessen wert\n        for item in languages:\n\n            # je item wird jeder bekannte Sprachkey gepr\u00fcft\n            for lang in self._cont_languages.keys():\n\n            # je Sprachkey wird der Wert aus item abgerufen und im node aufaddiert\n                if lang in node[1].keys():\n                    node[1][lang] += item.get(lang, 0)\n                else:\n                    node[1].update({lang: item.get(lang, 0)})\n</code></pre>"},{"location":"Anhang_Quelltext.html#def-add_usercontributionsself-depth-100-offset-users-none","title":"def add_usercontributions<code>(self, depth = \"100\", offset = \"\", users = None)</code>","text":"<p>F\u00fcgt f\u00fcr alle User des aktuellen Netzwerkes f\u00fcr alle definierten Sprachen (<code>self._cont_languages</code>) die User-Contributions als Nodes hinzu und verkn\u00fcpft diese mit dem User. Dient der Ermittlung der User-Sprachen \u00fcber die Contributions und zur Sichtbarmachung eventueller Contributionnetzwerke.</p> <pre><code># depth:    Int. Default = 100. Anzahl an Eintr\u00e4gen je Contribution die geladen werden soll.\n# offset:   Str. Datum im Format YYYYMMDDhhmmss. Zeitpunkt ab dem antichronologisch die Contributions ermittelt werden.\n# Users:    List. Default = None. Ermittelt die Contributions f\u00fcr die direkt als Liste \u00fcbergebenen User. Die lokale nodes[] wird hierbei ignoriert.\n\n# wenn Users nicht gesetzt ist -&gt; vorhandene User ermitteln\nif users is None or len(users) == 0:\n    users = [name for [name, lang, nodetype] in self._nodes if nodetype == \"user\"]\n\n    # (falsche) Stringeingaben abfangen und in Liste umwandeln\n    if isinstance(users, str) and len(users) &gt; 0:\n        users = [users]\n\n    for user in users:\n        print(\"ermittle Artikel f\u00fcr User \" + user + \" ..\")\n        for cont in self._cont_languages.items():\n\n            # je Sprachversion, NB &amp;target=USERNAME muss als letztes Element notiert sein\n            self.add_user_data(cont[1] + '&amp;offset=' + str(offset) + '&amp;limit=' + str(depth) + '&amp;target=' + user)\n</code></pre>"},{"location":"Anhang_Quelltext.html#def-delete_nodes_by_countself-edgecount-2-user-false","title":"def delete_nodes_by_count<code>(self, edgeCount = 2, user = False)</code>","text":"<p>Entfernt s\u00e4mtliche Article-Nodes mit weniger als n Versionen gesamt (<code>edgeCount</code>). Optional werden auch Usernodes entfernt (<code>user</code>).</p> <pre><code># edgeCount:    Anzahl an Versionen (edges) unter der ein Artikel gel\u00f6scht wird. Optional, default = 2\n# user:         Bool. Default = False. Wenn gesetzt, werden User analog zu Artikeln entfernt.\n\n# NB: Vor condense_edges() ausf\u00fchren.\n\n# lokale Kopie zur Manipulation\nnodes_reduced = self.nodes.copy()\nfor item in self.nodes:\n    mentions = None\n\n    if user and item[2] == 'user':\n        # Referenzen f\u00fcr User ermitteln\n        mentions = [article for [user, article, timestamp, vid, lang] in self.edges if user == item[0]]\n\n    elif item[2] == 'article':\n        # Referenzen f\u00fcr Artikel ermitteln\n        mentions = [user for [user, article, timestamp, vid, lang] in self.edges if article == item[0]]\n\n    # Wenn Referenzen &lt; Parameter, Item l\u00f6schen\n    if mentions is not None and len(set(mentions)) &lt; edgeCount:\n        nodes_reduced.remove(item)\n\n# reduzierte Liste \u00fcbergeben (an private, da setter appended)\nself._nodes = nodes_reduced.copy()\n</code></pre>"},{"location":"Anhang_Quelltext.html#def-return_intervalself-begin-end","title":"def return_interval<code>(self, begin, end)</code>","text":"<p>Vergleicht die Timestamps in <code>edges[]</code> mit den \u00fcbergebenen Grenzwerten und gibt ein (<code>nodes[]</code>, <code>edges[]</code>) tuple f\u00fcr den gegebenen Zeitraum zur\u00fcck. Relationen zu den nachtr\u00e4glich erzeugten Sprach-Nodes werden immer \u00fcbernommen, sind also interval-unabh\u00e4ngig.</p> <pre><code># begin:                Datetime. &lt;= Intervall.\n# end:                  Datetime. &gt;= Intervall.\n# Parametersignatur:    datetime(YYYY, M, D, h, m)\n# returns:              tuple(nodes[], edges[])\n\nnodes_slice = list()\nedges_slice = list()\n\n# Edges der Sprachrelationen ermitteln -&gt; die haben keine Timestamps\nlang_edges = [[user, language, timestamp, vid, lang]\n                for [user, language, timestamp, vid, lang]\n                in self._edges if language in self._cont_languages.keys()]\n\n# Edges \u00fcber timestamp ermitteln. Edges: [user, article, timestamp, id, lang]\n# oder condensed: [user, article, [timestamp], [id], lang]\n\nfor edge in self._edges:\n# Sprach-Relationen haben kein Timestamp und m\u00fcssen gesondert behandelt werden\n    if edge not in lang_edges:\n        try:\n            # liste -&gt; also condensed -&gt; auf Listeneintr\u00e4ge pr\u00fcfen\n            if type(edge[2]) == type(list()):\n                timestamps = [timestamp for timestamp in edge[2] \n                    if timestamp &gt;= begin and timestamp &lt;= end]\n                if len(timestamps) &gt; 0:\n                    # add this edge\n                    edges_slice.append(edge)\n            # keine Liste -&gt; nicht condensed -&gt; datetime()\n            else:\n                if edge[2] &gt;= begin and edge[2] &lt;= end:\n                    edges_slice.append(edge)\n        except TypeError:\n            print(\"Wrong timestamp type: \" + str(edge))\n\n# alle adressierten Nodes (user &amp; article) ermitteln und unn\u00f6tige Duplikate entfernen\nusers_in_edges = set([user for [user, article, timestamp, vid, lang]\n                    in edges_slice])\narticles_in_edges = set([article for [user, article, timestamp, vid, lang] \n                    in edges_slice])\n\n# Sprachrelationen f\u00fcr User hinzuf\u00fcgen\nedges_slice += [[user, language, timestamp, vid, lang]\n                for [user, language, timestamp, vid, lang]\n                in lang_edges if user in users_in_edges]\n\n# alle Nodes \u00fcbernehmen, die in edges_slice oder _cont_languages referenziert werden\nnodes_slice = [[name, lang, ntype]\n    for [name, lang, ntype]\n    in self._nodes\n    if name in users_in_edges\n    or name in articles_in_edges\n    or name in self._cont_languages.keys()]\n\nreturn (nodes_slice, edges_slice)\n</code></pre>"},{"location":"Anhang_Quelltext.html#xslt-schemata","title":"XSLT-SCHEMATA","text":"<p>Die folgenden Schema-Ausz\u00fcge zeigen die verwendeten Transformationsschemata zur Auswertung der HTML-Dateien. Der Quelltext entspricht XSLT in der Version 1.0. Die Ausz\u00fcge beschr\u00e4nken sich auf die Funktionslogik.</p>"},{"location":"Anhang_Quelltext.html#historyxsl","title":"history.xsl","text":"<p>Die Schemadatei dient dazu, das HTML-Dokument einer Wikipedia-Versionsgeschichte zu zerlegen und in eine auswertbare Struktur zu \u00fcberf\u00fchren.</p> <pre><code>&lt;xsl:variable name=\"lang\" select=\"//@lang\" /&gt;\n\n&lt;xsl:template match=\"/\"&gt;\n    &lt;article&gt;\n        &lt;language&gt;&lt;xsl:value-of select=\"$lang\"/&gt;&lt;/language&gt;\n        &lt;xsl:apply-templates /&gt;\n    &lt;/article&gt;\n&lt;/xsl:template&gt;\n\n&lt;xsl:template match='title'&gt;\n    &lt;title&gt;\n        &lt;xsl:value-of select='.'/&gt;\n    &lt;/title&gt;\n&lt;/xsl:template&gt;\n\n&lt;xsl:template match='ul[@id=\"pagehistory\"]'&gt;\n    &lt;versions&gt;\n        &lt;xsl:for-each select=\"li\"&gt;\n            &lt;version&gt;\n                &lt;id&gt;&lt;xsl:value-of select=\"@data-mw-revid\"/&gt;&lt;/id&gt;\n                &lt;timestamp&gt;\n                    &lt;xsl:value-of select='*[@class=\"mw-changeslist-date\"]' /&gt;\n                &lt;/timestamp&gt;\n                &lt;user&gt;\n                    &lt;xsl:value-of select=\".//bdi\"/&gt;\n                &lt;/user&gt;\n                &lt;minoredit&gt;\n                    &lt;xsl:choose&gt;\n                        &lt;xsl:when test='.//@class=\"minoredit\"'&gt;1&lt;/xsl:when&gt;\n                        &lt;xsl:otherwise&gt;0&lt;/xsl:otherwise&gt;\n                    &lt;/xsl:choose&gt;\n                &lt;/minoredit&gt;\n                &lt;comment&gt;\n                    &lt;xsl:value-of select='*[@class=\"comment comment--without-parentheses\"]'/&gt;\n                &lt;/comment&gt;\n           &lt;/version&gt;\n        &lt;/xsl:for-each&gt;\n    &lt;/versions&gt;\n&lt;/xsl:template&gt;\n</code></pre>"},{"location":"Anhang_Quelltext.html#userxsl","title":"user.xsl","text":"<p>Diese Schemadatei dient dazu, das HTML-Dokument einer Wikipedia-Benutzerbeitr\u00e4geseite zu zerlegen und in eine auswertbare Struktur zu \u00fcberf\u00fchren.</p> <pre><code>&lt;xsl:variable name=\"lang\" select=\"//@lang\" /&gt;\n\n&lt;xsl:template match=\"/\"&gt;\n    &lt;user&gt;\n        &lt;language&gt;&lt;xsl:value-of select=\"$lang\"/&gt;&lt;/language&gt;\n        &lt;xsl:apply-templates /&gt;\n    &lt;/user&gt;\n&lt;/xsl:template&gt;\n\n&lt;xsl:template match='link[@rel=\"canonical\"]'&gt;\n    &lt;name&gt;\n        &lt;xsl:value-of select='substring-after(@href, \"target=\")'/&gt;\n    &lt;/name&gt;\n&lt;/xsl:template&gt;\n\n&lt;xsl:template match='ul[@class=\"mw-contributions-list\"]'&gt;\n    &lt;versions&gt;\n        &lt;xsl:for-each select=\"li\"&gt;\n            &lt;version&gt;\n                &lt;id&gt;&lt;xsl:value-of select=\"@data-mw-revid\"/&gt;&lt;/id&gt;\n                &lt;timestamp&gt;\n                    &lt;xsl:value-of select='*[@class=\"mw-changeslist-date\"]' /&gt;\n                &lt;/timestamp&gt;\n                &lt;title&gt;\n                    &lt;xsl:value-of select=\"a/@title\"/&gt;\n                &lt;/title&gt;\n                &lt;comment&gt;\n                    &lt;xsl:value-of select='*[@class=\"autocomment\"]'/&gt;\n                &lt;/comment&gt;\n            &lt;/version&gt;\n        &lt;/xsl:for-each&gt;\n    &lt;/versions&gt;\n&lt;/xsl:template&gt;\n</code></pre>"},{"location":"Kapitel_1.html","title":"Kapitel 1 - Digital History und Wikipedistik \u2013 Diskurse und Fehlstellen","text":"<p>Die Untersuchung digitaler Quellen f\u00e4llt recht eindeutig in den Zust\u00e4ndigkeitsbereich der Historischen Fachinformatik, die heute h\u00e4ufig das Alias Digital History benutzt. Die vorsichtige Relativierung der Zust\u00e4ndigkeit ist hierbei mit Bedacht gew\u00e4hlt, da im Gegensatz zu den meisten anderen Fachbereichen die Digital History bis heute keine finale Definition erfahren hat. Im sp\u00e4rlich belegten deutschen Wikipediaartikel werden ihr formale Verfahren sowie \u00f6ffentliche Wirksamkeit zugeordnet, w\u00e4hrend der englische Artikel auch explizit digitale Medien erw\u00e4hnt und zwischen einer \u00f6ffentlichkeitswirksamen und forschungsorientierten Ausrichtung unterscheidet. <sup>1</sup> Diese Definitionsschwierigkeiten lassen sich jedoch auch auf die \u00fcbergeordneten Digital Humanities \u00fcbertragen, von denen ebenfalls unklar ist, ob diese eine Quellenart, einen Methodenkanon oder gar ein eigenes Fach bezeichnen. <sup>2</sup> Das vorliegende Kapitel widmet sich daher der Diskussion der Digital History selbst in zwei Schritten. Zun\u00e4chst wird die Funktion des Fachbereichs innerhalb der Geschichtswissenschaft anhand des 18. Historischen Forums betrachtet und anschlie\u00dfend der Forschungszweig der Wikipedistik vorgestellt und diskutiert.</p>"},{"location":"Kapitel_1.html#11-historische-grundwissenschaften-und-die-digitale-herausforderung","title":"1.1 Historische Grundwissenschaften und die digitale Herausforderung","text":"<p>Das Historische Forum mit dem Untertitel Historische Grundwissenschaften und die digitale Herausforderung tagte von November 2015 bis Januar 2016 und folgte der Fragestellung, welche Kompetenzen zu einer geschichtswissenschaftlichen Ausbildung im 21. Jahrhundert geh\u00f6re und welche Rolle die Digital History dabei spiele. <sup>3</sup> Angesichts seit Jahren schwindender grundwissenschaftlicher Lehrangebote war hierbei die m\u00f6gliche Eigenst\u00e4ndigkeit der Digital History und ihr Potential zur Wiederbelebung der Hilfswissenschaften neben der Digitalisierung der Quellen das zentrale Thema. Weiterhin illustriert es die Findungsphase, in der sich die Digital History nach wie vor befindet. So vergleicht Rehbein die Digital History mit der Pal\u00e4ographie, da beide uns erst den Zugriff auf die jeweiligen Quellen erm\u00f6glichten und fordert, dass eine basale technische Kompetenz bereits zu Beginn des Studiums gelehrt werden solle. <sup>4</sup> Ganz \u00e4hnlich sieht es Krajewski, der diesen \u201aletzten Neuzugang historischer Grundwissenschaften\u2018 insbesondere auch als Schnittstelle zu anderen Wissenschaften versteht. <sup>5</sup> Hiltmann argumentiert hingegen, dass man der Digitalisierung der Quellenbest\u00e4nde mit der Digitalisierung der Hilfswissenschaften begegnen sollte. Hierbei w\u00fcrde die Vermittlung grundlegender digitaler Kompetenzen die notwendige grundwissenschaftliche Ausbildung erg\u00e4nzen. <sup>6</sup> \u00c4hnlich sieht es auch Keupp, der fordert, dass die Digital History \u201eauf die breiten Schultern aller historischen Teildisziplinen gelegt und aus den Fragestellungen m\u00f6glichst aller Fachkolleg/innen gespeist werden [m\u00fcsse].\u201c <sup>7</sup> Jedoch erscheint die Digital History, in Anbetracht der Vielzahl an unterschiedlichen Aufgaben, Schwerpunkten und Auspr\u00e4gungen, die ihr zugewiesen werden, hier als eine Art Projektionsfl\u00e4che. So schlie\u00dft Schmale seinen Beitrag zum Forum mit der Einsch\u00e4tzung, dass die Debatte vorrangig als Hebel diene, um vernachl\u00e4ssigte Fragen an das Selbstverst\u00e4ndnis des Faches zu stellen. <sup>8</sup> Einig sind sich die am Forum Beteiligten jedenfalls, dass die Digital History, in welcher Gestalt auch immer, eine Zukunft haben wird und haben muss. Gleichwohl gibt es diesbez\u00fcglich durchaus auch ablehnende Haltungen. So schreibt Hafner fern des Historischen Forums in der NZZ im Mai 2016:</p> <p>Die Digitalisierung der Geschichte, wie die Digital History sie propagiert und praktiziert, f\u00fchrt zu ihrer Trivialisierung. Die Revolution ist eine Regression. [...] Gegen die Verg\u00e4nglichkeit f\u00e4hrt die Digital History ihren zeitblinden, unsensiblen Szientismus auf. <sup>9</sup></p> <p>Hafner ignoriert hierbei jedoch, ebenso wie viele Teilnehmende des Historischen Forums, vollst\u00e4ndig die Existenz und zeitgeschichtliche Relevanz der genuin digitalen Quellen. W\u00e4hrend die Geschichtswissenschaft nach wie vor \u00fcber die Digitalisierung diskutiert, ist diese in vielen anderen Bereichen, in Forschung, Wirtschaft und Politik, seit Jahren gelebte Praxis. Folglich werden viele der heute erzeugten, zuk\u00fcnftigen historischen Quellen niemals dem Prozess der Retrodigitalisierung unterworfen werden \u2013 denn sie sind ihrem Wesen nach digital. Die von Schmale geforderte grundwissenschaftliche Begleitung dieser genuin digitalen Quellen verlangt dementsprechend gr\u00f6\u00dfere Aufmerksamkeit und ist daher das Kernthema der vorliegenden Arbeit.<sup>10</sup> Eine sehr aktive Umgebung und entsprechend wichtiges Beispiel f\u00fcr die Arbeit mit genuin digitalen Quellen ist der Fachbereich der Wikipedistik, also die wissenschaftliche Auseinandersetzung mit der Wikipedia.</p>"},{"location":"Kapitel_1.html#12-wikipedistik-und-genuin-digitale-korpora","title":"1.2 Wikipedistik und genuin digitale Korpora","text":"<p>Sie ist ein exzellentes Beispiel f\u00fcr einen Wissensraum im Big Data und f\u00fcr ein offenes, leicht zug\u00e4ngliches Informationsnetz. Sie verh\u00e4lt sich heute schon so, wie es f\u00fcr alle Informationsressourcen der Geschichtswissenschaften w\u00fcnschenswert w\u00e4re. <sup>11</sup></p> <p>So euphorisch beschreiben Sahle und Henny diesen Vertreter einer neuen Quellengattung und z\u00e4hlen anschlie\u00dfend dessen Qualit\u00e4ten detailliert auf: So bestehe sie aus offenen und frei nachnutzbaren sowie gleichm\u00e4\u00dfig strukturierten Inhalten, deren Lizenzstatus geregelt sei und deren Datenobjekte, die eigentlichen Artikel, mit klaren Adressen dauerhaft angesprochen und ausgewertet werden k\u00f6nnten. <sup>12</sup></p> <p>Es erstaunt somit kaum, dass sich um die Wikipedia und die ihr verwandten Projekte eine Subkultur der Forschung etabliert hat, die Wikipedistik. Unter diesem relativ unscharfen Begriff werden wissenschaftliche Untersuchungen verschiedenster Art und Weise subsumiert, die sich in irgendeiner Art und Weise mit der Wikipedia besch\u00e4ftigen. Den fr\u00fchen Fragen nach der Belastbarkeit der Wikipedia als allt\u00e4gliches Nachschlagewerk folgten kurze Zeit sp\u00e4ter Untersuchungen aus verschiedensten Fachbereichen. Eine Folge der guten Zug\u00e4nglichen und des hohen Interesses ist die daraus resultierende Masse und Breite der mittlerweile verf\u00fcgbaren Untersuchungen. Um die bereits durchgef\u00fchrte Forschung im Ansatz erfassen und sortieren zu k\u00f6nnen, ben\u00f6tigen wir zun\u00e4chst eine basale Systematik. Auf Basis der umfassenden Bibliografie zum Sammelband Wikipedia und Geschichtswissenschaft schl\u00e4gt Wozniak hierzu eine feingliedrige Einteilung der Wikipediaforschung vor und baut dabei auf der Einteilung durch Haber und Hodel von 2008 auf. <sup>13</sup> Wozniaks Aufstellung umfasst zw\u00f6lf Kategorien und beinhaltet die Themen: Literatur zur chronologischen Entwicklung der Wikipedia, Enzyklop\u00e4distik, kollaborative Schreibprozesse, Biases, Rezeption und Zitierf\u00e4higkeit, Erfahrungsberichte aus Lehre, Politik und Forschung, Untersuchungen zu Autorschaft, Motivation und Genderproblemen, Analysetools, Unterschiede zwischen Sprachversionen sowie weitere, nicht klar zuzuordnende Analysen. <sup>14</sup> Diese inhaltlich fokussierte Einteilung gew\u00e4hrt zwar einen unmittelbaren \u00dcberblick \u00fcber die verschiedenen Forschungsinteressen, gleichwohl ist die Einsortierung einzelner Untersuchungen in dieses spezifische Raster determinierend. Komplexere Untersuchungen werden hier m\u00f6glicherweise auf einen Teilaspekt beschr\u00e4nkt.</p> <p>Die Wikipedia-Community selbst hat sich ebenfalls mit der Wikipedistik auseinandergesetzt. Sowohl die User als auch die Wikimedia Foundation zeichnen sich durch eine positive Grundhaltung zur Erforschung der Wikipedia sowie damit verkn\u00fcpfter Projekte aus. So existiert neben eher bibliografisch ausgerichteten Seiten, die eine prim\u00e4r sammelnde Funktion erf\u00fcllen, <sup>15</sup> auch ein eigenes Portal f\u00fcr Forschungsvorhaben mit Bezug zur Wikipedia. <sup>16</sup> Projekte erhalten auf Antrag eine eigene Seite zur Dokumentation des Forschungsprozesses und werden chronologisch in einem offiziellen Verzeichnis gef\u00fchrt.</p> <p>This is the canonical directory of Wikimedia research projects that are planned, underway or have recently been completed. This list includes projects run or hosted by the Wikimedia Foundation as well as projects run by the research and editor community. <sup>17</sup> [sic]</p> <p>Diese Listen und Verzeichnisse sind dabei \u00fcblicherweise nur chronologisch, nicht aber gem\u00e4\u00df wissenschaftlicher Tradition oder Methodik unterteilt. Einzig eine basale Gruppierung nach dem Verh\u00e4ltnis zum Untersuchungsgegenstand hat sich etabliert: Die Forschung zur Wikipedia <sup>18</sup> sowie die Forschung mit Hilfe der Wikipedia. <sup>19</sup> Auf diese Einteilung einigten sich auch die User Ghilt und Christianvater in einer kurzen Kommentarserie vom 26. und 27. Februar 2019 auf der deutschen Projektseite Wikipedistik/Arbeiten. <sup>20</sup> Fortan sollte die Bibliografie je Jahr in Arbeiten \u00fcber Wikipedia sowie Arbeiten unter Verwendung der Wikipedia aufgeteilt werden, jedoch wurde diese Trennung zumindest dort noch nicht implementiert. <sup>21</sup> Dieser Ansatz, die Untersuchungen gem\u00e4\u00df ihres Forschungsgegenstandes zu unterteilen, erscheint sowohl pragmatisch als auch hilfreich in der Bewertung von Arbeiten f\u00fcr die vorliegende Untersuchung und wird dementsprechend von der Autorin \u00fcbernommen.</p> <p>Auf die Kategorisierung von Wozniak \u00fcbertragen, w\u00e4ren die Themenfelder Literatur zur chronologischen Entwicklung der Wikipedia, Enzyklop\u00e4distik, kollaborativen Schreibprozessen, Biases, Rezeption und Zitierf\u00e4higkeit sowie Erfahrungsberichten aus Lehre, Politik und Forschung der ersten Kategorie zuzurechnen. Ihr k\u00f6nnen etwa drei Viertel der untersuchten Bibliografie zugerechnet werden. Mit der Wikipedia als zentralen Untersuchungsgegenstand besch\u00e4ftigen sich diese Untersuchungen insbesondere mit den soziokulturellen Auswirkungen der freien Enzyklop\u00e4die, ihrer Rolle in Digitalisierung des Alltags und den in Folge dessen auftretenden urheberrechtlichen Herausforderungen. Die zweite Kategorie umfasst dagegen Untersuchungen zu Autorschaft, Motivation, Genderproblemen, Analysetools, Unterschieden zwischen Sprachversionen sowie nicht klar zuzuordnende Analysen. <sup>22</sup> Im Fokus der Analysen stehen hier die eigentlichen Inhalte der Artikel (insbesondere bei komparativen Untersuchungen von Sprachversionen) oder aber die Autor*innen und deren Dynamiken. Die klare Mehrheit der vorgestellten Forschung besch\u00e4ftigt sich also mit dem Ph\u00e4nomen Wikipedia als solches, w\u00e4hrend Untersuchungen, die die Wikipedia als Quelle verwenden aktuell vergleichsweise selten sind.</p> <p>Dies deckt sich in etwa mit den verschiedenen Bibliografien der Forschungsseiten der Wikipedia. <sup>23</sup> F\u00fcr die Digital History ist dies jedoch eine ern\u00fcchternde Feststellung, da somit viel von dem Potential, das Sahle und Henny im eingangs angef\u00fchrten Zitat erkannten, noch nicht ausgesch\u00f6pft wurde. Um diesen vielversprechenden Bereich zu illustrieren, werden im Folgenden einige Arbeiten vorgestellt, die als Beispiele und Inspirationen f\u00fcr k\u00fcnftige historiographische Untersuchungen mit Hilfe der Wikipedia sowie anderer, genuin digitaler Quellen gelten k\u00f6nnen.</p>"},{"location":"Kapitel_1.html#121-technische-zugange","title":"1.2.1 Technische Zug\u00e4nge","text":"<p>Die erste H\u00fcrde zur Nutzung der Wikipedia in einem digital historischen Kontext ist der Zugriff auf die Daten selbst. Zwar k\u00f6nnen praktisch alle Inhalte der Enzyklop\u00e4die ohne gro\u00dfe Vorbereitung mittels eines gebr\u00e4uchlichen Browsers eingesehen werden, jedoch er\u00f6ffnet erst der automatisierte Abruf und die folgende Weiterverarbeitung von Informationen den Zugang zu allen Eigenheiten dieser Quellengattung.</p> <p>Ein solcher Zugang ist Verarbeitung der HTML-Seiten analog zu XML-Dokumenten, wodurch ein einfacher Zugriff auf die Strukturen der Seiten m\u00f6glich wird. Einen derartigen pragmatischen Ansatz verfolgen Sahle und Henny in ihrem 2015 erschienen Aufsatz und erkunden dabei die Wikipedia als Quellenkorpus. <sup>24</sup> Sie diskutieren die Eignung einzelner Bestandteile von Wikipeda-Artikeln f\u00fcr die Forschung. Der Artikeltext selbst eigne sich beispielsweise f\u00fcr computerlinguistische und -philologische Analysen, insbesondere auch wegen der guten Verf\u00fcgbarkeit sowie des umfangreichen Korpus. Die Gliederung der Artikel durch \u00dcberschriften, die zum Beispiel \u00fcber das HTML der Seite eindeutig identifiziert werden k\u00f6nnten, erlauben eine spezialisierte Suche in verschiedenen Artikeln. Bilder und Links wiederum sind leicht zu identifizierende Merkmale, die auch ohne eine Auswertung des eigentlichen Texts Informationen zum Artikel preisgeben k\u00f6nnen. <sup>25</sup> Zudem erm\u00f6glichen sie die Analyse der Verkn\u00fcpfung von Artikeln. Die links zu anderssprachigen Artikelversionen erm\u00f6glichen dar\u00fcber hinaus eine sprach\u00fcbergreifende Analyse von Artikeln. Die Zuordnung zu Kategorien erweitert die Auswertungsm\u00f6glichkeiten zus\u00e4tzlich. Da die Verschlagwortung durch Kategorien idealerweise einer Systematik folgt, k\u00f6nnen somit weitere Metadaten zum Artikel ermittelt werden. Letztlich betonen Sahle und Henny die N\u00fctzlichkeit der weit verbreiteten Infoboxen. Diese besonders formalisierten \u00dcbersichtsdarstellungen, \u00fcblicherweise am Rand eines Artikels positioniert, k\u00f6nnen mittels einer entsprechend angepassten Auswertungsmethodik \u00e4hnlich einer Datenbank benutzt werden. <sup>26</sup></p> <p>Den Zugriff via HTML und X-Technologien begr\u00fcnden sie sowohl pragmatisch, als auch quellenkundlich. So w\u00e4re ein Zugriff auf die Daten \u00fcber das API nicht nur aufwendiger, sondern w\u00fcrde zudem keine wirklichen Vorteile bieten. Zudem w\u00fcrden Forschende bei einem Abruf der Quellen \u00fcber das Webinterface dieselben Schnittstellen nutzen, wie sie von den Usern im Alltag genutzt werden. Gleichwohl behandeln Sahle und Henny die Wikipedia in ihrem Beispielen zun\u00e4chst eher als eine simple Faktenquelle, denn als ein historisches Objekt. So zeigen Sie auf, wie aus den oben genannten Infoboxen mit relativ simplen Mitteln standardisierte Informationen abgerufen werden k\u00f6nnen. Die Autor*innen f\u00fchren das am Beispiel von Zug\u00e4ngen und Verlusten deutscher U-Boote im Zweiten Weltkrieg vor. <sup>27</sup></p> <p>In einem zweiten Teil erweitern Sie diesen Ansatz um die Analyse des Diskursraums Wikipedia. Hierzu werten Sie die Beziehung zwischen 28.589 Artikeln zum Schlagwort Historiker aus, indem sie die Verkn\u00fcpfungen durch Kategorisierungen visualisieren. Folgend diskutieren Sie die Praxis der Kategorisierung, f\u00fchren weitere Analysen mit den Daten durch und schlie\u00dfen mit der Darstellung eines Historiker-Erw\u00e4hnungsnetzwerkes, ausgehend von Theodor Mommsen. <sup>28</sup></p> <p>Die aufgezeigten Beispiele sind eine hilfreiche Einf\u00fchrung in verschiedene Ans\u00e4tze der Datenerhebung und Auswertung, sowie die N\u00fctzlichkeit der Wikipedia als Sekund\u00e4rquelle. Die erhobenen Informationen sind dabei jedoch nicht charakteristisch f\u00fcr die Wikipedia, denn diese wurden dort nur strukturiert zusammengef\u00fchrt. Insbesondere das Auslesen der Infoboxen w\u00e4re durch einen direkten Zugriff auf die zugrundeliegenden Wikidata-Objekte eleganter zu l\u00f6sen. Durch eine leichte Verschiebung des Fokus lassen sich aber die vorgestellten Ans\u00e4tze weiter entwickeln und f\u00fcr eine Fragestellung verwenden, bei welcher der Datensatz in der Wikipedia die eigentliche Quelle w\u00e4re. Der Aufsatz zeichnet sich durch einen fast schon handbuchartigen Charakter aus und kann als Anleitung und Inspiration zur technischen Auswertung der Wikipedia verstanden werden. Die Autor*innen verstehen die vorgef\u00fchrten Analysen zudem als Vorlage f\u00fcr folgende Untersuchungen und fordern im Fazit, dass die vorgestellten Ans\u00e4tze nicht nur genutzt, sondern stattdessen weiterentwickelt und anderen Forschenden zur Verf\u00fcgung gestellt werden sollen. <sup>29</sup></p>"},{"location":"Kapitel_1.html#122-schwerpunkt-sprachversionen","title":"1.2.2 Schwerpunkt: Sprachversionen","text":"<p>Ein vielversprechender Ansatz f\u00fcr m\u00f6gliche Herangehensweisen sind die Sprachversionen der Wikipedia. Das Nebeneinander von kooperativ verfassten Texten aus unterschiedlichen Sprachr\u00e4umen zu \u00fcbereinstimmenden Themen verspricht enormes Potential f\u00fcr die geschichtswissenschaftliche Forschung. <sup>30</sup> Nach Wozniak waren 2015 derartige Untersuchungen mit mageren drei Prozent noch selten vertreten, jedoch betont er auch, dass sich dort zuk\u00fcnftig ein bemerkenswertes Forschungspotential f\u00e4nde. <sup>31</sup></p> <p>So bewiesen zum Beispiel Hecht und Gergle bereits 2010, dass verschiedene global consensus hypotheses als nicht haltbar betrachtet werden m\u00fcssten. Laut diesen f\u00fchre die internationale Zusammenarbeit unter dem Diktat eines Neutral Point of Views zwangsl\u00e4ufig dazu, dass sich eine international einheitliche Auffassung zu einzelnen Themen herausbilden w\u00fcrde. Ein globaler Konsens. Um diese Hypothese zu pr\u00fcfen, untersuchten sie 25 verschiedene Sprachversionen der Wikipedia auf Unterschiede in ihren Wissenskonzepten und der Pr\u00e4sentation derselben. Dabei kamen sie jedoch zum Schluss, dass zwischen den einzelnen Sprachversionen eine signifikante Wissensdiversit\u00e4t herrsche. Sie fordern daraus folgend einen kulturbewussten Umgang mit dieser Ressource und bekr\u00e4ftigen hyperlinguale Anwendungen. <sup>32</sup></p> <p>Diese Diversit\u00e4t aufgreifend, untersuchte Richter 2015 die unterschiedlichen Darstellungen der Stadt Vilnius/Wilno in der polnischen und litauischen Wikipedia. Die Texte beider Versionen wichen dabei kaum von ihren jeweilig pr\u00e4genden hegemonialen und ethnozentrischen Narrativen ab. Richtet mutma\u00dft, dass der Editionsprozess m\u00f6glicherweise zu Territorialisierungsprozessen beitragen k\u00f6nne. Er betont den Wert derartiger Untersuchungen f\u00fcr die Nationalismusforschung, da die Quellen hier, trotz eines hohen Grades an information asymmetry, standardisiert vorl\u00e4gen. Weiterhin verweist er auf die Diskussionsseiten als m\u00f6gliche Quellen, die auch abweichende Narrationen aufwiesen und damit von besonderem Interesse f\u00fcr die Forschung sein k\u00f6nnten. <sup>33</sup></p> <p>\u00c4hnlich verfahren Kleinke und Schulz bei ihrer Untersuchung, jedoch betrachten diese im Rahmen einer qualitativen Mikroanalyse die Konstruktion des Konzepts Nation in der englischen sowie deutschen Wikipedia. Sie verglichen die Artikel dabei auf Grundlage manueller Analysen der kulturvergleichenden Wikipedistik sowie Kategorien der kognitiven Semantik und der kognitiven kritischen Diskursanalyse. Sie kommen zum Schluss, dass der englische Artikel nation eher sozialwissenschaftlich gepr\u00e4gt sei und sich insbesondere die Entwicklung von Nationen im englischen Sprachraum auf dessen Begriffsbestimmung auswirkten. Der deutsche Artikel Nation hingegen sei vorrangig von einer wissenschaftstheoretischen Auseinandersetzung gepr\u00e4gt. <sup>34</sup></p> <p>Die vorgestellten Untersuchungen bieten einen Einblick in die Potentiale vergleichender Analysen auf Grundlage der Wikipedia Sprachversionen. Gleichwohl wirft die Identit\u00e4t der edierenden User hier Fragen auf. So wird die implizierte Homogenit\u00e4t der Usergruppen in den jeweiligen Sprachversionen ungl\u00fccklicherweise weder gepr\u00fcft noch thematisiert und auch auf andere Faktoren, wie zum Beispiel die Rolle von Bots im Prozess der Definitionsfindung, wird nicht weiter eingegangen.</p>"},{"location":"Kapitel_1.html#123-schwerpunkt-akteure","title":"1.2.3 Schwerpunkt: Akteure","text":"<p>Die Datenbasis der Wikipedia erlaubt es weiterhin, die Autor*innen der Artikel selbst ins Zentrum der Untersuchung zu stellen. So analysierte Ford 2011 die Dynamik zwischen internationalen Beitr\u00e4gern und der englischsprachigen Wikipedia am Beispiel spezifisch kenyanischer Inhalte, beigetragen durch kenyanische User. Sie bemerkt, dass es zwar f\u00fcr kenyanische User einfacher sei, der swahilisprachigen Wikipedia beizutragen, doch sei f\u00fcr viele User die englischsprachige Wikipedia attraktiver, insbesondere wegen deren Reichweite und der M\u00f6glichkeit, die eigene Kultur international darzustellen. <sup>35</sup></p> <p>Ausgehend vom Artikel Kosovo and Metohija, dem zum Zeitpunkt der Analyse einzigen Artikel zum Kosovo in serbischer Sprache, analysierten Bilic und Bulian 2014 die Benutzerinteraktion unter anderem durch die Auswertung von Diskussions- und Benutzerseiten sowie durch Interviews mit Editoren. Sie zeigen auf, dass zwischen den Sprachversionen politische sowie kulturelle Konflikte und Unterschiede nicht nur reproduziert, sondern um online Identit\u00e4ten erweitert werden. Weder Konsens noch Konflikt seien folglich stabile Muster innerhalb der Wikipedia. <sup>36</sup></p> <p>Die einer m\u00f6glichen Konsensbildung zugrunde liegenden Aushandlungsprozesse untersuchten Heinrich und Gilowsky 2018. Sie \u00fcbertragen dabei die wissenssoziologische Struktur von kommunikativem und kulturellem Ged\u00e4chtnis auf den Wikipediaartikel zur Wei\u00dfen Rose. <sup>37</sup> Die Autor*innen verorten hierzu den eigentlichen Artikeltext auf der Makroebene und definieren ihn somit als das Ergebnis eines Aushandlungsprozesses, der in Form der Diskussionsseite auf der Mesoebene stattf\u00e4nde. <sup>38</sup> Sie kommen jedoch zum Schluss, dass die untersuchten Beitr\u00e4ge nur in wenigen F\u00e4llen eine direkte Auswirkung auf die Makroebene, also den Artikeltext selbst, h\u00e4tten und dass nur eine Minderheit der Diskussionen die historiographische Interpretation selbst behandelten. <sup>39</sup> Es ist somit anzunehmen, dass der Gro\u00dfteil der Aushandlungsprozesse im Artikeltext selbst stattfindet und die Diskussionsseite nur als erg\u00e4nzende Quelle herangezogen werden kann, was Richters Vermutung widerlegt.</p> <p>Yasseri et al. unterst\u00fctzen die Annahme zentraler Unterschiede in sozialr\u00e4umlichen Priorit\u00e4ten, Interessen und Pr\u00e4ferenzen in ihrer 2014er Untersuchung. Sie untersuchten dazu Unterschiede und \u00dcberschneidungen in kontroversen Themen in 12 Sprachversionen der Wikipedia. Dazu analysierten sie die Artikelhistorien und bewerteten insbesondere Reverts, also wiederhergestellte \u00e4ltere Versionen eines Artikels. Hierzu generierten die Autor*innen zun\u00e4chst MD5 Hashes der Artikeltexte und konnten somit Duplikate innerhalb einer Artikelhistorie identifizieren. Sie best\u00e4tigen dabei fr\u00fchere Untersuchungen in der Feststellung, dass die Wikipedia als Werkzeug durchaus unterschiedliche Gruppen von Individuen zusammenbringt, jedoch lokale und kulturelle Charakteristiken keinesfalls ignoriert werden d\u00fcrfen. <sup>40</sup></p> <p>Diese exemplarischen Untersuchungen st\u00fctzen die naheliegende Hypothese, dass die Zusammensetzung der Autor*innengruppen eine relevante Rolle im Meinungsbildungsprozess einnimmt. F\u00fcr zuk\u00fcnftige Untersuchungen gilt es, Methoden zu etablieren, um diese Gruppen besser untersuchen und beschreiben zu k\u00f6nnen.</p>"},{"location":"Kapitel_1.html#124-digitale-werkzeuge","title":"1.2.4 Digitale Werkzeuge","text":"<p>Neben dem Zugang zu Artikeln \u00fcber deren Artikeltext oder der Autor*innenbeteiligung bieten die verwendeten Bilder einen dritten Zugriffsvektor. Bilder haben hierbei den Vorteil, direkt und sprachunabh\u00e4ngig interpretierbar und vergleichbar zu sein. Das Projekt Wikipedia Crosslingual Image Analysis der Digital Methods Initiative Amsterdam greift diesen Ansatz auf und erm\u00f6glicht einen direkten Vergleich verschiedener Sprachversionen eines Artikels anhand der zugeh\u00f6rigen Bilder. <sup>41</sup> Das Tool ist online erreichbar und zeichnet sich durch ein minimalistisches Interface aus. <sup>42</sup></p> <p>Einen quellenkritisch didaktischen Ansatz verfolgt dagegen die Seite Wikibu. <sup>43</sup> Wikibu erweitert das Layout der Wikipedia um eine Seitenleiste, in der anhand von Kennzahlen die Vertrauensw\u00fcrdigkeit des vorliegenden Artikels bewertet wird. Dieser Ansatz dient zwar vorrangig der Sensibilisierung von Sch\u00fclern im Umgang mit der Wikipedia, illustriert dabei jedoch die M\u00f6glichkeiten einer unterst\u00fctzenden automatischen Datenauswertung. <sup>44</sup></p> <p>Mit den XTools steht Forschenden schlie\u00dflich eine ganze Reihe an hilfreichen Statistikauswertungen zur Verf\u00fcgung, die analog zur Wikipedia selbst von Freiwilligen erstellt und gepflegt werden. <sup>45</sup> Eines des gebr\u00e4uchlichsten Tools der Sammlung ist dabei sicherlich die Page History, die eine Vielzahl an statistischen Informationen zu einem Artikel anzeigt und zudem \u00fcber einen Direktlinkt aus der englischen Artikelhistorie aufrufbar ist. <sup>46</sup></p> <p>Der Nutzen der einzelnen Werkzeuge ist je nach Forschungsabsicht nat\u00fcrlich sehr unterschiedlich zu bewerten, jedoch erleichtern sie \u00fcblicherweise einen ersten Einblick in die komplexeren Zusammenh\u00e4nge der Daten. Individuelle Anpassungen oder Eigenentwicklungen sind jedoch naheliegend, wohingegen ein grundlegend methodenkritischer Umgang mit solchen Tools zwingend erforderlich ist.</p> <ol> <li> <p>Siehe Historische Fachinformatik, in: Wikipedia, 05.09.2018. Online: https://de.wikipedia.org/w/index.php?title=Historische_Fachinformatik&amp;oldid=180649364; sowie Digital history, in: Wikipedia, 27.04.2020. Online:https://en.wikipedia.org/w/index.php?title=Digital_history&amp;oldid=953529232. Beiden Artikeln mangelt eszudem an Belegen und Aktivit\u00e4t. Der englische Artikel wurde seit 2008 kaum 350 \u00c4nderungen unterzogen,w\u00e4hrend der bereits 2003 angelegte deutsche Artikel auf nicht einmal 50 \u00c4nderungen kommt. Siehe Digital history - Page History - XTools, https://xtools.wmflabs.org/articleinfo/en.wikipedia.org/Digital_history, Stand: 06.08.2020; sowie Historische Fachinformatik - Page History - XTools, https://xtools.wmflabs.org/articleinfo/de.wikipedia.org/Historische_Fachinformatik, Stand: 06.08.2020.\u00a0\u21a9</p> </li> <li> <p>Vgl. Dogunke, Swantje: Was hei\u00dft \u00bbDigital Humanities\u00ab?, Blog - Klassik Stiftung Weimar, 17.06.2015, https://blog.klassik-stiftung.de/digital-humanities/, Stand: 06.08.2020.\u00a0\u21a9</p> </li> <li> <p>Vgl. Prinz, Claudia; Schlotheuber, Eva; Hohls, R\u00fcdiger: Vorwort der Redaktion, in: Historische Grundwissenschaften und die digitale Herausforderung, Bd. 18, 2016 (Historisches Forum), S. 4 f.\u00a0\u21a9</p> </li> <li> <p>Vgl. Rehbein, Malte: Digitalisierung braucht Historiker/innen, die sie beherrschen, nicht beherrscht, in: Historische Grundwissenschaften und die digitale Herausforderung, Bd. 18, 2016 (Historisches Forum), S. 45\u201351.\u00a0\u21a9</p> </li> <li> <p>Vgl. Krajewski, Markus: Programmieren als Kulturtechnik, in: Historische Grundwissenschaften und die digitale Herausforderung, Bd. 18, 2016 (Historisches Forum), S. 37\u201340.\u00a0\u21a9</p> </li> <li> <p>Vgl. Hiltmann, Torsten: Hilfswissenschaften in Zeiten der Digitalisierung, in: Historische Grundwissenschaften und die digitale Herausforderung, Bd. 18, 2016 (Historisches Forum), S. 79\u201383.\u00a0\u21a9</p> </li> <li> <p>Keupp, Jan: Die digitale Herausforderung: Kein Reservat der Hilfswissenschaften, in: Historische Grundwissenschaften und die digitale Herausforderung, Bd. 18, 2016 (Historisches Forum), S. 89\u201392.\u00a0\u21a9</p> </li> <li> <p>Vgl. Schmale, Wolfgang: Historische Grundwissenschaften international, in: Historische Grundwissenschaften und die digitale Herausforderung, Bd. 18, 2016 (Historisches Forum), S. 23\u201325.\u00a0\u21a9</p> </li> <li> <p>Hafner, Urs: Der Irrtum der Zeitmaschinisten - NZZ, Neue Z\u00fcrcher Zeitung, 27.05.2016, https://www.nzz.ch/feuilleton/zeitgeschehen/digital-history-historiografie-des-zeitpfeils-ld.85000, Stand: 13.06.2020.\u00a0\u21a9</p> </li> <li> <p>Vgl. Schmale: Historische Grundwissenschaften international, 2016, S. 25.\u00a0\u21a9</p> </li> <li> <p>Sahle, Patrick; Henny, Ulrike: Klios Algorithmen: Automatisierte Auswertung von Wikipedia-Inhalten als Faktenbasis und Diskursraum, in: Wozniak, Thomas; Nemitz, J\u00fcrgen; Rohwedder, Uwe (Hg.): Wikipedia und Geschichtswissenschaft, Berlin/Boston 2015, S. 120.\u00a0\u21a9</p> </li> <li> <p>Vgl. ebd.\u00a0\u21a9</p> </li> <li> <p>Siehe Wozniak, Thomas; Nemitz, J\u00fcrgen; Rohwedder, Uwe (Hg.): Wikipedia und Geschichtswissenschaft, Berlin/Boston 2015, S. 257\u2013299. Online: https://doi.org/10.1515/9783110376357.\u00a0\u21a9</p> </li> <li> <p>Vgl. Wozniak, Thomas: Wikipedia in Forschung und Lehre \u2013 eine \u00dcbersicht, in: Wozniak, Thomas; Nemitz, J\u00fcrgen; Rohwedder, Uwe (Hg.): Wikipedia und Geschichtswissenschaft, Berlin/Boston 2015, S. 41 f.\u00a0\u21a9</p> </li> <li> <p>So zum Beispiel die Bibliografie des deutschen Wikipedistik-Projekts, siehe Wikipedia:Wikipedistik/Arbeiten, in: Wikipedia, 19.06.2020. Online: https://de.wikipedia.org/w/index.php?title=Wikipedia:Wikipedistik/Arbeiten&amp;oldid=201125088.\u00a0\u21a9</p> </li> <li> <p>Siehe Research:Index - Meta, https://meta.wikimedia.org/wiki/Research:Index, Stand: 06.07.2020.\u00a0\u21a9</p> </li> <li> <p>Research:Projects - Meta, https://meta.wikimedia.org/w/index.php?title=Research:Projects&amp;oldid=19872838, Stand: 05.07.2020.\u00a0\u21a9</p> </li> <li> <p>Siehe zum Beispiel Wikipedia:Academic studies of Wikipedia, in: Wikipedia, 03.07.2020. Online: https://en.wikipedia.org/w/index.php?title=Wikipedia:Academic_studies_of_Wikipedia&amp;oldid=965824064.\u00a0\u21a9\u21a9</p> </li> <li> <p>Siehe zum Beispiel Wikipedia:Wikipedia as an academic source, in: Wikipedia, 28.11.2018. Online:https://en.wikipedia.org/w/index.php?title=Wikipedia:Wikipedia_as_an_academic_source&amp;oldid=871051852.\u00a0\u21a9\u21a9</p> </li> <li> <p>Siehe Wikipedia:Wikipedistik/Arbeiten, in: Wikipedia, 19.06.2020. Online: https://de.wikipedia.org/w/index.php?title=Wikipedia:Wikipedistik/Arbeiten&amp;oldid=201125088.\u00a0\u21a9</p> </li> <li> <p>Siehe Wikipedia Diskussion:Wikipedistik/Arbeiten, in: Wikipedia, 27.02.2019. Online: https://de.wikipedia.org/w/index.php?title=Wikipedia_Diskussion:Wikipedistik/Arbeiten&amp;oldid=186086510.\u00a0\u21a9</p> </li> <li> <p>Vgl. Wozniak: Wikipedia in Forschung und Lehre \u2013 eine \u00dcbersicht, 2015, S. 41 f.\u00a0\u21a9</p> </li> <li> <p>Siehe auch Fu\u00dfnoten <sup>18</sup> und <sup>19</sup>.\u00a0\u21a9</p> </li> <li> <p>Vgl. Sahle; Henny: Klios Algorithmen: Automatisierte Auswertung von Wikipedia-Inhalten als Faktenbasis und Diskursraum, 2015.\u00a0\u21a9</p> </li> <li> <p>Beispielsweise lassen sich durch widerstreitende L\u00f6schungen und Einf\u00fcgungen R\u00fcckschl\u00fcsse auf einem Artikel zu Grunde liegenden Diskurs ziehen. Diese Methode funktioniert dank der sprachunabh\u00e4ngigen Aussagekraft von Bildern selbst in fremdsprachigen Korpora. Vgl. Krug, Alexandra: Zensur in Bildern. Verlauf der Zensur der chinesischen Wikipedia in den 2010er Jahren in Bildern, in, 28.02.2020. Online:https://github.com/krugbuild/zensur-in-bildern, Stand: 15.03.2020.\u00a0\u21a9</p> </li> <li> <p>Vgl. Sahle; Henny: Klios Algorithmen: Automatisierte Auswertung von Wikipedia-Inhalten als Faktenbasis und Diskursraum, 2015, S. 116 f.\u00a0\u21a9</p> </li> <li> <p>Vgl. ebd., S. 122\u2013136.\u00a0\u21a9</p> </li> <li> <p>Vgl. ebd., S. 136\u2013145.\u00a0\u21a9</p> </li> <li> <p>Vgl. ebd., S. 148.\u00a0\u21a9</p> </li> <li> <p>Die technischen Details der Strukturen Sprachversion und Artikel werden im Kapitel 2.1 Zur Struktur des digitalen Objekts Artikel erl\u00e4utert.\u00a0\u21a9</p> </li> <li> <p>Vgl. Wozniak: Wikipedia in Forschung und Lehre \u2013 eine \u00dcbersicht, 2015, S. 42.\u00a0\u21a9</p> </li> <li> <p>Vgl. Hecht, Brent; Gergle, Darren: The tower of Babel meets web 2.0: user-generated content and its applications in a multilingual context, in: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, Atlanta, Georgia 2010, S. 291\u2013300. Online: https://doi.org/10.1145/1753326.1753370.\u00a0\u21a9</p> </li> <li> <p>Vgl. Richter, Klaus: Wikipedia als Objekt der Nationalismusforschung \u2013 das Beispiel der Stadt Vilnius/Wilno, in: Wozniak, Thomas; Nemitz, J\u00fcrgen; Rohwedder, Uwe (Hg.): Wikipedia und Geschichtswissenschaft, Berlin/Boston 2015, S. 149\u2013154.\u00a0\u21a9</p> </li> <li> <p>Vgl. Kleinke, Sonja; Schultz, Julia: Ist \u201eNation\u201c gleich \u201enation\u201c? Zwei Wikipedia-Artikel im Sprach- und Kulturvergleich, in: Diskurse \u2013 digital 1 (1), 19.02.2019, S. 62\u201397. Online: https://doi.org/10.25521/diskurse-digital.2019.61.\u00a0\u21a9</p> </li> <li> <p>Vgl. Ford, Heather: The Missing Wikipedians, in: Lovink, Geert; Tkacz, Nathaniel (Hg.): Critical Point of View: A Wikipedia Reader, Amsterdam 2011, S. 258\u2013268. Online: https://networkcultures.org/blog/publication/critical-point-of-view-a-wikipedia-reader/.\u00a0\u21a9</p> </li> <li> <p>Vgl. Bilic, Pasko; Bulian, Luka: Lost in Translation: Contexts, Computing, Disputing on Wikipedia, in, Berlin 2014. Online: https://doi.org/10.9776/14027.\u00a0\u21a9</p> </li> <li> <p>Das Modell besagt, dass Wissen und Erinnern sozial bedingt seien und geteilte Interpretationen der Vergangenheit durch kommunikative Prozesse erreicht werden. Darin wird zwischen der Mirkoebene (pers\u00f6nliche Erfahrungen), der Mesoebene (Kommunikation) und der Makroebene (kulturelles Ged\u00e4chtnis) unterschieden.Vgl. Heinrich, Horst-Alfred; Gilowsky, Julia: Wie wird kommunikatives zu kulturellem Ged\u00e4chtnis? Aushandlungsprozesse auf den Wikipedia-Diskussionsseiten am Beispiel der Wei\u00dfen Rose, in: Sebald, Gerd; D\u00f6bler, Marie-Kristin (Hg.): (Digitale) Medien und soziale Ged\u00e4chtnisse, Wiesbaden 2018 (Soziales Ged\u00e4chtnis, Erinnern und Vergessen \u2013 Memory Studies), S. 146 f. Online: https://doi.org/10.1007/978-3-658-19513-7.\u00a0\u21a9</p> </li> <li> <p>Vgl. ebd., S. 145.\u00a0\u21a9</p> </li> <li> <p>Vgl. ebd., S. 163 f.\u00a0\u21a9</p> </li> <li> <p>Vgl. Yasseri, Taha; Speorri, Anselm; Graham, Mark u. a.: The Most Controversial Topics in Wikipedia. A Multilingual and Geographical Aalysis, in: Global Wikipedia: International and Cross-Cultural Issues in Online Collaboration, Lanham 2014, S. 25\u201348. Online: http://arxiv.org/abs/1305.5566.\u00a0\u21a9</p> </li> <li> <p>Vgl. Gredel, Eva: Digitale Diskurse und Wikipedia. Wie das Social Web Interaktion im digitalen Zeitalter verwandelt, T\u00fcbingen 2018, S. 77 f.\u00a0\u21a9</p> </li> <li> <p>Siehe Wikipedia Cross-lingual Image Analysis, DMI Tools, https://tools.digitalmethods.net/beta/wikipediaCrosslingualImageAnalysis/.\u00a0\u21a9</p> </li> <li> <p>Siehe Wikibu, https://www.wikibu.ch/index.php.\u00a0\u21a9</p> </li> <li> <p>Vgl. Gredel: Digitale Diskurse und Wikipedia. Wie das Social Web Interaktion im digitalen Zeitalter verwandelt, 2018, S. 83\u201385.\u00a0\u21a9</p> </li> <li> <p>Siehe XTools, https://xtools.wmflabs.org/ ; sowie Welcome to XTools! \u2014 XTools 3.10.16 documentation, https://xtools.readthedocs.io/en/stable/.\u00a0\u21a9</p> </li> <li> <p>Siehe Page History - XTools, https://xtools.wmflabs.org/articleinfo ; sowie 1.2. Page History \u2014 XTools 3.10.16 documentation, https://xtools.readthedocs.io/en/stable/tools/articleinfo.html#articleinfo.\u00a0\u21a9</p> </li> </ol>"},{"location":"Kapitel_2.html","title":"Kapitel 2 - Ans\u00e4tze einer digitalen Quellenkritik","text":"<p>Die vorgestellten Untersuchungen und Projekte vermitteln einen fl\u00fcchtigen Einblick in die M\u00f6glichkeiten des Quellenmaterials sowie einen groben \u00dcberblick \u00fcber die bisherige Forschung. Hierbei f\u00e4llt auf, dass sich nur sehr wenige historiografische Ans\u00e4tze und Methoden in den Bibliografien und Projektverzeichnissen wiederfinden. Das ist im besonderen Ma\u00dfe entt\u00e4uschend, da viele Untersuchungen voraussichtlich von einem kritischeren Umgang mit dem Quellenmaterial profitieren w\u00fcrden \u2013 einem zentralen Merkmal der historisch-kritischen Methode. Bisher mangelt es jedoch trotz diverser Aufrufe noch an etablierten Ans\u00e4tzen einer historischen Quellenkritik genuin digitaler Objekte, wie sie in der Wikipedia anzutreffen sind. <sup>1</sup></p> <p>Eine Grundlage f\u00fcr diesen notwendigen Diskurs hat F\u00f6hr 2018 mit seiner Dissertation zur Historischen Quellenkritik im Digitalen Zeitalter geschaffen. <sup>2</sup> Darin bietet er einen breiten \u00dcberblick \u00fcber verschiedene Probleme beim Wechsel von klassischen hin zu digitalen Quellen. Er bietet eine grundlegende Charakterisierung digitaler Quellen an, die auch als Grundlage f\u00fcr die folgenden Kapitel dienen soll. Hierzu verwendet er den Begriff des digitalen Objekts als Sammelbegriff f\u00fcr alle als Quellen geeigneten Strukturen, die aus digitalen Daten best\u00fcnden und somit nur mittels eines Ausgabeger\u00e4ts wahrgenommen werden k\u00f6nnten. Daten, die auf unterster Ebene als Bin\u00e4rcode vorl\u00e4gen, seien hierbei als die kleinsten Elemente eines Wertebereichs zu verstehen und w\u00fcrden erst durch die Verarbeitung und Kontextualisierung zu Informationstr\u00e4gern. <sup>3</sup> Daten, die wiederum der Beschreibung anderer Daten dienten, seien als als Metadaten zu bezeichnen. <sup>4</sup> Durch sie k\u00f6nnen Teile eines digitalen Objekts in einen gemeinsamen Kontext gesetzt sowie dem Objekt selbst weitere Informationen zugeordnet werden. <sup>5</sup> W\u00e4hrend die im zuvor dokumentierten Diskurs h\u00e4ufig erw\u00e4hnten Retrodigitalisate Abbilder eines physischen Objekts im digitalen Raum sind, m\u00fcssten genuin digitale Artefakte jedoch als inh\u00e4rent digital verstanden werden und k\u00f6nnten folglich nicht aus dem digitalen Raum gel\u00f6st werden. Erst durch das Zusammenspiel von Daten, Wiedergabeger\u00e4t und den m\u00f6glicherweise multiplen Darstellungsformen dieser Daten erg\u00e4be sich das eigentliche digitale Objekt. <sup>6</sup> Somit k\u00f6nnten digitale Objekte zwar nicht von ihrer Darstellung getrennt werden, jedoch bewirke ihre elektrische Speicherung in bin\u00e4rer Codierung, dass sie als datentr\u00e4gerunabh\u00e4ngig zu betrachten seien. <sup>7</sup> Im Gegensatz zu physischen Artefakten spiele Abnutzung bei ihnen keine Rolle und durch ihren codierten und fl\u00fcchtigen Zustand w\u00e4re eine Kopie stets ein perfekter Klon. <sup>8</sup> F\u00f6hr fasst die Eigenheiten dieser Quellenart wie folgt zusammen:</p> <p>Digitale Objekte unterscheiden sich von bisher bekannten Objekten durch die ausschliessliche Digitalit\u00e4t, die verlustfreie und fehlerfreie Vervielf\u00e4ltig- und Wiederverwendbarkeit, die nicht nachvollziehbare Manipulation sowie dadurch, dass sie zwingend auf ein spezifisches, digitales Informationssystem angewiesen sind. <sup>9</sup></p> <p>Aus diesen Eigenheiten folgt jedoch, dass die traditionelle historische Quellenkritik an vielen Stellen als ungeeignet zur Bewertung eines digitalen Objektes betrachtet werden muss, wof\u00fcr insbesondere die fehlende K\u00f6rperlichkeit verantwortlich ist. Weiterhin gilt dies f\u00fcr die Metadaten, die folglich dieselben Probleme aufweisen.</p> <p>Im Anbetracht der Dringlichkeit des Themas bleibt F\u00f6hr mit seinen Ausf\u00fchrungen zur Quellenkritik jedoch sehr vage und formuliert eher eine allgemeing\u00fcltige N\u00e4herung zum Thema, als einen direkt umzusetzenden Leitfaden. Dass es schwerlich ein einzelnes Handbuch zum Umgang mit digitalen Quellen geben kann, zumindest zu diesem Zeitpunkt in der Entwicklung der Digital History, wird beim Vergleich mit anderen Quellenarten offenbar. Der Unterschied zwischen digitalen und herk\u00f6mmlichen Quellen entspricht hierbei eher dem Unterschied zwischen epochalen Fachbereichen, als jenem zwischen einzelnen Hilfswissenschaften. Es existieren also durchaus Parallelen, jedoch sind die Unterschiede zwischen einzelnen Quellenarten dergestalt, dass sie jeweils eigene Herangehensweisen verlangen. An eine auch nur ann\u00e4hernd vollst\u00e4ndige Erfassung aller spezifischen Quellenarten innerhalb der Gruppe der digitalen Quellen ist mit dem heutigen Forschungsstand kaum zu denken. <sup>10</sup> Entsprechend wird sich die Digital History zuk\u00fcnftig immer wieder mit neuen genuin digitalen Quellengattungen auseinandersetzen m\u00fcssen.</p> <p>Die hiesige Untersuchung n\u00e4hert sich dem Ziel einer Quellenkritik genuin digitaler Daten daher \u00fcber einen definierten Quellenbestand. Ausgehend von den Erkenntnissen aus der Wikipedistik wird im Folgenden eine historische Quellenkritik der Wikipedia diskutiert und anschlie\u00dfend exemplarisch durchgef\u00fchrt.</p>"},{"location":"Kapitel_2.html#21-zur-struktur-des-digitalen-objekts-artikel","title":"2.1 Zur Struktur des digitalen Objekts Artikel","text":"<p>Um die Theorie dem Untersuchungsgegenstand anzun\u00e4hern, muss zun\u00e4chst der Begriff des digitalen Objekts im vorliegenden Forschungs- und Quellenkontext gekl\u00e4rt sowie dessen Ausma\u00dfe definiert werden. Diese Untersuchung und Diskussion orientiert sich hierbei zun\u00e4chst an spezifischen Artikeln der Wikipedia. Von diesen ausgehend, kann anschlie\u00dfend die Definition funktionell erweitert werden. Selbstverst\u00e4ndlich kann eine derartige Definition je nach Methodik und Fragestellung auch unter Verwendung des selben Quellenkorpus anders ausfallen.</p> <p>\u00dcblicherweise wird unter dem Begriff Wikipedia Artikel ein HTML-Dokument verstanden, das nach einer Stichwortsuche zu einem beliebigen Thema von der soeben verwendeten Suchmaschine angeboten wird. Diese Vorstellung entspringt jedoch dem Umgang mit gedruckten Lexika, bei denen der Text eines Lemmas bereits das vollst\u00e4ndige lexikalische Objekt darstellt. Die digitalen Objekte, die wir als Artikel bezeichnen, sind jedoch weitaus komplexer und Umfangreicher, als ihre gedruckten Vorbilder. Im Vergleich mit klassischen Quellen erinnern sie dabei eher an einen Kodex als an ein einzelnes Diplom. Denn \u00e4hnlich dem Kodex fassen die Artikel verschiedene Objekte und Strukturen unter einem Thema zusammen, wobei die Bearbeitung einzelner Teile unterschiedliche Methoden erfordern kann und somit auch der Aussagegehalt variiert. Dementsprechend ist es n\u00f6tig, diese Objekte zun\u00e4chst in ihre Bestandteile zu zerlegen und die einzelnen Teile auf ihre Funktion innerhalb einer Untersuchung hin zu bewerten.</p> <p>In Anbetracht der Hypertextualit\u00e4t der Objekte, eine Eigenschaft fast aller Webdokumente, droht ein solches Vorhaben schnell zu eskalieren, da \u00fcber Querverweise zwischen Artikeln sowie \u00fcber Kategorisierungen vielfach ineinander verschachtelte Strukturen entstehen k\u00f6nnen. Diese Eigenschaften bewusst ausklammernd, beschr\u00e4nken wir uns zun\u00e4chst auf die technisch notwendigen Bestandteile einer einzelnen Instanz dieses Objekttyps. Dies dient der Vereinheitlichung und Vereinfachung der folgenden Quellendiskussion.</p> <p>Die oberste Ebene eines Wikipedia Artikels bildet die Zugeh\u00f6rigkeit zu einer Sprachversion. S\u00e4mtliche Seiten der Wikipedia existieren stets explizit im Namensraum einer einzigen Sprachversion, folglich sind s\u00e4mtliche Sprachversionen der Wikipedia relativ unabh\u00e4ngige Instanzen, die jedoch durch Hyperlinks semantisch miteinander verbunden sind. Die Links in der Seitenliste unter dem Abschnitt In anderen Sprachen verweisen somit auf sinnverwandte Artikel in anderen Sprachversionen, die dem aktuellen Artikel explizit zugeordnet wurden. Diese Zuordnung wird \u00fcber Normdaten des Projekts Wikidata gesteuert. <sup>11</sup></p> <p>Das Objekt Artikel im Kontext Sprachversion selbst ist wiederum zweigeteilt. Zentral f\u00fcr die allt\u00e4gliche Benutzung ist die Inhaltsseite, die mit dem Reiter Artikel betitelt wird. Die Artikelseite stellt dabei die jeweils aktuelle, bzw. die aktuell freigegebene Artikelversion dar. Neben dem Reiter Artikel f\u00fchrt der Reiter Diskussion auf die zum Artikel geh\u00f6rende Diskussionsseite. Diese ist mit dem vorangestellten Zusatz \u201aDiskussion:\u2018 vor dem Artikeltitel \u00fcberschrieben und bietet einen Raum zur Diskussion von geplanten \u00c4nderungen oder umstrittenen Aspekten des Artikels. Diese Zweiteilung der Inhaltsseiten ist eine Kernfunktion der MediaWiki-Software und findet sich deshalb auf praktisch allen Inhaltsseiten der Wikipedia. <sup>12</sup></p> <p></p> <p><code>Abbildung 1: Titelleiste und Reiter der englischsprachigen Wikipedia.</code></p> <p>Eine weitere Kernfunktion ist die Versionierung von \u00c4nderungen. Sowohl f\u00fcr die Artikelseite, als auch die Diskussionsseite ist diese \u00fcber den Reiter Versionsgeschichte zu erreichen. Die Versionsgeschichte ist im Gegensatz zu den Inhaltsseiten Artikel oder Diskussion eine automatisch erzeugte Seite. Algorithmisch von der Software angelegt und aktualisiert, kann diese von Usern nicht bearbeitet werden. <sup>13</sup> Die verantwortlichen Algorithmen basieren auf einer append-only-Logik, bei der s\u00e4mtliche \u00c4nderungen am Text in einer neuen Kopie des Textes ver\u00f6ffentlicht werden, w\u00e4hrend die alte Version, so wie alle vorangegangenen, mitsamt Metadaten zur Bearbeitung gespeichert werden. Diese Artikel\u00adhistorien dienen \u00fcblicherweise der Nachvollziehbarkeit von \u00c4nderungen im editorischen Prozess und somit unter Anderem der Korrektur von Vandalismus. <sup>14</sup> Im Rahmen einer geschichtswissenschaftlichen Herangehensweise erm\u00f6glichen sie zudem den Zugriff auf die vollst\u00e4ndige Entwicklungsgeschichte eines Artikels. Zus\u00e4tzlich zu den einzelnen Artikelversionen werden dort die jeweils verantwortlichen User, der Zeitpunkt der \u00c4nderung und neben einigen technischen Details auch ein Kommentar zu den vorgenommenen \u00c4nderungen aufgelistet.</p> <p>ie Auslagerung der Versionsgeschichte in einen separaten Reiter suggeriert hierbei eine Unterordnung der \u00e4lteren Versionen gegen\u00fcber dem aktuellen Artikeltext. Dieses Design ist nat\u00fcrlich auf die eigentlichen Anwendungsf\u00e4lle, \u00fcblicherweise der niedrigschwellige Zugriff auf lexikalische Inhalte, ausgerichtet und sollte nicht von der tats\u00e4chlichen technischen Struktur des digitalen Objekts ablenken. Weiterhin ist der initial angezeigte Artikeltext f\u00fcr unsere Herangehensweise als gleichwertig zu allen anderen unter Versionsgeschichte aufgelisteten Artikelversionen zu verstehen. Eine endg\u00fcltige Bewertung der Relevanz einzelner Artikelversionen f\u00fcr eine Untersuchung kann erst nach einer zeitlichen Eingrenzung des Untersuchungsgegenstandes und unter Betrachtung der vorliegenden Metadaten erfolgen. </p> <p>Zusammenfassend muss ein Wikipediaartikel also als komplexes digitales Objekt verstanden werden. Ein solches Objekt besteht aus mindestens einer Sprachversion, f\u00fcr die jeweils sowohl eine Liste an Artikeltextversionen als auch Diskussionstextversionen vorliegt. Jeder Textversion sind zudem weitere Metadaten zugeordnet. Diese Struktur l\u00e4sst sich regelm\u00e4\u00dfig auf verschiedene Seitentypen eines Mediawikis (Projekte, Benutzer, etc.) \u00fcbertragen.<sup>15</sup></p>"},{"location":"Kapitel_2.html#22-kritik-digitaler-prozesse","title":"2.2 Kritik digitaler Prozesse","text":"<p>Dem nun bekannten digitalen Objekt Wikipediaartikel sind einige Informationen inh\u00e4rent w\u00e4hrend andere als Metadaten bestimmte Teile des Objekts beschreiben. So kennen wir zum Beispiel die einzelnen Artikeltexte und zudem das jeweils zugeh\u00f6rige Datum der Ver\u00f6ffentlichung. Diese Informationen sind f\u00fcr folgende Auswertungen n\u00fctzlich, das digitale Objekt selbst beschreiben sie jedoch nicht, sondern eben nur Teile, beziehungsweise deren Inhalte. Eine herk\u00f6mmliche \u00e4u\u00dfere Quellenkritik ist somit schwerlich m\u00f6glich. So ist zum Beispiel eine Pr\u00fcfung der Echtheit im Sinne der Originalit\u00e4t des Objekts bei derart ideal kopierbaren Objekten praktisch nicht durchf\u00fchrbar. <sup>16</sup></p> <p>Je nach digitalem Objekt k\u00f6nnen Metadaten hilfreiche Informationen liefern. So beinhalten Digitalfotografien \u00fcblicherweise Exif-Informationen, die Hinweise auf die verwendete Kamera oder den Zeitpunkt der Aufnahme geben k\u00f6nnen. <sup>17</sup> Dokumente im XML-Format k\u00f6nnten Kommentare im Plaintext aufweisen oder Hinweise auf XSLT-Schemata enthalten, die wiederum Informationen zur Genese des vorliegenden digitalen Objekts liefern k\u00f6nnten. Digitale Akten enthalten m\u00f6glicherweise Hinweise auf fr\u00fchere Datenmigrationen, ein weiterer Prozess, der betrachtet werden sollte. <sup>18</sup> Diese Herangehensweisen sind streng genommen jedoch ebenfalls der inneren Quellenkritik zuzurechnen. All diese Informationen k\u00f6nnen mit relativ trivialen Mitteln manipuliert werden, was dank der Eigenheiten digitaler Objekte praktisch nicht nachvollziehbar ist. <sup>19</sup> Selbst vermeintlich klare Identifikatoren wie Dateiendungen sind nichts weiter als vage Empfehlungen an das Betriebssystem, wie die vorliegenden Daten zu interpretiert sind.</p> <p>Eine besondere Stellung nehmen hingegen kryptografische Signaturverfahren ein. Mittels Hashes, qualifizierter Signaturen und asynchronen Verschl\u00fcsselungsverfahren werden insbesondere in Archiven abgeschlossene Datenbest\u00e4nde derart archiviert, dass eine Feststellung der Authentizit\u00e4t und Integrit\u00e4t der Daten gew\u00e4hrleistet und \u00fcberpr\u00fcft werden kann. <sup>20</sup> Da sich diese Verfahren jedoch bislang auf abgeschlossene Datens\u00e4tze beschr\u00e4nken, und au\u00dferhalb solcher Einrichtungen kaum anzutreffen sind, legen Archive vermehrt ihre Prozesse zur Archivierung und Datensicherung offen. <sup>21</sup> Dieser Prozessfokus k\u00f6nnte auch im Rahmen einer historischen Quellenkritik zielf\u00fchrend sein.</p> <p>Digitale Objekte sind zwangsl\u00e4ufig stets das Ergebnis angewandter Algorithmen, weshalb sich ihre Form aus zuvor definierten Prozessen ergibt. Der Text dieser Arbeit zum Beispiel wird von LibreOffice in einer XML-konformen Struktur gesichert und mitsamt der verwendeten Abbildungen in einem Container mit der Endung .odt abgelegt. Zwar sind anschlie\u00dfende Manipulationen auf der Bitebene nicht zu erkennen, jedoch k\u00f6nnen wir den Prozess der Erzeugung der Datei untersuchen. Somit k\u00f6nnten Abweichungen von der angenommenen Funktion einer Software identifiziert werden und unter Umst\u00e4nden sogar Auff\u00e4lligkeiten des Zustands eines digitalen Objektes, wenn es nicht dem zu erwarteten Zustand gem\u00e4\u00df Funktionsanalyse entspricht. Diese Herangehensweise l\u00e4sst sich prinzipiell auf alle digitalen Objekte \u00fcbertragen. Das Foto einer Digitalkamera wird ebenso algorithmisch erzeugt, wie eine gerenderte Videosequenz oder eine Tonaufnahme. Die von F\u00f6hr dargelegte Problematik bleibt hierbei zwar bestehen, das digitale Objekt selbst l\u00e4sst sich nicht auf dessen Vergangenheit untersuchen, aber durch den Abgleich mit dessen algorithmischer Genese lie\u00dfen sich m\u00f6glicherweise bedeutungsvolle R\u00fcckschl\u00fcsse auf den Untersuchungsgegenstand ziehen.</p> <p>Hierbei zeigen sich aber schnell diverse Herausforderungen. Zun\u00e4chst ist dabei die Zug\u00e4nglichkeit zum Quellcode der verwendeten Software zu nennen. Im oben angef\u00fchrten Beispiel handelt es sich um ein open source Projekt, weshalb der Quellcode jederzeit \u00f6ffentlich einsehbar ist. <sup>22</sup> Eine Pr\u00fcfung der Implementation einzelner Funktionen w\u00e4re hier somit m\u00f6glich. Da ein Gro\u00dfteil der h\u00e4ufig verwendeten Software jedoch nicht so transparent zur Verf\u00fcgung steht, kommt dieser Ansatz nur f\u00fcr einen Teil der digitalen Objekte in Frage. Weiterhin erfordert eine solche Analyse ein tiefgehendes Wissen in der Softwareentwicklung sowie der verwendeten Programmiersprachen und -muster. Zudem k\u00f6nnen je nach Art des digitalen Objekts verschiedene Systeme an dessen Genese beteiligt sein, wodurch die Komplexit\u00e4t einer entsprechenden Analyse stark w\u00e4chst.</p> <p>Mit diesem Ansatz begeben wir uns in den Bereich des Softwaretestings, dessen Ziel das \u00dcberpr\u00fcfen der Funktionalit\u00e4t von Programmen auf Grundlage der definierten Anforderungen ist. Vereinfacht k\u00f6nnen Testverfahren in statische und dynamische Methoden unterschieden werden. Mit statischen Analysen sind dabei insbesondere Audits des Quellcodes eines Programms gemeint, bei dem die Software selbst nicht ausgef\u00fchrt wird. Die Interpretation des Quellcodes wird hierbei durch die auditierende Person selbst durchgef\u00fchrt, wobei eine vollst\u00e4ndige Quellcodedokumentation sowie eine vorliegende Funktionsspezifikation wichtige Voraus\u00adsetzungen darstellen. Es wird hierbei versucht, die Designentscheidungen zur Implementation der geforderten Funktionen nachzuvollziehen und offensichtliche Fehler im Design zu erkennen. Gebr\u00e4uchlicher und effektiver sind jedoch dynamische Testverfahren. Diese zielen darauf ab, m\u00f6glichst realistische Laufzeitumgebungen zu schaffen und die Software selbst mittels definierter Testf\u00e4lle auf eine korrekte Funktion zu pr\u00fcfen. Derartige Verfahren beziehen auch Wechselwirkungen der Systeme mit anderen Softwarekomponenten mit ein und versprechen daher eine h\u00f6here Trefferquote. Gleichwohl erg\u00e4nzen sich beide Ans\u00e4tze \u00fcblicherweise, da die statische Quellcodeanalyse eine strukturierte Pr\u00fcfung der Implementation selbst erlaubt, w\u00e4hrend dynamische Tests als Black-Box-Verfahren ohne genaue Kenntnis der internen Prozesse nur die Ergebnisse validieren k\u00f6nnen, nicht jedoch deren Zustandekommen.</p> <p>Im Kontext einer Quellenkritik m\u00fcssen diese Verfahren jedoch neu bewertet werden. Dem Fokus auf dem digitalen Objekt entsprechend erscheinen dynamische Methoden zun\u00e4chst vielversprechender. Sowohl die historische Quellenkritik als auch dynamische Tests orientieren sich am Ergebnis, also dem Zustand des digitalen Objektes selbst. Sie pr\u00fcfen dabei die \u00dcbereinstimmung mit einem Erwartungswert, bzw. verstehen Abweichungen davon als Indikatoren f\u00fcr Manipulationen. Weiterhin sind dynamische Verfahren an der realen Implementation der Software orientiert, die im Wechselspiel mit anderen Systemen arbeitet und daher mit Wechselwirkungen gerechnet werden muss. Jedoch sind solche Tests aufwendig, insbesondere im Fall von webbasierten Systemen. Im Falle von Wikipediaartikeln m\u00fcssten daher sowohl die Datenbank, das Serverbetriebssystem, der Webserver sowie die MediaWiki-Software selbst beachtet werden, zumindest in einem idealisierten Fall. Dem Anspruch einer m\u00f6glichst realit\u00e4tsnahen Umgebung folgend, m\u00fcssten hier zudem verteilte Services, Loadbalancing und weitere Technologien mit in Betracht gezogen werden, die seitens Wikipedia h\u00f6chstwahrscheinlich zur Sicherung der Performanz und Stabilit\u00e4t zum Einsatz kommen. Ein solch komplexes System f\u00fcr eine historische Quellenkritik nachzubilden erscheint jedoch schwerlich angemessen.</p> <p>Sehr viel einfacher zu implementieren w\u00e4re dagegen eine statische Quellcodeanalyse. Den Abstrichen in Hinblick auf m\u00f6gliche Wechselwirkungen mit anderen Systemen steht eine nach wie vor fundierte Bewertung der Kernfunktionalit\u00e4t gegen\u00fcber, f\u00fcr die keine umfangreiche IT-Infrastruktur aufgebaut werden m\u00fcsste. Gleichwohl erfordert auch dieses Verfahren vertiefte Kenntnisse der Forschenden in den Bereichen Softwareentwicklung und Testing.</p> <p>Sowohl eine Alternative als auch Erg\u00e4nzung zu beiden Verfahren stellen Bugtracker dar. Solche Systeme sind im Prinzip Datenbanken, in denen Strukturiert Fehlerberichte zu Software eingetragen werden k\u00f6nnen und die einen formalisierten Arbeitsablauf f\u00fcr diese Fehlerberichte vorsehen. H\u00e4ufig haben derartige Systeme auch \u00f6ffentlich zug\u00e4ngliche Portale, damit auch f\u00fcr ansonsten geschlossene Software seitens der User Fehler gemeldet werden k\u00f6nnen. Das oben erw\u00e4hnte LibreOffice nutzt f\u00fcr diese Zwecke zum Beispiel eine Bugzilla-Instanz, w\u00e4hrend MediaWiki das eigene Portal Phabricator benutzt. <sup>23</sup> Diese Systeme erm\u00f6glichen eine strukturierte Suche nach Auff\u00e4lligkeiten in zu untersuchenden Funktionen.</p> <p>Die Wahl der angewandten Mittel muss je nach Quellengegenstand, Fragestellung, technischer Expertise der Forschenden sowie in Abw\u00e4gung von erwartetem Nutzen und Aufwand getroffen werden. So ist davon auszugehen, dass nur die wenigsten Untersuchungen von einem komplexen dynamischen Testszenario profitieren w\u00fcrden, wohingegen eine kurze Konsultation \u00f6ffentlicher Bugtracker auch bei kleineren Untersuchungen zu einem besseren Verst\u00e4ndnis der Quellen sowie zu einer ansonsten schwerlich zu generierenden Sicherheit im Umgang mit den digitalen Objekten beitragen w\u00fcrde.</p>"},{"location":"Kapitel_2.html#23-quellensicherung","title":"2.3 Quellensicherung","text":"<p>Diese kritische Evaluation der Prozesse muss selbstverst\u00e4ndlich ebenfalls auf die zwangs\u00adl\u00e4ufige Verarbeitung der digitalen Objekte im Rahmen einer Untersuchung angewendet werden. Die Verarbeitung beginnt bereits bei der Betrachtung der digitalen Objekte, insbesondere bei online vorliegenden Quellen. Bereits beim Aufruf werden diese kopiert, \u00fcbertragen und anschlie\u00dfend im Arbeitsspeicher des vom Forschenden benutzten Computers zwischengespeichert. <sup>24</sup> Untersuchungen behandeln somit stets lokale Kopien der Datens\u00e4tze und nicht die Datens\u00e4tze selbst, was prinzipiell dank der Datentr\u00e4gerunabh\u00e4ngigkeit kein Problem darstellen sollte. Weiterhin ist Volatilit\u00e4t eine zentrale Eigenheit digitaler Quellen. Dies trifft im Besonderen Ma\u00dfe erneut auf Online-Quellen zu, wie zum Beispiel Webseiten aber auch die Wikipedia. Zwar verwendet das MediaWiki ein robustes System, um Revisions\u00adsicherheit und Verf\u00fcgbarkeit zu gew\u00e4hrleisten, jedoch unterliegen die Server selbst vermutlich keiner Archivierung im klassischen Sinn, wie wir sie bei Papierakten erwarten w\u00fcrden. <sup>25</sup> Manipulationen oder Defekte auf Dateisystemebene sind technisch vorstellbar und das Ende der Wikipedia als Projekt darf auch nicht ausgeschlossen werden. Folglich erscheint F\u00f6hrs Forderungen nach einer Quellensicherung auch f\u00fcr digitale Objekte, unter Ber\u00fccksichtigung ihrer Spezifika und der Problematik der Langzeitarchivierung im Digitalen, als absolute Notwendigkeit der digitalhistorischen Arbeit. <sup>26</sup></p> <p>Die daraus folgende Frage ist: was wird wie von wem zu welchem Zweck gespeichert? Eine vollst\u00e4ndige Sicherung von digitalen Objekten wird sp\u00e4testens dann zu einem Problem, wenn Hyperlinks ins Spiel kommen. Zur Sicherstellung der Konsistenz eines Objektes m\u00fcssen auch dessen Abh\u00e4ngigkeiten \u00fcberpr\u00fcft und unter Umst\u00e4nden mit in die Sicherung aufgenommen werden. Im Falle von abgeschlossenen Objekten wie zum Beispiel einem Film auf einer BlueRay, beschr\u00e4nken sich die assoziierten Objekte h\u00f6chstwahrscheinlich auf zus\u00e4tzliche Tonspuren, Videos und die zum Abspielen notwendige Software. Derartige Objekte sind also gut kapselbar. Im Falle von Web-Dokumenten mit Hyperlinks, wie im vorliegenden Fall, wird diese Abgrenzung sehr viel problematischer. Davon ausgehend, dass Links als kulturelle Assoziationen verstanden werden k\u00f6nnen, m\u00fcssen diese verkn\u00fcpften Objekte ebenfalls im Rahmen der Quellensicherung evaluiert werden. <sup>27</sup> Dabei m\u00fcsste f\u00fcr jedes Objekt fallbezogen entschieden werden, welche verkn\u00fcpften Objekte mit einbezogen werden und in welcher Tiefe. In einem Wikipediaartikel ist dies eine offenkundige Herausforderung, da umfangreiche Artikel regelm\u00e4\u00dfig thematisch aufgeteilt werden, um die \u00dcbersicht und Pflegbarkeit zu wahren. F\u00fcr die Untersuchung sowie Quellensicherung ist dementsprechend festzulegen, welche verlinkten Artikel zus\u00e4tzlich und in gleicher Weise betrachtet werden m\u00fcssen.</p> <p>Ein weiteres Problem stellt die individualisierte Pr\u00e4sentation digitaler Objekte dar. Insbesondere Webseiten binden h\u00e4ufig Nebeninhalte Dritter ein, zum Beispiel Werbung, die den eigentlichen Inhalt in einen bestimmten Kontext stellen. Da derartige Elemente jedoch nutzergebunden sind und keine fixe Verkn\u00fcpfung mit dem eigentlichen digitalen Objekt aufweisen, w\u00e4re hier der genaue Umgang mit diesen Inhalten fallbezogen zu kl\u00e4ren. Ein zus\u00e4tzliches Problem findet sich in der Darstellung von Webinhalten selbst. Diese ist zwangsl\u00e4ufig abh\u00e4ngig von der verwendeten Software und Hardware und variiert ebenso, wie die zuvor erw\u00e4hnten Nebeninhalte. Die Umsetzbarkeit einer vollst\u00e4ndigen Objektsicherung ist somit stark vom betrachteten digitalen Objekt abh\u00e4ngig und h\u00e4ufig wohl ausgeschlossen.</p> <p>Wenn eine vollst\u00e4ndige Objektsicherung h\u00e4ufig nicht erreicht werden kann und eine simple Textsicherung nicht ausreicht, muss zur Sicherstellung der Falsifizierbarkeit ein Mittelweg gew\u00e4hlt werden. Die Speicherung nur der f\u00fcr die durchgef\u00fchrte Forschung relevanten Daten durch die Forschenden selbst erscheint hier als naheliegende L\u00f6sung. Nach F\u00f6hr solle dieses Research Driven Archiving (RDA) insbesondere die Bed\u00fcrfnisse von selbstst\u00e4ndig Forschenden erf\u00fcllen und damit gleichzeitig verschiedenste Quellenarten abdecken k\u00f6nnen. <sup>28</sup> Diese pragmatische Sicherung der Arbeitsdaten k\u00f6nnte zudem Open Science Ans\u00e4tze erg\u00e4nzen, da somit von der bearbeiteten Quelle bis zur finalen Auswertung der Forschungsprozess nachvollziehbar gestaltet wird.</p> <p>Die Schwierigkeit des Umgangs mit sowie die grundlegende Problematik der Definition historischer Forschungsdaten zeigt sich weiterhin in der Erkl\u00e4rung des geschichts\u00adwissenschaftlichen Konsortiums NFDI4Memory:</p> <p>With a few promising exceptions, there is still no commonly established consensus within historically engaged disciplines about on what historical \u201cresearch data\u201d actually means, and discussions are continuing on how such data should be generated, standardized, integrated, stored, re-used, and published. <sup>29</sup></p>"},{"location":"Kapitel_2.html#24-akteure","title":"2.4 Akteure","text":"<p>Horizont und Tendenz der Autor*innen einer Quelle sind auch bei digitalen Objekten zentrale Ansatzpunkte einer inneren Quellenkritik und stehen folglich im Fokus dieser Untersuchung. Die Verantwortlichkeit f\u00fcr ein bestimmtes Objekt l\u00e4sst sich hierbei zwar h\u00e4ufig den Metadaten entnehmen, jedoch ist das Konzept der Urheberschaft nicht zwangsl\u00e4ufig auf alle digitalen Objekte \u00fcbertragbar, nicht deckungsgleich mit dem Ersteller des spezifischen Datensatzes oder aber schlichtweg nicht zu bestimmen. Anonyme Datens\u00e4tze sowie der Umgang mit algorithmisch generierten Inhalten sind insbesondere f\u00fcr die weitere digitalhistorische Forschung zentrale Problemfelder, jedoch behandelt die vorliegende Untersuchung ein anderes Ph\u00e4nomen: die kollaborative Autorschaft. Zwar sind die Autor*innen eines Wikipediaartikels klar benannt und jede \u00c4nderung wird detailliert protokolliert, doch sind bei n\u00e4herer Betrachtung die User nicht mit den Autor*innen im quellenkritischen Sinn gleichzusetzen. Insbesondere die Pseudonymit\u00e4t oder Anonymit\u00e4t der User sowie der kollaborative Schreibprozess erschwert die Identifikation von und Zuweisung von Verantwortung zu einzelnen Individuen. Zum besseren Verst\u00e4ndnis der Problematik sowie zur Erarbeitung eines L\u00f6sungsansatzes werden im Folgenden verschiedene Problemfelder betrachtet. Zun\u00e4chst wird hierbei die Herausforderung der Bestimmung von Verantwortlichen am verwandten Problemfeld der Zitierbarkeit diskutiert, anschlie\u00dfend wird das Verh\u00e4ltnis von Anonymit\u00e4t und Identit\u00e4t beleuchtet und schlie\u00dflich ein L\u00f6sungsansatz mittels Netzwerkanalysen vorgestellt.</p>"},{"location":"Kapitel_2.html#241-urheberschaft-gemeinschaft-und-zitierfahigkeit","title":"2.4.1 Urheberschaft, Gemeinschaft und Zitierf\u00e4higkeit","text":"<p>Die Herausforderung der Zuordnung von Verantwortlichkeit bei kollaborativ erzeugten Texten findet sich auch im Diskurs im die Zitierf\u00e4higkeit der Wikipedia im schulischen oder akademischen Kontext wieder. Die zentralen Probleme sind hierbei die bef\u00fcrchtete Fl\u00fcchtigkeit der Artikelinhalte, also \u00c4nderungen oder L\u00f6schungen nach einer Sichtung, sowie die fehlende personelle Verantwortlichkeit f\u00fcr Inhalte.</p> <p></p> <p><code>Abbildung 2: Werkzeugleiste in der deutschsprachigen Wikipedia.</code></p> <p>Der Wunsch nach einem Verweis auf einen unver\u00e4nderlichen Artikeltext kann hierbei als vorrangig technische Heraus\u00adforderung verstanden werden, die jedoch problemlos mit vorhanden Funktionen zu erf\u00fcllen ist. Zwar wird beim Aufruf eines Artikels \u00fcblicherweise die jeweils aktuellste, oder ggf. die letzte gesichtete, Version aufgerufen, jedoch kann mittels permanenter Links direkt auf eine bestimmte Artikelversion verwiesen werden. Diese Links enthalten dazu einen eindeutigen Identifikator der anzuzeigenden Artikelversion, wodurch ein manueller Abgleich erm\u00f6glicht wird. <sup>30</sup> Diese Funktion ist von jedem Artikel aus \u00fcber die Werkzeugleiste auf der linken Seite zug\u00e4nglich. (Siehe Abbildung 2) Die Funktion Artikel zitieren geht noch einen Schritt weiter und bietet eine vorformatierte Referenz inklusive permanentem Link zum Kopieren an. Eine eindeutige Referenz zu einer unver\u00e4nderlichen Version des zu zitierenden Artikels anzugeben, sollte somit weder technisch noch methodisch als H\u00fcrde betrachtet werden. Die Zitierhilfe des MediaWikis offenbart jedoch das Kernproblem der Zitierf\u00e4higkeit von Wikipediaartikeln: die Autor*innenangabe.</p> <p></p> <p><code>Abbildung 3: Ausschnitt aus der Zitierhilfe zum Artikel \"Mehrautorenschaft\".</code></p> <p>Inhaltlich ist die Angabe der Gruppe der Wikipedia-Autor*innen mit Verweis auf die zugeh\u00f6rige Versionsgeschichte als f\u00fcr den Artikel Verantwortliche durchaus korrekt und in anderen Disziplinen finden sich sogar Parallelen zu dieser Praxis. So urteilte zum Beispiel Zosel in Anbetracht der Zitationspraxis an deutschen Gerichten bereits 2009, dass der Richterspruch \u201aim Namen des Volkes\u2018 vergleichbar w\u00e4re mit der Verantwortlichkeit der \u201aGemeinschaft der Wikipedia-Autor*innen\u2018 f\u00fcr einzelne Artikel. <sup>31</sup> Wissenschaftlichen Standards gen\u00fcgt dies jedoch nicht, denn hier bedarf es zumindest eines Hauptautors. Nach Wozniak m\u00fcssen f\u00fcr die Bestimmung solcher Hauptautor*innen von Wikipediaartikeln die folgenden drei Bedingungen erf\u00fcllt sein:</p> <p>(1) Klarname: Der Hauptautor muss namentlich bekannt sein, (2) quantitativer Anteil: dessen Anteil am Text muss eine bestimmte Grenze \u00fcberschreiten und (3) qualitative Korrektheit: der Autor muss die Korrektheit der zitierten Artikelversion verantworten. <sup>32</sup></p> <p>Die notwendigen Infor\u00admationen zu den Autor*innen und deren Anteil am Artikel k\u00f6nnen dabei den Metadaten der Artikel direkt entnommen werden, was durch verschiedene Tools der Community erleichtert wird. <sup>33</sup> Den notwendigen quantitativen Anteil ver\u00adortet er bei mindestens 83 Prozent f\u00fcr einzelne Haupt\u00adautor*innen, beziehungsweise 70 und 13 Prozent f\u00fcr Erst- und Zweitautor*innen. Sollten alle Bedingungen bei einem Artikel erf\u00fcllt sein, w\u00e4re dieser voll zitierf\u00e4hig. Wozniak leitet daraus eine Zitierpflicht derartiger Artikel ab und fordert fortan die eingehende Pr\u00fcfung aller konsultierter Artikel. <sup>34</sup></p> <p></p> <p><code>Abbildung 4: Urheberanteile unter einer Artikel\u00fcberschrift. (Modul: WikiHistory)</code></p> <p>Dieses System ist jedoch keinesfalls frei von Problemen. Der Entwickler des oben genannten Wikipedia-Moduls WikiHistory beschreibt einige der Herausforderungen auf einer separaten Seite. Dabei geht er unter anderem auf die Problematik der Zuweisung von Autorschaft f\u00fcr editorische Eingriffe wie L\u00f6schungen, Reverts oder Verschiebungen ein, die sich nicht im eigentlichen Text wiederfinden und sich folglich nicht auf die Auswertung auswirken. Der Vergleich auf Wort- und Zeichen-Ebene f\u00fchre weiterhin dazu, dass simple Rechtschreib\u00adkorrekturen deutlich \u00fcberbewertet w\u00fcrden. <sup>35</sup> Insbesondere kann diese rein quantitative Analyse jedoch keine Aussage \u00fcber die Sch\u00f6pfungsh\u00f6he der einzelnen Beitr\u00e4ge treffen. F\u00fcr Wozniaks geforderte Pr\u00fcfung der allt\u00e4glich verwendeten Artikel ist eine solche Software durchaus eine gro\u00dfe Erleichterung, eine zweifelsfreie Identifikation von Hauptautor*innen kann jedoch auch dieses System nicht leisten.</p>"},{"location":"Kapitel_2.html#242-identitat-pseudonymitat-und-algorithmen","title":"2.4.2 Identit\u00e4t, Pseudonymit\u00e4t und Algorithmen","text":"<p>Doch selbst nach der Identifikation einzelner Autor*innen sowie der Bestimmung inhaltlicher Verantwortlichkeit bleibt deren tats\u00e4chliche Identit\u00e4t unklar. Wie zuvor angef\u00fchrt, fordert Wozniak zur Anerkennung der Haupturheberschaft die Angabe eines Klarnamens. Das MediaWiki setzt Accountnamen, also den technischen Identifikator zur Anmeldung, und Anzeigenamen jedoch gleich, sodass nicht-einmalige Namen zwangsl\u00e4ufig durch ein Pseudonym ersetzt werden m\u00fcssen, um die Einzigartigkeit der Accountnamen zu gew\u00e4hrleisten. <sup>36</sup> Dies wird durch den Umstand verst\u00e4rkt, dass die Wikipedia eine sprachversions\u00fcbergreifende Nutzerverwaltung besitzt, wodurch die Accountnamenwahl stets in globaler Konkurrenz stattfindet. <sup>37</sup> Pseudonyme k\u00f6nnen zwar denkbar nah an den b\u00fcrgerlichen Namen der Autor*innen gew\u00e4hlt werden, jedoch finden h\u00e4ufig auch im Internet gebr\u00e4uchliche Spitznamen, nicknames, Verwendung, die anschlie\u00dfend auf der Benutzerseite mit dem b\u00fcrgerlichen Namen aufgel\u00f6st werden. <sup>38</sup></p> <p>Die Belastbarkeit von augenscheinlichen Klarnamen sowie der Eigendarstellung auf Benutzerseiten ist mangels Falsifizierbarkeit gleichwohl zumindest als problematisch zu bewerten. Hoeres verweist hier auf die M\u00f6glichkeit der Konstruktion halb-fiktiver Netzpers\u00f6nlichkeiten, die zwar m\u00f6glicherweise auf eine echte Identit\u00e4t verweisen, deren Wahrheitsgehalt aber schwerlich gepr\u00fcft werden k\u00f6nne. <sup>39</sup> Bei der Bewertung von Benutzerseiten sehen wir uns n\u00e4mlich mit Egodokumenten konfrontiert, die im Hinblick auf die Autorenkritik zwar dieselben Probleme wie die Artikelseiten aufweisen, gleichzeitig jedoch keiner Korrektur durch einen formalisierten, kollaborativen Schreibprozess unterliegen. Die inhaltliche Kontrolle obliegt somit einzig und allein dem User selbst. Gleichwohl dominiert diese Gruppe an sehr aktiven Usern die Statistiken, da etwa 40 Prozent aller \u00c4nderungen von nur zwei Prozent der angemeldeten Usern verfasst werden. <sup>40</sup></p> <p>Eine neutralere jedoch potentiell weniger aussagekr\u00e4ftige Referenz findet sich bei nicht-angemeldeten Usern. Fast die H\u00e4lfte aller Eingriffe findet ohne Verwendung eines Benutzeraccounts statt, wobei von diesen Usern die jeweils aktuelle IP-Adresse gespeichert wird. <sup>41</sup> Mittels der IP lassen sich zwar m\u00f6glicherweise in einem engen zeitlichen Rahmen noch Muster erkennen sowie die grobe Herkunft der Akteure bestimmen, jedoch m\u00fcssen auch diese Analysen mit gro\u00dfer Vorsicht behandelt werden. Eine Lokalisierung via IP ist zum Beispiel nur dann zutreffend, wenn der User keine weiteren Methoden zur Verschleierung, wie VPN oder TOR, verwendet hat. Da wir den Metadaten einzig die IP-Adresse zum Zeitpunkt der Bearbeitung entnehmen k\u00f6nnen, fehlen uns jedoch s\u00e4mtliche Mittel, um solche Techniken zu identifizieren. Weiterhin darf nicht davon ausgegangen werden, dass eine IP-Adresse mit einem einzelnen User gleichzusetzen ist, da User in institutionellen oder offenen Netzwerken unter derselben IP agieren, wie alle anderen User des jeweiligen Netzwerkes.</p> <p>Die Anonymit\u00e4t der User darf aus forschender Sicht jedoch nicht nur als Hindernis im Zuge der Quellenkritik verstanden werden. Es erscheint vielleicht naheliegend, die vielf\u00e4ltigen M\u00f6glichkeiten der Informationstechnik zur Deanonymisierung zu nutzen (siehe Big Data), jedoch muss hierbei sofort die Frage folgen, ob dies ethisch vertretbar w\u00e4re. Der Umgang mit personenbezogenen Daten verlangt stets ein umsichtiges Abw\u00e4gen, welches die Interessen der betroffenen Person mit einbezieht. Im Falle von unabh\u00e4ngig abgerufenen pseudonymisierten Massendaten ist das Einholen von individuellen Einverst\u00e4ndniserkl\u00e4rungen nicht praktikabel bis nicht umsetzbar. <sup>42</sup> Dementsprechend kann nicht von einer allgemeinen Akzeptanz der Ver\u00f6ffentlichung personenbezogener Daten ausgegangen werden, wie sie bei einer expliziten Deanonymisierung zur Ermittlung von individuellen Usern im Rahmen einer Autorenanalyse in Verbindung mit einem Open Science Ansatz naheliegend erscheint. <sup>43</sup> Forschende m\u00fcssen also stets zwischen der Dokumentationspflicht auf der einen und der ethischen Verantwortung gegen\u00fcber der Forschungssubjekte auf der anderen Seite abw\u00e4gen. Gleichwohl k\u00f6nnen gesetzliche Vorgaben oder Anforderungen von Mittelgebern diese Abw\u00e4gung zus\u00e4tzlich erschweren. [^92] Es erscheint somit geboten, das Problem der Autorschaft innerhalb eines kollaborativen System nicht durch eine Orientierung an einzelnen Akteuren aufl\u00f6sen zu wollen. Die Personalisierung der Untersuchung w\u00fcrde m\u00f6glicherweise die pers\u00f6nlichen Interessen der Akteure verletzen und gleichzeitig auf unzuverl\u00e4ssige Informationen zur\u00fcckgreifen. Stattdessen sollten die Prozesse auf einer abstrakteren Ebene unter Einbezug quantitativer Methoden bewertet werden. Das Projektportal der Wikimedia Foundation zeigt diesbez\u00fcglich den folgenden Hinweis:</p> <p>Ethical considerations around research in social spaces are complex. Researchers are expected to follow appropriate policies and guidelines in the Wikis they study. Contact Halfak (WMF) if you'd like help to make sure your study won't cause a disruption. <sup>44</sup></p> <p>Neben angemeldeten und nicht-angemeldeten Usern m\u00fcssen Bots als eine dritte Gruppe von Autor*innen betrachtet werden, deren Untersuchung wiederum eigene Probleme birgt. Bots sind technisch betrachtet nicht mehr als Programme, die unter Verwendung eines Benutzeraccounts und gem\u00e4\u00df ihrer Programmierung oder erlernter Muster \u00c4nderungen in der Wikipedia vornehmen. Sie waren 2015 f\u00fcr etwa zehn Prozent aller Beitr\u00e4ge verantwortlich, jedoch variiert dieser Anteil je nach Sprachversion massiv und d\u00fcrfte mittlerweile auch gesamt gestiegen sein. <sup>45</sup> Von Forschenden werden diese digitalen Akteure h\u00e4ufig entweder als hilfreiche Werkzeuge in der Datenerhebung, als eigenst\u00e4ndige Autokorrekturprogramme oder aber als f\u00fcr die Untersuchung irrelevante Bestandteile der Software betrachtet. <sup>46</sup> Ein solches Vorgehen missachtet ganz offensichtlich sowohl den m\u00f6glichen Einfluss von Bots auf einen Diskurs sowie die kreative Leistung, die das Design derartiger digitaler Akteure verlangt. Da Bots f\u00fcr einen genehmigten Betrieb verschiedene Anforderungen erf\u00fcllen m\u00fcssen, ist deren Wirken gut nachweisbar. <sup>47</sup> Dank der globalen Benutzerkontenverwaltung der Wikipedia k\u00f6nnen Bots mit geringem Aufwand auch in anderen Sprachversionen eingesetzt werden, sofern diese die jeweiligen Bestimmungen erf\u00fcllen. Folglich ist zu erwarten, dass einige Bots  in verschiedenen Sprachversionen gleichzeitig aktiv sind. <sup>48</sup> Nach Geiger sollten Bots in der Wikipedia als soziale Akteure verstanden werden, die sich durch ihre stringente Implementation bisher individuell interpretierter Regeln auszeichnen. Die daraus resultierenden Konflikte innerhalb der Community beleuchten die unterschiedlichen Interpretationen des zuvor als allgemeing\u00fcltig verstandenen Regelwerkes. Bots k\u00f6nnen somit als Katalysatoren sozialer Aushandlungsprozesse dienen, wobei das Ergebnis dieser Prozesse sowohl das Regelwerk selbst, als auch die Implementation desselben in den Algorithmen eines Bot betreffen kann, zum Beispiel durch das Hinzuf\u00fcgen einer Opt-Out-Funktion. <sup>49</sup></p> <p>In all, bots defy simple single-sided categorizations: they are both editors and software, social and technical, discursive and material, as well as assembled and autonomous. One-sided determinisms and constructionisms, while tempting, are insufficient to fully explain the complicated ways in which these bots have become vital members of the Wikipedian community. <sup>50</sup></p> <p>Entgegen bisheriger Gleichg\u00fcltigkeit gegen\u00fcber der Rolle von Bots in sozialen und insbesondere kollaborativen Systemen, erscheint es als absolute Notwendigkeit, diese digitalen Akteure in eine Autorenkritik mit einzubeziehen und entsprechend ihren Eigenheiten zu bewerten.</p>"},{"location":"Kapitel_2.html#243-relationen","title":"2.4.3 Relationen","text":"<p>Wir k\u00f6nnen in der Breite somit weder die individuellen inhaltlichen Beitr\u00e4ge, noch die Identit\u00e4t der einzelnen Akteure methodisch zuverl\u00e4ssig bewerten. Wie also kann eine Autorenkritik dieser digitalen Objekte aussehen?</p> <p>Analog zu der zuvor vorgeschlagenen Analyse der Prozesse sind es hier die Relationen, welche die vielversprechendsten Informationen bieten. Mit Relationen sind dabei die einzelnen Akte des Schreiben bzw. s\u00e4mtlicher aufgezeichneten Manipulationen gemeint, die ein User an einem Artikel vornimmt. Folglich fallen darunter sowohl das Hinzuf\u00fcgen umfangreicher Texte, als auch das Korrigieren einzelner Tippfehler sowie Prozesse wie L\u00f6schungen oder Ver\u00adschiebungen. Durch diese Orientierung am Nutzungsprofil der User und der daraus folgenden Abkehr von der individualisierten Betrachtung einzelner Akteure, umgehen wir insbesondere das Problem der nicht-falsifizierbaren Eigendarstellung auf Benutzerseiten und Eingriffen in die Pseudonymit\u00e4t der User. Diese Relationen sind somit klassisch als \u00dcberreste zu betrachten und k\u00f6nnen folglich als nicht-tendenzi\u00f6s verstanden werden.</p> <p>Die Informationen zur Relation zwischen Artikel und User liegen strukturiert innerhalb der Artikelhistorien vor und k\u00f6nnen analog zu den anderen Bestandteilen des digitalen Objekts Wikipediaartikel erhoben werden. <sup>51</sup> \u00c4hnlich der Artikel\u00adhistorien bietet die Wikipedia automatisch erzeugte Seiten zu den von Usern vor\u00adgenommenen \u00c4nderungen an, die in gleicher Weise ausgewertet werden k\u00f6nnen. Weiterhin folgen diese Wartungsseiten einer sprach\u00fcbergreifend einheitlichen, wenn auch nicht identischen, Nomenklatur, wodurch globale Relationen erhoben werden k\u00f6nnen. <sup>52</sup> Durch den Fokus auf der Mitarbeit an Artikeln kann so f\u00fcr einzelne Benutzer ein rudiment\u00e4res Profil erzeugt werden, dass sich nicht an der Eigendarstellung der User orientiert, sondern an deren tats\u00e4chlichen Verhalten. Ausgehend von einem Artikel k\u00f6nnen solche Erhebungen automatisiert f\u00fcr zum Beispiel alle Autor*innen innerhalb eines festgelegten Zeitraums durchgef\u00fchrt werden. Aus der Summe der Handlungen einer Benutzergruppe ergibt sich somit ein Netzwerk, das anschlie\u00dfend visualisiert und ausgewertet werden kann.</p> <p>Dieses Netzwerk bildet somit die Relationen zwischen Usern und Artikeln ab. In Folge dessen ergeben sich zwar auch Relationen zwischen den Usern selbst, jedoch sollte dieses Modell nicht als Netzwerk im klassischen sozialwissenschaftlichen Sinn verstanden werden. Die behandelten Objekte sind abstrakt und die Relationen entsprechen Datenmanipulationen im System. In dieser grundlegenden Form darf der zugrunde liegende technische Determinismus des Datenmodells nicht ausgeblendet werden. Diese Art der Darstellung ist also zwischen einem informationstechnischen Entity-Relationship-Modell und einem sozialwissenschaft\u00adlichen Netzwerkmodell zu verorten.</p> <p>Es gilt somit zu evaluieren, inwiefern die technischen Strukturen sich auf soziale Inter\u00adaktionen \u00fcbertragen lassen. Da dieses Netzwerk zur Approximation der Autorenidentit\u00e4t dient und einen stark technischen Hintergrund hat, scheinen viele quantitative sozial\u00adwissenschaftliche Ans\u00e4tze der Netzwerkanalyse inkompatibel zu sein. Stattdessen folgt diese Untersuchung einem qualitativen Ansatz, der sich insbesondere zur explorativen Untersuchungen und zur Betrachtung von Konstitutionsbedingungen eignet. Hierzu ist nach Hollstein eine gewisse Offenheit im Erhebungsprozess unabdingbar, um nicht ungewollt Daten auszuschlie\u00dfen. Die Zielsetzung ist hierbei das Sinnverstehen, was durch interpretative Ans\u00e4tze in der Auswertung beg\u00fcnstigt wird. <sup>53</sup></p>"},{"location":"Kapitel_2.html#25-konsequenz","title":"2.5 Konsequenz","text":"<p>Die Ausformulierung quellenkritischer Methoden f\u00fcr genuin digitale Objekte sowie die Etablierung eines sicheren, nachvollziehbaren und zuk\u00fcnftig einheitlichen Umgangs mit Forschungsdaten sind zentrale Herausforderungen der Digital History. Die hier vorgestellten Ans\u00e4tze folgen einer st\u00e4rkeren Orientierung an den Prozessen, welche sowohl die digitalen Objekte, als auch deren Inhalte gestalten.</p> <p>Die abstrakte und unbest\u00e4ndige Pr\u00e4senz digitaler Objekte verlangt nach neuen Herangehens\u00adweisen, da die hergebrachte Diskussion des Quellengegenstands mangels Materialit\u00e4t nicht anwendbar ist. Die Neuorientierung hin zu den konstituierenden Prozessen erscheint dagegen naheliegend und vielversprechend. \u00dcber die Analyse der Systeme im Hintergrund lassen sich sowohl die Echtheit einer Quelle, im Sinne von Abweichungen vom Erwartungswert, sowie ihrer Provenienz in einem gewissen Rahmen \u00fcberpr\u00fcfen. Das hierzu notwendige Studium dieser Systeme vermittelt weiterhin einen zum Verst\u00e4ndnis der Quelle dringend notwendigen Einblick in deren technische Struktur sowie den Kontext ihrer Genese. Analog zu klassischen Hilfswissenschaften ist auch hier nat\u00fcrlich Spezialwissen von N\u00f6ten, das sich zudem je nach Quellenart unterscheidet. Gleichwohl bieten offene Dokumentationsplattformen wie zum Beispiel Bugtracker f\u00fcr einige Systeme bereits einen gut zug\u00e4nglichen und verst\u00e4ndlichen Pool an Quellenkommentaren, die den Zugang zu den Systemen erleichtern. Tiefer gehende Untersuchungen in Form von statischen Quellcodeanalysen oder gar dynamischen Systemtests erh\u00f6hen zwar die Komplexit\u00e4t und Anforderungen der Quellenkritik, bieten dabei jedoch m\u00f6glicherweise v\u00f6llig neue M\u00f6glichkeiten zur Bewertung genuin digitaler Objekte.</p> <p>\u00c4hnlich dem Fokuswechsel vom Status zum Prozess im Rahmen der \u00e4u\u00dferen Quellenkritik erscheint auch die Analyse kollaborativ von anonymen Autor*innen erstellter Objekte durch eine Konzentration auf die Schreibprozesse ein zielf\u00fchrender Ansatz zu sein. Die Anonymit\u00e4t der Autoren steht hierbei im Spannungsfeld zwischen dem Forschungsinteresse, da f\u00fcr eine ad\u00e4quate Autorenkritik eine Identifikation der Autor*innen ein notwendiger erster Schritt w\u00e4re, und dem Pers\u00f6nlichkeitsrecht sowie dem Schutz der Identit\u00e4t der beforschten Akteure im Sinne einer Forschungsethik. Durch die Konzentration auf die Schreibakte und darauf aufbauend auf das Wirken der Autor*innen im transnationalen System Wikipedia k\u00f6nnen die Charakteristiken einzelner User aber auch Schnittmengen von Usergruppen erforscht werden, ohne eine ungewollte Deanonymisierung zu provozieren, oder sich auf die offensichtlich unzuverl\u00e4ssigen Egodokumente der Benutzerseiten verlassen zu m\u00fcssen. Auf diese Weise ist es zudem fast unerheblich, ob die Akteure pseudonyme Accounts benutzen, oder anonym mittels IP-Adresse verzeichnet sind. Um diese komplexen Strukturen erkennen und auswerten zu k\u00f6nnen, kann eine qualitative Netzwerkanalyse auf Grundlage der frei zug\u00e4nglichen Wartungsseiten der Wikipedia erstellt werden. Mangels etablierter Verfahren und Metriken sollte dieser Prozess einem explorativen Ansatz folgen.</p> <p>Eine transparente Dokumentation der erhobenen Daten sowie der Verarbeitung derselben ist schlie\u00dflich die Voraussetzung einer nachvollziehbaren Auswertung und bildet somit die Grundlage f\u00fcr den wissenschaftlichen Diskurs. Bis im Rahmen der NFDI zentralisierte Ans\u00e4tze zur Verf\u00fcgung stehen, erscheint hierbei Research Driven Archiving, also das Sichern der Daten durch die Forschenden selbst, als pragmatische L\u00f6sung.</p> <ol> <li> <p>Diese Forderung teilen u.a. Sahle, Henny und Wozniak. Vgl. Sahle; Henny: Klios Algorithmen: Automatisierte Auswertung von Wikipedia-Inhalten als Faktenbasis und Diskursraum, 2015, S. 115 ; Vgl. Wozniak: Wikipedia in Forschung und Lehre \u2013 eine \u00dcbersicht, 2015, S. 52.\u00a0\u21a9</p> </li> <li> <p>Vgl. F\u00f6hr, Pascal: Historische Quellenkritik im Digitalen Zeitalter, Dissertation, Universit\u00e4t Basel, Basel 2018 ; Aufgegriffen u.a. von Fickers, Andreas: Update f\u00fcr die Hermeneutik. Geschichtswissenschaft auf dem Weg zur digitalen Forensik?, in: Zeithistorische Forschungen 17 (1), ZZF \u2013 Centre for Contemporary History: Zeithistorische Forschungen, 2020, S. 157\u2013168. Online: https://doi.org/10.14765/ZZF.DOK-1765.\u00a0\u21a9</p> </li> <li> <p>Vgl. F\u00f6hr: Historische Quellenkritik im Digitalen Zeitalter, 2018, S. 25\u201327.\u00a0\u21a9</p> </li> <li> <p>Vgl. ebd., S. 26.\u00a0\u21a9</p> </li> <li> <p>Vgl. Wurthmann, Nicola; Schmidt, Christoph: Digitale Quellenkunde. Zukunftsaufgaben der Historischen Grundwissenschaften, in: Zeithistorische Forschungen 17 (1), ZZF \u2013 Centre for Contemporary History: Zeithistorische Forschungen, 2020, Abschn. 1. Online: https://doi.org/10.14765/ZZF.DOK-1764.\u00a0\u21a9</p> </li> <li> <p>Vgl. F\u00f6hr: Historische Quellenkritik im Digitalen Zeitalter, 2018, S. 31 f.\u00a0\u21a9</p> </li> <li> <p>Vgl. ebd., S. 35.\u00a0\u21a9</p> </li> <li> <p>In Hinblick auf die Abnutzung ist es wichtig zu betonen, dass hiermit nat\u00fcrlich die Daten eines digitalen Objekts gemeint sind. Selbstverst\u00e4ndlich unterliegen die Datenspeicher selbst auch Alterungsprozessen und Dateisysteme k\u00f6nnen durch Fehler Sch\u00e4den erleiden. Die elektrische Repr\u00e4sentation des digitalen Objekts hingegen unterliegt keinen derartigen Effekten.\u00a0\u21a9</p> </li> <li> <p>F\u00f6hr: Historische Quellenkritik im Digitalen Zeitalter, 2018, S. 42.\u00a0\u21a9</p> </li> <li> <p>Ein Ansatz zur Auswertung genuin digitaler Aktenbest\u00e4nde zum Beispiel findet sich bei Wurthmann und Schmidt. Vgl. Wurthmann; Schmidt: Digitale Quellenkunde. Zukunftsaufgaben der Historischen Grundwissenschaften, 2020.\u00a0\u21a9</p> </li> <li> <p>Siehe Wikidata, https://www.wikidata.org/wiki/Wikidata:Main_Page, Stand: 04.08.2020.\u00a0\u21a9</p> </li> <li> <p>Der Reitertitel ist kontextabh\u00e4ngig, sodass Kategorieseiten zum Beispiel mit vorangestelltem Kategorie identifiziert werden, und nat\u00fcrlich sprachsensitiv, wodurch sich die Nomenklatur je nach Sprachversion \u00e4ndert.\u00a0\u21a9</p> </li> <li> <p>Im Sinne von direkt zu bearbeiten. Selbstverst\u00e4ndlich spiegeln sich die \u00c4nderungen der User an Artikeln dort wieder und auch L\u00f6schvorg\u00e4nge von Administratoren haben einen direkten Einfluss auf den Inhalt der Liste. Vgl. Wozniak: Wikipedia in Forschung und Lehre \u2013 eine \u00dcbersicht, 2015, S. 50 f.\u00a0\u21a9</p> </li> <li> <p>Siehe auch Hilfe:Versionen, in: Wikipedia, 10.05.2020. Online: https://de.wikipedia.org/w/index.php?title=Hilfe:Versionen&amp;oldid=199804860.\u00a0\u21a9</p> </li> <li> <p>Eine tiefer gehende Analyse der zugrunde liegenden technischen Architektur findet sich im Kapitel 3.2.\u00a0\u21a9</p> </li> <li> <p>Vgl. Fickers, Andreas: Update f\u00fcr die Hermeneutik. Geschichtswissenschaft auf dem Weg zur digitalen Forensik?, 2020, Abschn. 2.\u00a0\u21a9</p> </li> <li> <p>Siehe Exchangeable Image File Format, in: Wikipedia, 08.05.2020. Online: https://de.wikipedia.org/w/index.php?title=Exchangeable_Image_File_Format&amp;oldid=199741501.\u00a0\u21a9</p> </li> <li> <p>Vgl. Wurthmann; Schmidt: Digitale Quellenkunde. Zukunftsaufgaben der Historischen Grundwissenschaften, 2020, Abschn. 2.\u00a0\u21a9</p> </li> <li> <p>Entsprechende Dateisysteme oder Repositorien w\u00fcrden derartige Eingriffe zwar durchaus protokollieren k\u00f6nnen, jedoch sind diese Informationen wiederum eher den Metadaten und folglich der inneren Quellenkritik zuzuordnen. Die Fl\u00fcchtigkeit digitaler Objekte ist eine systemische Herausforderung, die sich durch entsprechend aufwendige Konstrukte nur relativieren, niemals jedoch negieren lassen w\u00fcrde.\u00a0\u21a9</p> </li> <li> <p>Integrit\u00e4t meint im Folgenden die inhaltliche Integrit\u00e4t. Die informationstechnische Korrektheit ist vor allem im Zuge von Verarbeitungsprozessen wie zum Beispiel Datenmigrationen von Relevanz, jedoch muss sie nicht zwangsl\u00e4ufig eine Auswirkung auf die Aussage des digitalen Objektes haben und wird folglich hier nicht n\u00e4her behandelt. Vgl. auch Fickers, Andreas: Update f\u00fcr die Hermeneutik. Geschichtswissenschaft auf dem Weg zur digitalen Forensik?, 2020, Abschn. 2.\u00a0\u21a9</p> </li> <li> <p>Vgl. Wurthmann; Schmidt: Digitale Quellenkunde. Zukunftsaufgaben der Historischen Grundwissenschaften, 2020, Abschn. 2.\u00a0\u21a9</p> </li> <li> <p>Links zum LibreOffice Quellcode finden sich auf der offiziellen Webseite des Projekts. Siehe Source Code - LibreOffice - Free Office Suite - Based on OpenOffice - Compatible with Microsoft, https://www.libreoffice.org/about-us/source-code/, Stand: 25.07.2020.\u00a0\u21a9</p> </li> <li> <p>Siehe LibreOffice Bug List, https://bugs.documentfoundation.org/buglist.cgi? bug_status=__open__&amp;product=LibreOffice, Stand: 25.07.2020 ; sowie Wikimedia Phabricator,https://phabricator.wikimedia.org/, Stand: 25.07.2020.\u00a0\u21a9</p> </li> <li> <p>Vgl. Kirschenbaum, Matthew: The .txtual Condition: Digital Humanities, Born-Digital Archives, and the Future Literary, in: Digital Humanities Quarterly 7 (1), 01.07.2013, Abs. 16.\u00a0\u21a9</p> </li> <li> <p>Zur Artikelhistorie siehe Kapitel 2.1 Zur Struktur des digitalen Objekts Artikel.\u00a0\u21a9</p> </li> <li> <p>Vgl. F\u00f6hr: Historische Quellenkritik im Digitalen Zeitalter, 2018, S. 57 f, 137.\u00a0\u21a9</p> </li> <li> <p>Vgl. ebd., S. 141.\u00a0\u21a9</p> </li> <li> <p>Vgl ebd., S. 164 f.\u00a0\u21a9</p> </li> <li> <p>Historical research data - 4Memory/Nationale Forschungsdaten Infrastruktur (NFDI), https://4memory.de/historical-research-data/, Stand: 04.08.2020.\u00a0\u21a9</p> </li> <li> <p>Diese Art des Nachweises ist als technisch robust zu betrachten. Zur Versionierung siehe auch das Kapitel 2.1 Zur Struktur des digitalen Objekts Artikel.\u00a0\u21a9</p> </li> <li> <p>Vgl. Zosel, Ralf: Im Namen des Volkes: Gerichte zitieren Wikipedia, in: JurPC Web-Dok 140/2009, 07.07.2009, Abs. 71. Online: https://doi.org/10.7328/jurpcb/2009247123.\u00a0\u21a9</p> </li> <li> <p>Wozniak, Thomas: Zitierpflicht f\u00fcr Wikipediaartikel \u2013 und wenn ja, f\u00fcr welche und wie?, Billet, Mittelalter,https://mittelalter.hypotheses.org/3721, Stand: 14.06.2020.\u00a0\u21a9</p> </li> <li> <p>Siehe zum Beispiel Benutzer:APPER/WikiHistory, in: Wikipedia, 10.06.2020. Online: https://de.wikipedia.org/w/index.php?title=Benutzer:APPER/WikiHistory&amp;oldid=200830746.\u00a0\u21a9</p> </li> <li> <p>Vgl. Wozniak: Zitierpflicht f\u00fcr Wikipediaartikel \u2013 und wenn ja, f\u00fcr welche und wie?\u00a0\u21a9</p> </li> <li> <p>Siehe Benutzer:APPER/WikiHistory/Autorenbestimmung, in: Wikipedia, 27.05.2020. Online: https://de.wikipedia.org/w/index.php?title=Benutzer:APPER/WikiHistory/Autorenbestimmung&amp;oldid=200382830.\u00a0\u21a9</p> </li> <li> <p>Eine alternativer Ansatz ist die Trennung von Anzeige- und Benutzernamen bei gleichzeitiger Darstellung im Profil. So zeigen zum Beipsiel Tweets auf Twitter unter einem frei zu w\u00e4hlenden Anzeigenamen stets auch den durch ein vorangestelltes @ markierten Benutzernamen. Weiterhin haben Twitter und andere soziale Netzwerke ein System zur Best\u00e4tigung von Klarnamen implementiert.\u00a0\u21a9</p> </li> <li> <p>Siehe hierzu auch Kapitel 2.1 Zur Struktur des digitalen Objekts Artikel.\u00a0\u21a9</p> </li> <li> <p>Der Account der Autorin ist ein solcher Fall, bei dem eine Accountnamensdopplung durch ein auf der Benutzerseite aufgel\u00f6sten Nicknamen erkl\u00e4rt wurde.\u00a0\u21a9</p> </li> <li> <p>Vgl. Hoeres, Peter: Hierarchien in der Schwarmintelligenz. Geschichtsvermittlung auf Wikipedia, in: Wozniak, Thomas; Nemitz, J\u00fcrgen; Rohwedder, Uwe (Hg.): Wikipedia und Geschichtswissenschaft, Berlin/Boston 2015, S. 29.\u00a0\u21a9</p> </li> <li> <p>Vgl. Wozniak: Wikipedia in Forschung und Lehre \u2013 eine \u00dcbersicht, 2015, S. 43.\u00a0\u21a9</p> </li> <li> <p>Vgl. ebd. Es erscheint weiterhin geboten anzunehmen, dass auch Benutzer mit eigenem Account unter gewissen Umst\u00e4nden das anonyme Editieren bevorzugen. Dies mag zum Beispiel zum Schutz der eigenen Person oder Reputation geschehen und insbesondere in Jurisdiktionen mit eingeschr\u00e4nkter Meinungsfreiheit von Bedeutung sein.\u00a0\u21a9</p> </li> <li> <p>Vgl. Matzner, Tobias; Ochs, Carsten: Sorting Things Out Ethically. Privacy as a Research Issue beoyond the Individual, in: Zimmer, Michael; Kinder-Kurlanda, Katharina E. (Hg.): Internet research ethics for the social age: new challenges, cases, and context, New York 2017, S. 45 f. Online: .\u00a0\u21a9 <li> <p>Vgl. Weller, Kathrin; Kinder-Kurlanda, Katharina E.: To Share or Not to Share. Ethical Challanges in Sharing Social Media-based Research Data, in: Zimmer, Michael; Kinder-Kurlanda, Katharina E. (Hg.): Internet research ethics for the social age: new challenges, cases, and context, New York 2017, S. 127. Online:  92 Vgl. ebd., S. 120\u2013122.\u00a0\u21a9 <li> <p>Wikimedia - Research:Projects, https://meta.wikimedia.org/wiki/Research:Projects, Stand: 04.08.2020.\u00a0\u21a9</p> </li> <li> <p>Vgl. Wozniak: Wikipedia in Forschung und Lehre \u2013 eine \u00dcbersicht, 2015, S. 43.\u00a0\u21a9</p> </li> <li> <p>Vgl. Geiger, R. Stuart: The Lives of Bots, in: Lovink, Geert; Tkacz, Nathaniel (Hg.): Critical Point of View: A Wikipedia Reader, Amsterdam 2011, S. 80. Online: https://networkcultures.org/blog/publication/critical-point-of-view-a-wikipedia-reader/.\u00a0\u21a9</p> </li> <li> <p>Bez\u00fcglich der Anforderungen innerhalb der deutschen Wikipedia siehe Wikipedia:Bots, in: Wikipedia, 03.12.2019. Online: https://de.wikipedia.org/w/index.php?title=Wikipedia:Bots&amp;oldid=194607653. F\u00fcr eine Liste mit allen in der deutschen Wikipedia registrierten Bots siehe Wikipedia Benutzerverzeichnis \u00abbot\u00bb, in: Wikipedia, 25.11.2017. Online: https://de.wikipedia.org/wiki/Spezial:Benutzer/bot, Stand: 22.07.2020.\u00a0\u21a9</p> </li> <li> <p>Bez\u00fcglich globaler Benutzerkonten siehe auch Kapitel 2.1 Zur Struktur des digitalen Objekts Artikel.\u00a0\u21a9</p> </li> <li> <p>Vgl. Geiger: The Lives of Bots, 2011, S. 82 f.\u00a0\u21a9</p> </li> <li> <p>Ebd., S. 92.\u00a0\u21a9</p> </li> <li> <p>Zur Artikelhistorie und deren Einordnung siehe das Kapitel 2.1 Zur Struktur des digitalen Objekts Artikel.\u00a0\u21a9</p> </li> <li> <p>Zur technischen Umsetzung siehe das Kapitel 3.3 Datenbezug und Sicherung.\u00a0\u21a9</p> </li> <li> <p>Vgl. Hollstein, Betina: Qualitative Methoden und Netzwerkanalyse - ein Widerspruch?, in: Qualitative Netzwerkanalyse: Konzepte, Methoden, Anwendungen, 2007, S. 18\u201322.\u00a0\u21a9</p> </li>"},{"location":"Kapitel_3.html","title":"Kapitel 3 - Fallbeispiel: 1989 Tiananmen Square protests","text":"<p>Die Artikel zur gewaltsamen Niederschlagung der Proteste auf dem Tiananmen-Platz 1989 sollen diesem Fallbeispiel als Untersuchungsgegenstand dienen. Schon die Wahl der Titel in den unterschiedlichen Sprachversionen der Wikipedia zeigt die ausgepr\u00e4gte Varianz in der Darstellung des Themas. So Lautet der deutsche Titel Tian\u2019anmen-Massaker, der englische 1989 Tiananmen Square protests und der chinesische kann als six-four incident \u00fcbersetzt werden. Innerhalb der Volksrepublik China wird dieser Vorfall als Tabuthema betrachtet und systematisch zensiert. <sup>1</sup> Wiederholt wurde dieser Anspruch auf Deutungshoheit auf Diskursr\u00e4ume jenseits der Grenzen Chinas ausgeweitet, wobei insbesondere die wirtschaftliche Funktion des Landes eine zentrale Rolle spielte. So f\u00fchrte 2019 ein Werbefilm des deutschen Kameraherstellers Leica zu einem Aufschrei in China, da in einer kurzen Sequenz das weltbekannte Bild des Tank mans zu sehen war. <sup>2</sup> 2020 sperrte China einen Trailer des Computerspiele Publishers Activision, da in diesem ebenfalls in einem kurzen Ausschnitt die Proteste von 1989 gezeigt wurden. <sup>3</sup></p> <p>Zwischen dem chinesischen und dem englischen Artikel sind somit sowohl inhaltlich als auch in der Zusammensetzung der Autor*innen gewichtige Unterschiede zu erwarten. Im Folgenden werden die genuin digitalen Quellen entsprechend der zuvor erl\u00e4uterten Methodik einer digital-historischen Quellenkritik unterzogen. Der Fokus gilt dabei der Validit\u00e4t der digitalen Objekte sowie der Kritik der anonymen Autor*innengruppen der zu untersuchenden Artikel.</p>"},{"location":"Kapitel_3.html#31-heuristik","title":"3.1 Heuristik","text":"<p>Ausgangspunkt der Untersuchung ist der Artikel 1989 Tiananmen Square protests (im Folgenden als en\u2070 bezeichnet) der englischen Sprachversion der Wikipedia. <sup>4</sup> Diese nimmt im Netz der Sprachversionen eine besondere Rolle ein. Nicht nur wurde mit ihr das Projekt Wikipedia urspr\u00fcnglich ins Leben gerufen, sie ist auch bis heute die aktivste und umfassendste Sprachversion des Projekts. <sup>5</sup> Weiterhin nimmt sie eine vermittelnde Funktion unter den zahlreichen Sprachversionen ein, indem sie regelm\u00e4\u00dfig als Quelle oder Ziel von \u00dcbersetzungs\u00advorhaben dient. Ban, Perc und Levnaji\u0107 zeigten, dass \u00dcbersetzungs\u00adleistungen nicht gleich verteilt zwischen Sprachversionen stattf\u00e4nden, sondern sich bevorzugt innerhalb bestimmter Cluster abspielten. Ausgenommen von diesem Ph\u00e4nomen sei jedoch die englische Sprachversion, die sich keinem der ermittelten Cluster zuordnen lasse. <sup>6</sup> Dank ihrer Rolle als lingua franca beteiligen sich insbesondere viele nicht-muttersprachliche User aktiv an der Gestaltung dieser Wikipedia. Nach Kim (et al.) seien die Beitr\u00e4ge nicht-muttersprachlicher User in ihrer sprachlichen Komplexit\u00e4t und der Auswahl der Artikel kaum von den mutter\u00adsprachlichen Usern zu unterscheiden. Gleichwohl zeige sich, dass auch multilinguale User bevorzugt in ihrer jeweiligen Muttersprache und folglich der entsprechenden Sprach\u00adversion der Wikipedia schreiben w\u00fcrden. <sup>7</sup> Die englischsprachige Wikipedia ist wegen ihrer au\u00dferordentlichen Relevanz sowie des intensiven interkulturellen Diskurses somit eine ausgezeichnete Vergleichsbasis.</p> <p>Fokus dieser Untersuchung ist die Bewertung der Schreibakte der Autor*innen als Teil einer inneren Quellenkritik. Jedem Artikel kann \u00fcber die Teilnahme am editorischen Prozess eine Gruppe an Usern zugewiesen werden. Die zuvor genannten Untersuchungen lassen vermuten, dass diese Gruppe bei einem Artikel der englischsprachigen Wikipedia vergleichsweise heterogen im Sinne einer sprachlichen oder nationalen Zuordnung ist. Da Useraccounts jedoch systemweit einzigartig vergeben werden, kann \u00fcber den Benutzernamen eine Beteiligung an Schreibprozessen in verschiedenen Sprachversionen nachgewiesen werden.</p> <p>Ein m\u00f6glicher Ansatz zur Beurteilung von Nutzergruppen ist die Suche nach Schnittmengen in Artikeln unterschiedlicher Sprachversionen. Der Artikel \u516d\u56db\u4e8b\u4ef6  (ab hier: zh\u2070) ist das chinesische Gegenst\u00fcck zu en\u2070 und soll fortan die Vergleichsbasis zu diesem darstellen. <sup>8</sup> Die chinesische Sprachversion ist \u00e4hnlich der englischen Version ein Sonderfall in der Wikipedia. Bis etwa Ende 2014 war sie auch innerhalb der Volksrepublik China erreichbar, was sich mit dem Jahresbeginn 2015 jedoch \u00e4nderte. Ab etwa 2015 wurde der Zugriff auf die chinesische Sprachversion, analog zur restlichen Wikipedia, f\u00fcr Internetteilnehmer innerhalb Chinas gesperrt. Es kann daher davon ausgegangen werden, dass die chinesischsprachige Wikipedia vor 2015 haupts\u00e4chlich durch den Einfluss von Usern aus der VRC gepr\u00e4gt wurde, w\u00e4hrend nach 2015 insbesondere User aus anderen L\u00e4ndern, wie z.B. der Republik China (Taiwan) oder Hong Kong, die Artikel bearbeiteten. <sup>9</sup> Diese \u00c4nderung der Nutzerbasis f\u00fchrte zu einem ver\u00e4nderten Umgang mit f\u00fcr die Kommunistische Partei Chinas sensiblen Themen. <sup>10</sup> Die Zeitachse mit einbeziehend, sind f\u00fcr zh\u2070 somit zwei unterschiedlich zu charakterisierende Akteursgruppen anzunehmen, die auf Schnittmengen mit der Akteursgruppe von en\u2070 abgeglichen werden sollen.</p> <p>Zus\u00e4tzlich zum Ansatz eines Gruppenvergleichs auf Grundlage hermeneutisch ermittelter Artikel bietet sich weiterhin eine Analyse auf Ebene der Akteure selbst an. \u00c4hnlich der Artikelhistorie, bei der die einzelnen Artikelversionen eines Artikels chronologisch aufgelistet werden, verf\u00fcgt die Wikipedia zudem \u00fcber die Funktion der User Contributions oder Benutzerbeitr\u00e4ge. Diese Funktion listet die Beitr\u00e4ge eines spezifischen Users chronologisch auf, wodurch dessen Schreibakte artikel\u00fcbergreifend nachvollziehbar werden. Jedoch ist diese Funktion stets auf die aktuelle Sprachversion begrenzt, obwohl die Useraccounts selbst sprachversions\u00fcbergreifend gestaltet sind. Um Aktivit\u00e4ten in anderen Sprachversionen zu inkludieren, muss je Sprache eine eigene Abfrage der User Contributions durchgef\u00fchrt werden.</p> <p>Neben dem beschr\u00e4nkten Wirkungsbereich der User Contributions erzwingt auch die sprachsensible Formatierung der Wikipedia eine explizite Auswahl zu untersuchender Sprachversionen im Vorfeld der Datenerhebung. Insbesondere die Formatierung der Datumsangaben sowie einige Details im HTML der zu untersuchenden Seiten variieren teils betr\u00e4chtlich je nach Sprachversion, worauf u.a. mit einer entsprechenden \u00dcbersetzung der Datumsangaben reagiert werden muss.<sup>11</sup> Den zuvor ausgew\u00e4hlten Artikeln entsprechend, sind f\u00fcr diese Untersuchung mindestens die Sprachversionen Chinesisch (zh) und Englisch (en) in Betracht zu ziehen. Da die Wikipedia in etwa dreihundert Sprachversionen vorliegt und f\u00fcr einen signifikanten Anteil dieser Sprachen Anpassungen an den Skripten zur Datenerhebung vorzunehmen w\u00e4ren, ist der Anspruch einer vollst\u00e4ndigen Erfassung im Rahmen dieser Arbeit nicht zielf\u00fchrend. Stattdessen erscheint es sinnvoll, Sprachversionen gem\u00e4\u00df ihrer Aktivit\u00e4t mit in die Untersuchung aufzunehmen. Als Indikator f\u00fcr die Aktivit\u00e4t wird hier die Anzahl aktiver Benutzer einer Sprachversion benutzt. Dementsprechend werden zus\u00e4tzlich zu den oben genannten folgende Sprachversionen in dieser Untersuchung mit einbezogen: Deutsch (de), Franz\u00f6sisch (fr), Spanisch (es), Japanisch (ja), Russisch (ru) sowie Italienisch (it). <sup>12</sup> Durch diese Metrik wird verhindert, dass Sprachversionen mit geringer Benutzerzahl aber sehr hoher Botaktivit\u00e4t untersucht werden. <sup>13</sup></p>"},{"location":"Kapitel_3.html#32-auere-kritik-validierung-der-digitalen-objekte","title":"3.2 \u00c4u\u00dfere Kritik: Validierung der digitalen Objekte","text":"<p>Gegenstand der \u00e4u\u00dferen Quellenkritik sind die digitalen Objekte Article History sowie User Contributions der Wikipedia, die zum Zeitpunkt der Untersuchung und Datenerhebung unter der Software MediaWiki in Version 1.36.0-wmf.4 (98d11b3) lief. <sup>14</sup> Da die hier vorgestellte genuin digitale \u00e4u\u00dfere Quellenkritik die zu Grunde liegenden Prozesse und die technische Implementation adressiert, k\u00f6nnen die zuvor ermittelten Untersuchungsgegenst\u00e4nde en\u2070 und zh\u2070 sowie die Benutzerbeitragslisten der zugeh\u00f6rigen User ignoriert werden, da es sich dabei um Instanzen der zu untersuchenden digitalen Objekte handelt.</p> <p>Ziel ist es somit, die Integrit\u00e4t der zu untersuchenden Daten durch eine Analyse der Software\u00adarchitektur und Daten\u00adverarbeitung zu bewerten. Als Indikator f\u00fcr Abweichungen vom Erwartungswert dient hierbei das zum MediaWiki geh\u00f6rende Bugtracking-Portal Phabricator. Zur Identifikation von Programmfehlern wird dort die unscharfe Bezeichnung Task verwendet. In diese Kategorie fallen zudem auch neue Anforderungen an die Software sowie unspezifische Auff\u00e4lligkeiten oder Anmerkungen. Erst aus der Description wird ersichtlich, um welchen Typ es sich beim vorliegenden Task handelt. In Anbetracht der Offenheit des Systems und der Relevanz des Projektes Wikipedia kann bei negativem Befund mit relativer Sicherheit davon ausgegangen werden, dass keine Anomalien in der untersuchten Datenverarbeitung auftreten. Neben offenen Tasks sind f\u00fcr die Bewertung der digitalen Objekte auch bereits geschlossene Tasks von Interesse. Dort k\u00f6nnten Hinweise auf Fehler zu finden sein, die sich dauerhaft auf die vorliegende Datenbasis ausgewirkt haben. In diesem Fall w\u00e4re zu pr\u00fcfen, ob die Datenbasis retrospektiv korrigiert wurde.</p> <p>F\u00fcr eine erfolgreiche Recherche in Phabricator muss zun\u00e4chst die Architektur der betroffenen Objekte analysiert werden, damit die betroffenen Komponenten der Software eindeutig identifiziert werden k\u00f6nnen. Hilfreiche Ressourcen zur Einarbeitung in das System sind das MediaWiki Handbuch, die Community Seite Developer Hub sowie die Klassen\u00adreferenz, in der die strukturierten Quellcodekommentare zusammengefasst vorliegen. <sup>15</sup></p> <p>Wie bereits in Kapitel 2.1 Zur Struktur des digitalen Objekts Artikel dargelegt, bestehen Artikel aus einer Reihe an einzelnen Artikelversionen, welche die eigentlichen Informationstr\u00e4ger des digitalen Objektes darstellen. Diese Artikelversionen werden im Quellcode von der abstrakten Klasse RevisionItemBase abgeleitet und tragen die Bezeichnung RevDelRevisionItem. <sup>16</sup> F\u00fcr diese Untersuchung sind drei Funktionen von Interesse, die auf diese Klasse zugreifen: das Laden einzelner Artikelversionen, das Laden einer Liste von Artikelversionen sowie das Speichern von Artikelversionen.</p> <p>Das Laden einer bestimmten Artikelversion wird beim Aufrufen eines Wikipediaartikels ausgef\u00fchrt. Die f\u00fcr die Artikel verantwortliche Klasse hei\u00dft Article und diese ruft \u00fcber die Funktion fetchRevisionRecord() die jeweils aktuelle Artikelversion ab. <sup>17</sup> Das \u00d6ffnen der Artikelhistorie f\u00fchrt zum Aufruf der Klasse HistoryAction, die \u00fcber die Funktion fetchRevisions() mehrere Artikelhistorien als Liste l\u00e4dt. [^120] Beim Speichern hingegen wird zun\u00e4chst \u00fcber eine EditAction die Klasse EditPage aufgerufen, von der aus via attemptSave() eine neue Revision erstellt werden kann. <sup>18</sup></p> <p>Erg\u00e4nzend zu den Artikelversionen sind f\u00fcr die vorliegende Untersuchung die Benutzer\u00adbeitr\u00e4ge von Interesse. Diese werden mit der Klasse ContribsPager abgebildet, die \u00fcber die Funktion formatRow() die jeweiligen Artikel\u00adversionen abruft. <sup>19</sup></p> <p></p> <p><code>Abbildung 5: Suchmaske des Trackingtools Phabricator.</code></p> <p>Die relevanten Prozesse im Umgang mit Artikelversionen umfassen also die Klassen Article, HistoryAction, EditAction, EditPage, RevDelRevisionItem sowie ContribsPager. \u00dcber diese Suchbegriffe k\u00f6nnen nun relevante Tasks in Phabricator ermittelt werden. <sup>20</sup> Die Suche verkn\u00fcpft hierbei Suchbegriffe stets mit einem logischen AND, wodurch separate Such\u00addurchl\u00e4ufe je Begriff notwendig sind. Eine Einschr\u00e4nkung des Document-Types auf Task vermeidet die Anzeige irrelevanter Ergebnis\u00adarten. Das Feld Tags bietet weiterhin die M\u00f6glichkeit, die Suche auf bestimmte Komponenten einzuschr\u00e4nken. Hier bieten sich zur Beschr\u00e4nkung auf die relevanten Themengebiete die Eintr\u00e4ge MediaWiki-Page-History sowie MediaWiki-Page-Editing an.</p> <p>Die Recherche ergab hierbei keine Hinweise auf fehlerhafte Prozesse oder inkonsistente Daten, die Datenbasis kann somit als integer betrachtet werden.</p>"},{"location":"Kapitel_3.html#33-datenbezug-und-sicherung","title":"3.3 Datenbezug und Sicherung","text":"<p>Der Bezug der zu untersuchenden Daten ist prozessual eng mit deren Sicherung im Rahmen eines Research Driven Archiving verkn\u00fcpft. <sup>21</sup> Zur besseren Lesbarkeit werden diese Prozesse im Folgenden jedoch nacheinander behandelt.</p> <p>Die Wikipedia richtet sich mit ihrem Angebot und ihrer Gestaltung an menschliche User, doch erst durch eine zumindest teilautomatisierte Erhebung und Auswertung der genuin digitalen Quellen werden deren Vorz\u00fcge klar. Der Zugang zu und folglich das Abrufen der Daten aus der Wikipedia stellen die Voraussetzung f\u00fcr alle weiteren Schritte dar. In der Wikipedistik haben sich hierzu vorrangig zwei Zugriffsm\u00f6glichkeiten auf die Inhalte der Wikipedia etabliert. Der technisch naheliegende Weg ist der Zugriff \u00fcber die API des MediaWikis. <sup>22</sup> Diese Schnittstelle erm\u00f6glicht zwar einen direkten Zugriff auf die Inhalte der Wikipedia, jedoch sind dar\u00fcber nicht alle gewohnten Funktionen des Webinterface zug\u00e4nglich. So bem\u00e4ngeln Sahle und Henny zu Recht, dass Suchkriterien nicht kombinierbar und Einschr\u00e4nkung auf bestimmte Artikelteile zu unpr\u00e4zise seien. <sup>23</sup> Zudem verlangt der Einsatz dieser spezialisierten API eine gewisse Einarbeitungszeit, wobei sich das angeeignete Wissen schwerlich auf andere Quellenkorpora \u00fcbertragen l\u00e4sst.</p> <p>Vielversprechender erschient hingegen die Auswertung der HTML-Dateien unter Einsatz von XML, XPath und XSLT, zumal der Einsatz der Extensible Markup Language ein \u00fcbliches Vorgehen zur teilautomatisierten Auswertung von Daten darstellt. Dank der sprachstrukturellen \u00c4hnlichkeit k\u00f6nnen HTML-Dokumente zudem direkt mit Mitteln der X-Technologien verarbeitet werden. <sup>24</sup> Weiterhin entspricht der Zugriff auf die Daten \u00fcber die formatierten HTML-Seiten am ehesten dem Zugriff durch einen realen User und die anfallenden Zwischenergebnisse k\u00f6nnen direkt mit den online vorliegenden Informationen abgeglichen werden. Zwar ist es anzunehmen, dass der Weg \u00fcber die API gleichartige Ergebnisse liefern w\u00fcrde, jedoch hat dieser Prozess keine realweltliche Entsprechung und deckt sich nicht mit typischem Benutzerverhalten. Die Nutzung der selben Anzeigeschicht f\u00fchrt weiterhin dazu, dass auch etwaige Fehler im System sich auf die selbe Weise auf die Datenerhebung auswirken, wie auf die Nutzung durch menschliche User. Das zu implementierende Logging des Datenabrufs ist bei einem Zugriff \u00fcber die HTML-Seiten ebenfalls besser nachvollziehbar zu gestalten, da auch hier die Parallele zum \u00fcblichen Anwendungsfall besteht.</p> <p>Sahle und Henny weisen jedoch darauf hin, dass \u00c4nderungen in der HTML-Struktur der Wikipediaartikel, wie sie im Rahmen von Softwareupdates vorstellbar sind, zu Inkompatibilit\u00e4ten mit der Auswertungssoftware f\u00fchren k\u00f6nnen. Dies w\u00fcrde die Nachnutzungsm\u00f6glichkeiten der Software beeintr\u00e4chtigen. <sup>25</sup> Dieser Nachteil kann jedoch durch den Einsatz von XSLT-Skripten zur Interpretation der HTML-Dateien relativiert werden. Diese Skripte dienen in diesem Fall als Schnittstelle zwischen Quelldatei und Arbeitskopie. Anpassungen an Struktur\u00e4nderungen w\u00fcrden sich somit auf diese Skripte beschr\u00e4nken. Weiterhin sind diese f\u00fcr die Sicherung der Arbeitsdaten verantwortlich.</p> <p>Sowohl der Datenbezug, als auch die Quellensicherung und die Visualisierung der Akteursnetzwerke wurden von der Autorin unter Verwendung von Python 3.6 implementiert. Die zentrale Funktionslogik wurde in der Klasse UserNetwork geb\u00fcndelt, f\u00fcr die fallabh\u00e4ngigen Funktionsaufrufe sowie die Implementation der Netzwerkvisualisierung pyvis wurden separate Skripte angelegt. <sup>26</sup> Als Entwicklungsumgebung kam Spyder in der Version 3.2.6 zum Einsatz.</p> <p>Der erste Schritt des Datenbezugs ist der eigentliche Abruf der HTML-Seiten, was hier \u00fcber die Library Requests: HTTP for Humans implementiert wurde. <sup>27</sup> Anhand einer definierten URL gibt requests ein Objekt mit plain HTML Text zur\u00fcck, das anschlie\u00dfend weiterverarbeitet werden kann. Da die URLs parametrisiert sind, k\u00f6nnen diese entsprechen zerlegt oder konstruiert werden. Zentral hierf\u00fcr sind der action- sowie title-Parameter des MediaWikis. Mit diesen kann statt einem Artikel dessen Artikelhistorie oder statt einer Benutzerseite die Liste der Benutzerbeitr\u00e4ge geladen werden. Der parametrisierte Aufruf der Versionsgeschichte zu en\u2070 mit maximal f\u00fcnfhundert Eintr\u00e4gen sieht dementsprechend wie folgt aus:</p> <p><code>https://en.wikipedia.org/w/index.php?title=1989_Tiananmen_Square_protests&amp;action=history&amp;limit=500</code></p> <p>Der Artikel selbst wird \u00fcber den title-Parameter durch einen einmaligen Artikeltitel identifiziert, w\u00e4hrend die Tiefe der Artikelhistorie mittels limit beschr\u00e4nkt wird. Die Parameter sind optional solange das Zieldokument selbst identifiziert werden kann. Bei einem Aufruf einer spezifischen Artikelversion \u00fcber den oldid-Parameter kann dementsprechend auf den title-Parameter verzichtet werden, da die Versions-ID ebenfalls einen einmaligen Identifikator darstellt. Der Aufruf der en\u2070-Version vom 26.06.2020 kann somit wie folgt verk\u00fcrzt werden:</p> <p><code>https://en.wikipedia.org/w/index.php?oldid=964661527</code></p> <p>Diese direkte Adressierung \u00fcber die Versions-ID erleichtert den automatisierten Abruf von Artikelversionen, da dieses Format standardisiert ist und im Gegensatz zu sprachabh\u00e4ngigen Titeln keine Kodierungsprobleme zu erwarten sind.</p> <p>Die so bezogenen HTML-Texte k\u00f6nnten nun im Sinne des Research Driven Archiving als Abbild der digitalen Objekte lokal gespeichert werden. Da die Untersuchung sich jedoch auf die Relationen zwischen Usern und Artikeln konzentriert, w\u00fcrden damit auch viele Daten gesichert werden, die kein Bestandteil der eigentlichen Auswertung sind. Durch die Erhebung der Daten durch teilautomatisierte Verfahren ist der Abruf tausender Datens\u00e4tze f\u00fcr einzelne Analysen nicht unwahrscheinlich, dementsprechend scheint es im Sinne der Datensparsamkeit geboten zu sein, die Sicherung der Arbeitsdaten auf die tats\u00e4chlich untersuchten Datens\u00e4tze zu beschr\u00e4nken. Die Falsifizierbarkeit der Untersuchung ist somit auch ohne Zugriff auf die Originaldaten m\u00f6glich und durch eine automatisierte Protokollierung der Datenverarbeitung ist eine retrospektive Analyse der urspr\u00fcnglichen Daten ebenfalls gegeben.</p> <p>Die HTML-Texte werden im Folgenden daher mittels XSLT-Schemata in ein reduziertes XML-Format \u00fcberf\u00fchrt und anschlie\u00dfend lokal gespeichert. <sup>28</sup> F\u00fcr jede HTML-Seite wird ein eigenes Schema ben\u00f6tigt, um die jeweilige Struktur des HTML-Textes korrekt \u00fcbersetzen zu k\u00f6nnen. Durch die Offenlegung des Quelltextes der Schemata wird die Nachvollziehbarkeit der Transformation der Daten sichergestellt. Die \u00dcbersetzung der HTML-Texte in das spezielle XML-Format schlie\u00dft im Quellcode direkt an den Datenabruf an und wurde mit Hilfe der etree API aus der lxml Library implementiert. <sup>29</sup> Der Parameter stylesheet erwartet hierbei die Angabe des zur abzurufenden HTML-Seite passenden XSLT-Schemata. Nach erfolgreicher Transformation wird das erzeugte XML-Objekt zun\u00e4chst lokal gesichert, bevor es weiterverarbeitet werden kann. Um unn\u00f6tiges Abrufen von Daten zu vermeiden, wird dabei anhand des Dateinamens auf m\u00f6glicherweise bereits vorhandene XML-Dateien gepr\u00fcft und bei Erfolg diese geladen. Der Dateiname setzt sich aus der Angabe eines Unterordners, der Sprachversion sowie dem Querystring des Abfrageziels zusammen.</p> <p>Diese XML-Objekte repr\u00e4sentieren jeweils eine HTML-Seite, entweder die Artikelhistorie oder die Benutzerbeitr\u00e4ge, mit n einzelnen Datens\u00e4tzen. Jeder Datensatz entspricht dabei entweder einem Artikel oder einem User. F\u00fcr die anschlie\u00dfende Netzwerkanalyse m\u00fcssen diesen zun\u00e4chst aggregiert und verkn\u00fcpft werden. Netzwerke werden \u00fcblicherweise durch nodes (Knotenpunkte) und edges (Kanten bzw. Relationen) beschrieben. Sowohl Artikel als auch User sind eigenst\u00e4ndige Entit\u00e4ten und werden somit als nodes betrachtet. Die Relationen zwischen einzelnen Nodes, also insbesondere zwischen Artikeln und den zugeh\u00f6rigen Autor*innen, m\u00fcssen jedoch explizit erzeugt werden. Diese edges definieren sich daher durch die Kombination eines Artikeltitels mit einem Benutzernamen.</p> <p>Die Funktion zum Auslesen der Artikelhistorien ermittelt zun\u00e4chst das Sprachkennzeichen aus dem XML-Objekt und anschlie\u00dfend den Titel des Artikels. <sup>30</sup> Die Informationen werden mittels XPath-Ausdr\u00fccken adressiert und \u00fcber eine lokale Funktion in die Liste der nodes geschrieben. Ein node besteht aus einem einmaligen Bezeichner (Titel oder Username), seiner Klasse (Artikel oder User), dem zum Eintrag geh\u00f6rigen Sprachk\u00fcrzel mitsamt der Sprachh\u00e4ufigkeit, die beim Einlesen stets 1 betr\u00e4gt. Anschlie\u00dfend wird f\u00fcr jede Artikelversion der zugeh\u00f6rige User ermittelt und ebenfalls der Liste der nodes hinzugef\u00fcgt. Benutzern wird initial keine Sprachzugeh\u00f6rigkeit zugewiesen, da diese nur \u00fcber eine Analyse aller Beitr\u00e4ge eines Users approximiert werden kann. Das \u00c4nderungsdatum sowie die ID der Artikelversion werden anschlie\u00dfend als Relation zwischen User und Artikel in die Liste der edges geschrieben. Analog zu dieser Methodik werden auch die Benutzerbeitr\u00e4ge ausgewertet.</p> <p>Zus\u00e4tzlich zur Speicherung der einzelnen XML-Dateien k\u00f6nnen diese komplexen Listen als CSV-Dateien lokal gespeichert werden. Somit k\u00f6nnen die Arbeitsdaten zus\u00e4tzlich zur Sicherung nach Herkunft auch fallbezogen f\u00fcr spezifische Analysen gesichert werden.</p>"},{"location":"Kapitel_3.html#34-innere-quellenkritik-analyse-der-akteure","title":"3.4 Innere Quellenkritik - Analyse der Akteure","text":"<p>Die Autor*innen der Wikipedia arbeiten stets unter pseudonymen Benutzerkonten. Zwar gibt es durchaus auch Autor*innen, die Klarnamen verwenden und das unter Umst\u00e4nden auch auf ihrer Benutzerseite deklarieren, doch m\u00fcssen wir diese Egodokumente in Anbetracht der fehlenden Validierungsm\u00f6glichkeiten, zumindest bei Massenauswertungen, als unzuverl\u00e4ssig betrachten. Die Autor*innen sind als anonym zu behandeln. Eine Kritik dieser Autorschaft sollte sich dementsprechend auf ihre Schreibakte konzentrieren. <sup>31</sup></p> <p>Um diese Informationen auswerten zu k\u00f6nnen, m\u00fcssen die erhobenen Daten zun\u00e4chst aufbereitet werden. Die Zuordnung eines Artikels zu einer Sprache ist offensichtlich und wird dementsprechend direkt bei Datenabruf im entsprechenden Knotenpunkt notiert. Aufgrund der globalen G\u00fcltigkeit der Benutzeraccounts k\u00f6nnen die Sprachkenntnisse der User initial nicht bewertet werden, weshalb die zugeh\u00f6rigen Knotenpunkte einen Leereintrag erhalten. \u00dcber die Auswertung der Relationen der Benutzer mit Artikeln aus verschiedenen Sprachversionen lassen sich die Sprachkenntnisse der User ermitteln. Hierzu pr\u00fcft die Funktion compute_language() s\u00e4mtliche einem User zugeordneten Artikel und notiert deren Sprachkennzeichen sowie die H\u00e4ufigkeit im Knotenpunkt des Users. <sup>32</sup> Den Nutzern werden somit Sprach\u00adfertigkeiten zugewiesen, die nach der H\u00e4ufigkeit der jeweiligen Schreibakte gewichtet sind. Somit wird die sprachliche Herkunft der User auf Grundlage ihrer Handlungen und nicht ihrer Eigendarstellung bewertet.</p> <p>Zur Darstellung dieser gewichteten Sprachkenntnisse innerhalb eines Akteursnetzwerkes werden den Sprachen eigene Knotenpunkte zugewiesen. Die Gewichtung der Sprachkenntnisse einzelner User wird hierbei auf zwei Arten visualisiert. Durch eine Verkn\u00fcpfung der Sprachh\u00e4ufigkeit mit der Linienst\u00e4rke im Netzwerk k\u00f6nnen individuelle Relationen sichtbar gemacht werden. Dynamische Netzwerkdarstellungen mit Physiksimulationen erm\u00f6glichen es zudem, der Sprachgewichtung eine virtuelle Anziehungskraft zuzuweisen, wodurch die Position der Sprachversionsknoten im Netzwerk sowie die Gruppierung der restlichen Knoten einen direkten Eindruck der Sprachverteilung im untersuchten Ausschnitt erm\u00f6glicht.</p> <p>Da die Bestimmung der Sprachkenntnisse der User somit von den untersuchten Artikeln abh\u00e4ngt, w\u00fcrden in einer direkt vergleichenden Untersuchung, wie der Gegen\u00fcberstellung von en\u2070 und zh\u2070, dementsprechend nur die den Artikeln zugeh\u00f6rigen Sprachen in Betracht gezogen werden. Um weitere Sprachkenntnisse der User zu erheben, muss zun\u00e4chst auf deren Benutzerbeitr\u00e4ge in anderen Sprachversionen gepr\u00fcft werden.</p> <p>Hierzu ruft die Funktion add_usercontributions() f\u00fcr jeden User in der Liste nodes oder f\u00fcr eine als Parameter \u00fcbergebene Liste an Usern die Benutzerbeitr\u00e4ge in allen definierten Sprachversionen ab. <sup>33</sup> Hierbei kann \u00fcber den Parameter depth die Anzahl der Artikel begrenzt werden, die abgerufen werden sollen. Ein m\u00f6glichst hoher Wert f\u00fchrt dabei zwar voraussichtlich f\u00fcr eine belastbarere Analyse der Sprachfertigkeiten, jedoch wirkt dieser Parameter gleichzeitig als achtfacher Multiplikator gegen\u00fcber allen zuvor ermittelten Usern, da im Rahmen dieser Untersuchung die acht aktivsten Sprachversionen der Wikipedia untersucht werden. Eine depth von zehn w\u00fcrde somit zu maximal achtzig Datenpunkten je User f\u00fchren. Der eigentliche Abruf der Benutzerbeitr\u00e4ge ist im MediaWiki zwar standardisiert, jedoch ist der Titel der Spezialseite sprachabh\u00e4ngig und muss dementsprechend im Code je Sprache hinterlegt werden. Der Aufruf der russischen Benutzerbeitr\u00e4ge f\u00fcr den User Krugbuild verlangt zum Beispiel die folgende URL:</p> <p><code>https://ru.wikipedia.org/w/index.php?title=\u0421\u043b\u0443\u0436\u0435\u0431\u043d\u0430\u044f:\u0412\u043a\u043b\u0430\u0434/Krugbuild</code></p> <p>Die Bestimmung der zu untersuchenden Ausschnitte ist eine weitere Notwendigkeit der Datenaufbereitung. Hierbei erscheinen wiederum zwei Ans\u00e4tze zielf\u00fchrend zu sein. Die Reduzierung der Knotenpunkte nach Relationsh\u00e4ufigkeit dient dabei einer besseren \u00dcbersicht im Netzwerk. <sup>34</sup> Hierbei werden Knotenpunkte entfernt, die eine bestimmte Anzahl an Relationen zu anderen Knotenpunkten unterschreiten. Dies betrifft \u00fcblicherweise Artikelversionen, die von untersuchten Benutzern bearbeitet wurden, aber keine weiteren Relationen zum eigentlichen Untersuchungsgegenstand haben. Weiterhin k\u00f6nnen damit nicht oder schlecht vernetzte Akteure aus dem Ergebnissatz entfernt werden. Dies betrifft insbesondere User, die nur vereinzelte Bearbeitungen an einem Artikel durchgef\u00fchrt haben und somit als einzelne Knotenpunkte am Rand eines Netzwerkes dargestellt werden. Bei der Betrachtung von Gruppen und Schnittmengen ist es zwar hilfreich, diese Knotenpunkte auszublenden, jedoch d\u00fcrfen diese nicht vollst\u00e4ndig ignoriert werden. Eine unhinterfragte L\u00f6schung dieser einzelnen Akteure w\u00fcrde das untersuchte Netzwerk stets zu Gunsten sehr aktiver Akteure ver\u00e4ndern.</p> <p>Der zweite Ansatz dient der chronologischen Definition der zu untersuchenden Ausschnitte. Da die Relationen den Artikelversionen entsprechen, kann \u00fcber diese die Datenbasis auf einen definierten Zeitraum eingeschr\u00e4nkt werden. Anhand der so ermittelten Relationen k\u00f6nnen anschlie\u00dfend die zugeh\u00f6rigen Knotenpunkte geladen werden. <sup>35</sup> \u00dcber diese Auswahl bestimmter Ausschnitte k\u00f6nnen Artikel und deren Autor*innengruppen auch zeitdiskret miteinander verglichen werden. Weiterhin erm\u00f6glicht dieses Generieren von zeitlichen Ausschnitten die Analyse der Entwicklung der sprachlichen Zusammensetzung eines einzelnen Artikels \u00fcber mehrere Zeitr\u00e4ume hinweg.</p> <p>F\u00fcr die Analyse der Autor*innengruppen ergeben sich drei Muster: der Schnittmengenvergleich, die Analyse der Sprachverteilung und die Kleingruppenanalyse. Beim Schnittmengenvergleich wird auf die \u00dcbereinstimmung von zwei oder mehr Autor*innengruppen gepr\u00fcft. Eine hohe \u00dcberdeckung bedeutet dabei, dass an den untersuchten Artikeln oder Artikelteilen die selben Autor*innen beteiligt waren. Eine fehlende \u00dcberdeckung beschreibt somit den Fall v\u00f6llig unterschiedlicher Autor*innengruppen. Die Analyse der Sprachverteilung erweitert diesen Ansatz auf die Sprachkenntnisse der beteiligten Autor*innen. \u00dcber diese Darstellung kann der Einfluss mehrsprachig agierender User visualisiert werden. Mittels serieller Vergleiche k\u00f6nnen somit \u00c4nderungen in der Zusammensetzung der Autorschaft eines Artikels identifiziert werden. Da die Netzwerkvisualisierung auf einer Gravitationssimulation beruht, k\u00f6nnen Schnittmengen und Sprachverteilungen jedoch nicht aus demselben Diagramm abgelesen werden. Die Relationen der einzelnen Knotenpunkte \u00e4ndert sich durch die Anwesenheit von mit ihnen verbundenen Sprachversions-Knotenpunkten, wodurch das Gesamtbild ver\u00e4ndert wird. Der dritte Anwendungsfall ist die Kleingruppenanalyse. Hier steht eine zuvor identifizierte Gruppe und die ihnen zugeordneten Schreibakte im Fokus der Visualisierung. Durch die Bestimmung h\u00e4ufig referenzierter Artikel k\u00f6nnen so f\u00fcr die untersuchte Gruppe relevante Themen identifiziert und die Gruppe selbst kritisiert werden.</p> <p>Im Folgenden werden diese Muster zur Diskussion der hier definierten Datens\u00e4tze angewandt:</p> Kennung Von Bis Fall Beschreibung en\u2070 1a, b Vollst\u00e4ndiger, englischer Artikel. en\u00b9 21.05.2009 18.06.2009 4a, b 20. Jahrestag Tiananmenproteste. en\u00b2 21.05.2019 18.06.2019 4a, b 30. Jahrestag Tiananmenproteste. en\u00b3 21.05.2020 18.06.2020 4a, b J\u00fcngster Jahrestag Tiananmenproteste. zh\u2070 1a, b Vollst\u00e4ndiger, chinesischer Artikel. zh\u00b9 01.03.2011 31.10.2014 2a, b; 4a Zeitraum ungesperrte chin.-Wikipedia. zh\u00b9a 01.03.2011 31.12.2012 2c Erste H\u00e4lfte von zh\u00b9. zh\u00b9b 01.01.2013 31.10.2014 2c; 3a, b Zweite H\u00e4lfte von zh\u00b9. zh\u00b2 01.05.2015 31.08.2020 2a, b; 4a Zeitraum gesperrte chin.-Wikipedia. zh\u00b2a 01.05.2015 31.12.2017 2d Erste H\u00e4lfte von zh\u00b2. zh\u00b2b 01.01.2018 31.08.2020 2d Zweite H\u00e4lfte von zh\u00b2."},{"location":"Kapitel_3.html#341-fall-1-referenzvergleich-en0-und-zh0-schnittmengen-der-untersuchten-artikel","title":"3.4.1 Fall 1: Referenzvergleich en\u2070 und zh\u2070 \u2013 Schnittmengen der untersuchten Artikel","text":"<p>Diese Analyse dient als Referenz und soll das Verh\u00e4ltnis von en\u2070 und zh\u2070, also der Artikel in ihrer Gesamtheit, darstellen. Zum Zeitpunkt der Datenerhebung hatte en\u2070 9.452 und zh\u2070 6.576 Artikelversionen. Es wurden keine weiteren Benutzerbeitr\u00e4ge erhoben und keine Knotenpunkte von der Auswertung ausgeschlossen. Der Datensatz umfasst somit 3473 verschiedene User, zwei Artikel und zwei Sprachversionen. Die Arbeitsdaten der folgenden Analysen sowie die interaktiven Netzwerk sind in entsprechend bezeichneten Ordnern der Arbeit beigelegt.</p> <p> </p> <p><code>Illustration 1: Fall 1a. Schnittstellenvergleich von en\u2070 und zh\u2070.</code></p> <p>Rot markiert und rechts im Bild ist der Knotenpunkt der chinesischen Sprache. <sup>36</sup> Er ist praktisch deckungsgleich mit dem Knotenpunkt zh\u2070. Eng um diese Knoten gruppiert sind die Autor*innen des Artikels. Auf der linken Seite zeigt sich bei en\u2070 und dem englischen Knotenpunkt ein identisches Bild. In der Bildmitte ist eine verh\u00e4ltnism\u00e4\u00dfig kleine Gruppe an Usern erkennbar, die sowohl an en\u2070 als auch an zh\u2070 beteiligt waren. In dieser Gruppe finden sich unter anderem auch der zu erwartende, global agierende InternetArchiveBot wieder. Diese erste Auswertung zeigt, dass unter Einbezug der gesamten Existenz und aller Autor*innen nur eine Minderheit sowohl am englischen wie auch chinesischen Artikel beteiligt war.</p> <p>Diese Darstellung umfasst jedoch nur die Sprachversionen der beiden untersuchten Artikel und suggeriert daher eine Homogenit\u00e4t unter den Bearbeitern des englischen beziehungsweise chinesischen Artikels. Dies kann durch die Auswertung der sonstigen Benutzerbeitr\u00e4ge der beteiligten Autor*innen in weiteren Sprachversionen relativiert werden. <sup>37</sup> Zur Begrenzung der Menge der auszuwertenden Daten werden je User und Sprachversion maximal zehn Artikel\u00adeintr\u00e4ge abgerufen. Der somit erzeugte Datensatz beinhaltet somit eine solide Stichprobe der Sprachfertigkeiten der beteiligten Autor*innen auf Grundlage ihrer Aktivit\u00e4t in der Wikipedia. Die Begrenzung der Benutzerbeitr\u00e4ge beschr\u00e4nkt diese Auswertung jedoch auf die Analyse der generellen Sprachfertigkeiten der beteiligten User. R\u00fcckschl\u00fcsse auf individuelle sprachliche Schwerpunkte sind damit nicht m\u00f6glich. Bei der Betrachtung einzelner User oder kleiner Usergruppen k\u00f6nnten wesentlich mehr Benutzerbeitr\u00e4ge je Benutzer und Sprachversion analysiert und somit eine Unterscheidung zwischen pr\u00e4ferierten und nur selten verwendeten Sprachkenntnissen getroffen werden. Trotz dieser Beschr\u00e4nkung umfasst dieser erweiterte Datensatz 2146 Artikel in verschiedenen Sprachversionen, die zum Gro\u00dfteil nur eine einzelne Relation zu einem einzelnen User aufweisen und somit die Lesbarkeit des Netzwerkes beeintr\u00e4chtigen, ohne einen inhaltlichen Mehrwert beizusteuern. Durch das Ausblenden aller Artikel mit weniger als zehn Relationen wird die Anzahl der anzuzeigenden Artikel auf 43 reduziert und somit die Lesbarkeit verbessert. Diese Artikel repr\u00e4sentieren weiterhin Schnittstellen zwischen mehreren Benutzern der untersuchten Gruppe.</p> <p></p> <p><code>Illustration 2: Fall 1b. Sprachverteilung zwischen en\u2070 und zh\u2070.</code></p> <p>Zwar ist die grundlegende Struktur des Falls 1a auch hier noch erkennbar, jedoch ist die scharfe Trennung der drei Autor*innengruppen einem viel komplexeren \u00dcbergang gewichen. Der verwendete Barnes-Hut-Algorithmus weist den Relationen eine gewisse Anziehungskraft zwischen den verbundenen Knotenpunkten zu, welche durch die H\u00e4ufigkeit der Relation gewichtet wird. Knotenpunkte, die durch viele Relationen verbunden werden, sind dementsprechend nah beieinander positioniert. Daraus ergeben sich Gruppierung von zusammengeh\u00f6rigen Autor*innen, Artikeln und Sprachversionen. Bei der Gegen\u00fcberstellung von en\u2070 und zh\u2070 zeigt sich, dass insbesondere der englische Artikel auch von Autor*innen verfasst wurde, die in mehr als einer Sprache an der Wikipedia mitschreiben. Am Netzwerk ist das durch die relative N\u00e4he der Knotenpunkte de, fr, es und it zu en zu erkennen. In dieser Verteilung der Sprachen unter den Autor*innen der beiden Artikel spiegelt sich weiterhin auch die geografische Herkunft der Sprachversionen wider. So erstaunt es kaum, dass sich bei der Autor*innengruppe des englischen Artikels vermehrt deutsche, franz\u00f6sische, spanische und italienische Einfl\u00fcsse finden, w\u00e4hrend den Bearbeitern des chinesischen Artikels insbesondere auch japanische Einfl\u00fcsse zugerechnet werden k\u00f6nnen. Der gr\u00f6\u00dfere Abstand des chinesischen Knotenpunkts zu allen anderen Sprachversionen deutet zudem auf eine geringer ausgepr\u00e4gte Mehrsprachigkeit unter den Autor*innen hin. <sup>38</sup> Der russische Sprachknoten steht weiterhin mit einigem Abstand zwischen den beiden Polen des Netzwerkes.</p> <p>Es ist festzuhalten, dass beide Artikel in ihrer jeweiligen Gesamtbetrachtung von einer mehrsprachigen Autorschaft verfasst wurden. Die Zusammensetzung dieser Autor*innengruppen folgt dabei geografischen Gegebenheiten, wodurch der englische Artikel im besonderen Ma\u00dfe auch von Autor*innen mit deutschen Sprachkenntnissen verfasst wurde, w\u00e4hrend der chinesische Artikel vermehrt japanische Einfl\u00fcsse in der Autor*innengruppe aufweist. Quantitativ ist der englische Artikel dabei jedoch st\u00e4rker von multilingualen Usern gepr\u00e4gt, als der chinesische.</p>"},{"location":"Kapitel_3.html#342-fall-2-gruppenvergleich-zh1-und-zh2-zur-sperrung-der-chinesischen-wikipedia","title":"3.4.2 Fall 2: Gruppenvergleich zh\u00b9 und zh\u00b2 \u2013 zur Sperrung der chinesischen Wikipedia","text":"<p>Die Historie der chinesischen Wikipedia l\u00e4sst eine Z\u00e4sur auch in der Autor*innengruppe erwarten. Diesen Umbruch gilt es zun\u00e4chst durch einen Vergleich der Zeitabschnitte des Artikels jeweils vor und nach der Sperrung zu \u00fcberpr\u00fcfen. Laut GreatFire Analyzer war die Wikipedia bis Ende Oktober 2014 zug\u00e4nglich und ab Anfang Mai 2015 mit relativer Sicherheit gesperrt. <sup>39</sup> Da die Aufzeichnungen des Analyzers nur bis M\u00e4rz 2011 reichen wird der Datensatz zh\u00b9 somit durch den Zeitraum vom 01. M\u00e4rz 2011 bis zum 31. Oktober 2014 definiert und umfasst damit 307 Benutzer. Der Vergleichsdatensatz zh\u00b2 repr\u00e4sentiert den Zeitraum vom 01. Mai 2015 bis zum 31. August 2020 mit insgesamt 410 Benutzern. Die Datenlage zwischen November 2014 und April 2015 kann auf Grundlage des Analyzers nicht eindeutig eingesch\u00e4tzt werden und wird somit von dieser Untersuchung ausgeschlossen. Die Erhebung der Daten findet analog zum Fall 1 statt, jedoch muss in einem Zwischenschritt zun\u00e4chst der Artikelname je Datensatz mit einem Alias ersetzt werden, damit die Relationen korrekt zugeordnet werden k\u00f6nnen. Die Benutzerbeitr\u00e4ge sowie Sprachversionen werden erneut in einem zweiten Schritt in die Untersuchung einbezogen.</p> <p></p> <p><code>Illustration 3: Fall 2a. Schnittstellenvergleich von zh\u00b9 und zh\u00b2. (01.03.2011 \u2013 31.10.2014 und 01.05.2015 - 31.08.2020)</code></p> <p>Das sich ergebende Muster weist starke \u00c4hnlichkeiten zur Illustration 1 auf. Der Unterschied der Benutzergruppen der Post-Blockade-Wikipedia und der Pr\u00e4-Blockade-Wikipedia gleicht somit dem Unterschied zwischen dem vollst\u00e4ndigen englischen und dem vollst\u00e4ndigen chinesischen Artikel. Diese weitgehende Trennung der Autor*innengruppen st\u00fctzt vorangegangene Befunde der Sperrung.</p> <p>Um die Benutzerbeitr\u00e4ge und somit deren Sprachzuordnung auch im Kontext des definierten zeitlichen Rahmens auswerten zu k\u00f6nnen, musste die Datenabfrage mit einem offset versehen werden. <sup>40</sup> So wurde sichergestellt, dass die erhobenen Daten das Bearbeitungsverhalten der User innerhalb des untersuchten Zeitabschnittes widerspiegeln. Anschlie\u00dfend wurden auf dieser Datenbasis die selben Zwischenschritte wie im Fall 2a durchgef\u00fchrt und schlie\u00dflich die Sprachverteilung der Datens\u00e4tze analog zu Fall 1b ermittelt.</p> <p></p> <p><code>Illustration 4: Fall 2b. Sprachverteilung zwischen zh\u00b9 und zh\u00b2. (01.03.2011 \u2013 31.10.2014 und 01.05.2015 \u2013 31.08.2020)</code></p> <p>Im Gegensatz zu Illustration 2 lassen sich bei diesem Netzwerk keine eindeutigen Pole mehr erkennen. Trotz der zuvor ermittelten Trennung der Autor*innengruppen von zh\u00b9 und zh\u00b2 zeigt sich unter Einbezug der Sprachversionen ein intensiver Einfluss mehrsprachig agierender User bei beiden Datens\u00e4tzen. \u00dcberraschend ist jedoch, dass zh\u00b9 im direkten Vergleich zu zh\u00b2 eine ausgepr\u00e4gte relative N\u00e4he zum Cluster der nicht-chinesischen Sprachversionen aufweist. Dadurch ist zu schlie\u00dfen, dass die chinesische Sprachversion des Artikels vor der Sperrung einen gr\u00f6\u00dferen internationalen Einfluss hatte, als danach. Die steht zun\u00e4chst im direkten Kontrast zur angenommenen Dominanz der chinesischen Akteure im Zuge der Informationskontrolle der KPC. Zur weiteren Analyse werden die beiden Vergleichsdatens\u00e4tze jeweils geteilt und die Teilmengen untereinander auf \u00dcbereinstimmung untersucht. Zur Pr\u00fcfung von zh\u00b9 entstehen somit zwei jeweils 22 Monate umfassende Datens\u00e4tze. Dabei beschreibt zh\u00b9a den Zeitraum vom 01. M\u00e4rz 2011 bis zum 31. Dezember 2012 und zh\u00b9b den Zeitraum vom 01. Januar 2013 bis zum 31. Oktober 2014.</p> <p></p> <p><code>Illustration 5: Fall 2c. Sprachverteilung zwischen zh\u00b9a und zh\u00b9b. (01.03.2011 \u2013 31.12.2012 und 01.01.2013 \u2013 31.10.2014)</code></p> <p>Die Positionierung der Artikelknoten zeigt hier, dass zh\u00b9b einem deutlichen Einfluss des Clusters der nicht-chinesischen Sprachen unterliegt, w\u00e4hrend zh\u00b9a klar von einer Gruppe aus nur einer Sprache zugeordneten Usern bestimmt wird. Der bereits in Illustration 4 identifizierte intensive internationale Einfluss ist somit ein Ph\u00e4nomen, dass der zweiten H\u00e4lfte des Zeitraums zh\u00b9 zuzuordnen ist. Die exakte Gestalt dieses Einflusses l\u00e4sst sich aus diesem Datensatz jedoch nicht ablesen. Vorstellbar sind jedoch zwei Szenarien: Eine Ausweitung des Aktionsraumes des chinesischen Akteure oder eine verst\u00e4rkte Aktivit\u00e4t nicht-chinesischer Akteure im untersuchten Artikel. In Anbetracht des eingeschr\u00e4nkten Zugangs zu internationalen Webangeboten erscheint der zweite Erkl\u00e4rungsansatz jedoch wahrscheinlicher. Zur Bewertung dieses Ph\u00e4nomens m\u00fcsste der Fokus der Untersuchung angepasst und das Wirken einzelner Akteure genauer untersucht werden. Diese Analyse wird im Fall 3: Kleingruppenanalyse zh\u00b9b fortgef\u00fchrt.</p> <p>Analog zu Fall 2c wird zun\u00e4chst der Datensatz zh\u00b2 gepr\u00fcft. Hierzu wurden zwei Datens\u00e4tze zu je 32 Monaten gebildet, wodurch zh\u00b2a den Zeitraum vom 01. Mai 2015 bis 31. Dezember 2017 beschreibt und zh\u00b2b den 01. Januar 2018 bis 31. August 2020 umfasst.</p> <p></p> <p><code>Illustration 6: Fall 2d. Sprachverteilung zwischen zh\u00b2a und zh\u00b2b. (01.05.2015 \u2013 31.12.2017 und 01.01.2018 \u2013 31.08.2020)</code></p> <p>Im Gegensatz zu zh\u00b9 zeigt sich hier eine Parallelit\u00e4t der beiden Teilmengen. Da die relative Position zu den einzelnen Sprachknotenpunkten als ann\u00e4hernd gleich betrachtet werden kann, kann in Bezug auf die Sprachverteilung von einer gleichartigen Autor*innengruppe bei zh\u00b2a und zh\u00b2b ausgegangen werden. Einer gewissen, in Anbetracht des zeitlichen Rahmens zu erwartenden, Ver\u00e4nderung war die Autor*innengruppe jedoch ausgesetzt, sonst w\u00fcrden die beiden Knotenpunkte sich \u00fcberdecken. Von den drei untersuchten Teilmengen weist somit nur zh\u00b9b eine signifikante Abweichung in der Zusammensetzung der Autor*innen auf.</p>"},{"location":"Kapitel_3.html#343-fall-3-kleingruppenanalyse-zh1b","title":"3.4.3 Fall 3: Kleingruppenanalyse zh\u00b9b","text":"<p><code>Illustration 7: Fall 3a. Detailansicht der Sprachverteilung von zh\u00b9b. (01.01.2013 \u2013 31.10.2014)</code></p> <p>In der Detailansicht des Datensatzes zh\u00b9b kann die Gruppe der im besonderen Ma\u00dfe international agierenden Benutzer gut bestimmt und die zugeh\u00f6rigen Benutzernamen ermittelt werden. <sup>41</sup> Auf dieser Grundlage k\u00f6nnen die zugeh\u00f6rigen Benutzerbeitr\u00e4ge abgerufen werden. Um eine m\u00f6glichst belastbare Datenbasis pro User zu erzielen, werden pro Sprache und Benutzer bis zu 500 Eintr\u00e4ge erhoben und anschlie\u00dfend der Datensatz auf den durch zh\u00b9b definierten Zeitraum eingegrenzt. <sup>42</sup> Bots wurden von der Auswahl ausgeschlossen, da dieser Fall die weitere Themenauswahl der Autor*innen behandelt.</p> <p></p> <p><code>Illustration 8: Fall 3b. Detailansicht der international agierenden Autor\\*innengruppe in zh\u00b9b. (01.01.2013 \u2013 31.10.2014)</code></p> <p>Wie erwartet, zeichnet sich die Usergruppe durch eine ausgepr\u00e4gte Vielsprachigkeit aus, jedoch zeigen sich starke Pr\u00e4ferenzen f\u00fcr die englische und chinesische Sprachversion. Der Grenzwert f\u00fcr zu inkludierende Artikel wurde in Anbetracht der geringen Datensatzgr\u00f6\u00dfe auf drei Relationen gesetzt. Damit wurden 38 Artikel ermittelt, von denen 16 auff\u00e4llige Themengebiete betreffen, die in der untenstehenden Tabelle aufgef\u00fchrt sind. Die sonstigen Artikel sind vorrangig den Wartungs- und Benutzerseiten zuzurechnen.</p> Titel (original) Titel (\u00fcbersetzt) Kommentar Wikipedia:\u8bf7\u6c42\u4fdd\u62a4\u9875\u9762 Wikipedia:Entsperrw\u00fcnsche \u5927\u97e9\u6c11\u56fd S\u00fcdkorea Kennedy Town station Bahnstation in Hong Kong. Wikipedia:\u7ba1\u7406\u54e1\u89e3\u4efb\u6295\u7968/\u4e4c\u62c9\u8de8\u6c2a Wikipedia: Admin Dismissal Voting/Ula Cross Krypton  Abstimmung zur Entfernung eines Admins zwischen dem 29.08.2014 und 18.09.2014. <sup>43</sup> Wikipedia:\u5f53\u524d\u7684\u7834\u574f Wikipedia:Vandalismusmeldung East Turkestan independence movement Uigurische Unabh\u00e4ngigkeitsbewegung. \u963f\u514b\u8d5b\u94a6 Aksai Chin Umstrittenes Gebiet im westlichen Teil der chinesisch-indischen Grenze. \u516d\u56db\u4e8b\u4ef6 \u201eVorfall vom 4. Juni\u201c Tiananmenplatz-Proteste. \u897f\u975e\u4f0a\u6ce2\u62c9\u75c5\u6bd2\u75ab\u75c7 Ebolafieber-Epidemie 2014 bis 2016 \u9093\u5c0f\u5e73 Deng Xiaoping \u4e60\u8fd1\u5e73 Xi Jinping 2014\u5e7410\u6708 Oktober 2014 Monats\u00fcberblick, u.a. Umbrellarevolution. \u8b93\u611b\u8207\u548c\u5e73\u4f54\u9818\u4e2d\u74b0 Occupy Central with Love and Peace Politische Kampagne in Hong Kong, die mitverantwortlich f\u00fcr die Proteste 2014 war. \u9999\u6e2f\u8b66\u52d9\u8655 Polizei Hong Kongs \u65b9\u6fdf\u5404 (\u6559\u5b97) Papst Franziskus Im Artikel wird der Besuch der Dioz\u00f6se in Hong Kong im Oktober 2014 erw\u00e4hnt. \u7530\u5317\u4fca James Tien Pei-chun Politiker, Hong Kong. <p>Diese Zusammensetzung der Artikel ist bemerkenswert, da insbesondere politisch relevante und potentiell umstrittene Inhalte dominieren. Es ist festzuhalten, dass diese durch die Analyse der Sprachverteilung identifizierte Gruppe einen signifikanten Anteil ihrer Bearbeitungen in Artikeln geleistet hat, die sowohl im historischen Kontext, als auch heute, als f\u00fcr die KPC sensibel zu bewerten sind. Ohne eine genaue Analyse der einzelnen Schreibakte kann hier jedoch keine abschlie\u00dfende Beurteilung stattfinden.</p>"},{"location":"Kapitel_3.html#344-fall-4-gruppenvergleich-en1-en2-und-en3-mit-zh1-und-zh2-jahrestage-der-tiananmenproteste","title":"3.4.4 Fall 4: Gruppenvergleich en\u00b9, en\u00b2 und en\u00b3 mit zh\u00b9 und zh\u00b2 \u2013 Jahrestage der Tiananmenproteste","text":"<p><code>Illustration 9: Fall 4a. Schnittmengenvergleich von en\u00b9, en\u00b2 und en\u00b3 mit zh\u00b9 und zh\u00b2. (en: 21.05.2009 \u2013 18.06.2009, 21.05.2019 \u2013 18.06.2019 und 21.05.2020 \u2013 18.06.2020 sowie zh: 01.03.2011 \u2013 31.10.2014 und 01.05.2015 \u2013 31.08.2020)</code></p> <p>Die Datens\u00e4tze zh\u00b9 und zh\u00b2 bezeichnen wieder die Autor*innengruppen des chinesischen Artikels zu den Tiananmenplatz-Protesten jeweils vor und nach der Sperrung der chinesischen Wikipedia. Dem gegen\u00fcbergestellt sind en\u00b9, en\u00b2 und en\u00b3, die jeweils einen Zeitraum von vier Wochen um die Jahrestage der Proteste in den Jahren 2009, 2019 sowie 2020 repr\u00e4sentieren. Der Vergleich der einzelnen Autor*innengruppen zeigt, dass praktisch keine Schnittmengen zwischen den ermittelten Datens\u00e4tzen existieren. Eine Beteiligung der Autor*innen des chinesischen Artikels ist somit zumindest auf der Ebene der Accounts auszuschlie\u00dfen.</p> <p></p> <p><code>Illustration 10: Fall 4b. Sprachverteilung zwischen en\u00b9, en\u00b2 und en\u00b3. (21.05.2009 \u2013 18.06.2009, 21.05.2019 \u2013 18.06.2019 und 21.05.2020 \u2013 18.06.2020)</code></p> <p>Die Visualisierung der Sprachverteilung zeigt das Englische klar als zentralen Sprachknoten unter geringerer Beteiligung der deutschen und italienischen Knotenpunkte. Die restlichen Sprachen sind jeweils mit einer bis drei Relationen vertreten, darunter auch das Chinesische. Von den drei Usern mit chinesischen Relationen war CentreLeftRight an en\u00b3 und Wwbread und die IP 202.40.139.164 an en\u00b9 beteiligt. Die \u00c4nderungen der benannten User beschr\u00e4nkten sich auf Details und sprachliche Korrekturen, wohingegen der anonyme User eine unbelegte und dementsprechend zuvor gekennzeichnete Behauptung zur H\u00f6he der Opfer entfernte. <sup>44</sup> Weder mittels der Schnittmengenanalyse, noch der Auswertung der Sprachverteilung konnten somit Auff\u00e4lligkeiten innerhalb der Autor*innengruppen zum Zeitpunkt der Jahrestage der Tiananmenplatz-Proteste identifiziert werden.</p>"},{"location":"Kapitel_3.html#35-zusammenfassung-und-interpretation-der-ergebnisse","title":"3.5 Zusammenfassung und Interpretation der Ergebnisse","text":"<p>Auf Grundlage der Akteursgruppen konnten keine Indizien f\u00fcr einen relevanten Einfluss chinesischer Akteure auf den Inhalt des englischen Artikels zu den Jahrestagen der Proteste 2009, 2019 und 2020 festgestellt werden. Eine kleine Gruppe von Usern, die auch in chinesischen Artikeln aktiv war, zeigte in der Einzelbetrachtung kein auff\u00e4lliges Bearbeitungs\u00adverhalten.</p> <p>Weiterhin ist festzuhalten, dass der chinesische Artikel zu jedem Zeitpunkt einer gewissen Beteiligung durch international agierende User unterworfen war. Bemerkenswert ist dabei, dass die Aktivit\u00e4t mehrsprachig arbeitender Autor*innen in den Jahren kurz vor der Sperrung der chinesischen Wikipedia stark anstieg und nach deren Sperrung wieder abnahm. Eine feinere Untersuchung der beteiligten Akteursgruppen ergab, dass diese vermehrt politisch sensible Themen bearbeiteten. Dieses Ph\u00e4nomen kann sehr unterschiedlich gedeutet werden. So erscheint es wahrscheinlich, dass chinesische User zum Schutz der eigenen Identit\u00e4t VPN-Services oder vergleichbare Technologien eingesetzt und sich somit unter Nutzung ausl\u00e4ndischer IP-Adressen im Internet bewegt haben. Gegen diese These spricht jedoch die Art der Bestimmung international agierender Autor*innen im vorgestellten System. Da diese Zuordnung ausschlie\u00dflich auf den Schreibakten in verschiedenen Sprachversionen der Wikipedia beruht, spielt die IP-Adresse selbst keine Rolle. Die hier vermuteten User h\u00e4tten somit nicht nur entsprechende Services nutzen m\u00fcssen, um \u00fcberhaupt Zugang zu anderen Sprachversionen zu erhalten, sondern sich zudem aktiv an diesen beteiligen. Somit erscheint es wahrscheinlicher, dass diese ver\u00e4nderte Zusammensetzung auf einer erh\u00f6hten internationalen Aufmerksamkeit der chinesischen Wikipedia beruhte. Insbesondere User aus Taiwan oder Hong Kong k\u00f6nnten ein Interesse am Aussagegehalt verschiedener Artikel in der chinesischen aber auch in anderen Sprachversionen gehabt haben. Dieser zunehmende internationale Widerspruch k\u00f6nnte schlie\u00dflich zur Sperrung der chinesischen Wikipedia gef\u00fchrt haben. Die vorgestellten Ergebnisse und resultierenden Thesen k\u00f6nnen selbstverst\u00e4ndlich nur als Grundlage f\u00fcr die eigentliche Auswertung der Quellen verstanden werden.</p> <p>Gleichwohl ist zu beachten, dass die ausgew\u00e4hlten Gruppen jeweils relativ kleine Stichproben darstellen. Es ist nicht auszuschlie\u00dfen, dass eine Pr\u00fcfung gegen einen breiten Querschnitt von Artikeln der chinesischen Wikipedia abweichende Ergebnisse hervorgebracht h\u00e4tte. Zwar erscheint die Untersuchung auf die Sprachverteilung der User eine robuste Erg\u00e4nzung zum Direktvergleich zu sein, jedoch schlie\u00dft die Beschr\u00e4nkung auf die acht aktivsten Sprachversionen m\u00f6glicherweise lokal relevante Sprachversionen aus. Hier muss stets eine Abw\u00e4gung zwischen dem Anspruch auf Vollst\u00e4ndigkeit sowie der arbeitspraktischen \u00dcberlegung der Performanz im Sinne der Auswertungszeit getroffen werden.</p> <ol> <li> <p>Vgl. Becker, Kim-Bj\u00f6rn: Internetzensur in China: Aufbau und Grenzen des chinesischen Kontrollsystems, Wiesbaden 2011, S. 102\u2013104.\u00a0\u21a9</p> </li> <li> <p>Siehe Leica China video sparks backlash over Tiananmen Square image, in: BBC News, 19.04.2019. Online: https://www.bbc.com/news/world-asia-china-47987817, Stand: 17.09.2020.\u00a0\u21a9</p> </li> <li> <p>Siehe Kent, Emma: Activision removes Tiananmen Square footage in Call of Duty: Black Ops Cold War trailer, in: Eurogamer, 25.08.2020. Online: https://www.eurogamer.net/articles/2020-08-25-activision-removes-tiananmen-square-footage-in-call-of-duty-black-ops-cold-war-trailer-after-china-ban, Stand: 04.09.2020.\u00a0\u21a9</p> </li> <li> <p>Siehe 1989 Tiananmen Square protests, in: Wikipedia, Online: https://en.wikipedia.org/wiki/1989_Tiananmen_Square_protests.\u00a0\u21a9</p> </li> <li> <p>Laut wikistats.wmflabs.org hat die englischsprachige Wikipedia mit Stand 21.06.2020 \u00fcber 6,1 Millionen Artikel und verf\u00fcgt \u00fcber 141.495 User, die sich innerhalb der letzten 30 Tage am Projekt beteiligt haben. Platz zwei belegt die vorwiegend durch automatisierte Verfahren gepflegte cebuanosprachige Wikipedia sowie mit 21.009 aktiven Usern die franz\u00f6sischsprachige Wikipedia. Siehe WikiStats - List of Wikipedias, http://wikistats.wmflabs.org/display.php?t=wp, Stand: 21.06.2020 ; Siehe Cebuanosprachige Wikipedia, in: Wikipedia, 09.06.2020. Online: https://de.wikipedia.org/w/index.php?title=Cebuanosprachige_Wikipedia&amp;oldid=200773707.\u00a0\u21a9</p> </li> <li> <p>Vgl. Ban, Kristina; Perc, Matja\u017e; Levnaji\u0107, Zoran: Robust clustering of languages across Wikipedia growth, in: Royal Society Open Science 4 (10), Royal Society, 18.10.2017, S. 9\u201311. Online: https://doi.org/10.1098/rsos.171217.\u00a0\u21a9</p> </li> <li> <p>Vgl. Kim, Suin; Park, Sungjoon; Hale, Scott A. u. a.: Understanding Editing Behaviors in Multilingual Wikipedia, in: PLOS ONE 11 (5), 12.05.2016, S. 18. Online: https://doi.org/10.1371/journal.pone.0155305.\u00a0\u21a9</p> </li> <li> <p>Chin.: 4. Juni Vorfall. Siehe \u516d\u56db\u4e8b\u4ef6 , in: Wikipedia, Online: https://zh.wikipedia.org/wiki/ \u516d\u56db\u4e8b\u4ef6 .\u00a0\u21a9</p> </li> <li> <p>Der Zugriff auf Webseiten aus der Volksrepublik China heraus kann mittels des Great Fire Analyzer gepr\u00fcft sowie vergangene Anfragen eingesehen werden. Demnach wurden Anfragen an die Adresse zh.wikipedia.org ab etwa November 2014 regelm\u00e4\u00dfig geblockt. Siehe: zh.wikipedia.org is 100% blocked in China - GreatFire Analyzer, https://en.greatfire.org/zh.wikipedia.org, Stand: 21.06.2020. Die Autorin hat anhand teilautomatisierter Bildanalysen dieses Ph\u00e4nomen bereits in einer fr\u00fcheren Arbeit diskutiert und best\u00e4tigt. Siehe: Krug: Zensur in Bildern, 2020. Die ersten Sperrungen d\u00fcrfen zwischen 2004 und 2006 angenommen werden. Vgl. Wozniak; Nemitz; Rohwedder (Hg.): Wikipedia und Geschichtswissenschaft, 2015, S. 240. Die Einsch\u00e4tzung der Nutzerverteilung nach 2015 basiert auf der Relevanz der chinesischen Sprache in diesen L\u00e4ndern. Siehe: Chinesische Sprachen, in: Wikipedia, 09.06.2020. Online: https://de.wikipedia.org/w/index.php?title=Chinesische_Sprachen&amp;oldid=200775114.\u00a0\u21a9</p> </li> <li> <p>Zur Relevanz der sozialen Stabilit\u00e4t vgl. Shirk, Susan L.: China: Fragile Superpower, New York 2008, S. 52 f.  (\u00a0\u21a9</p> </li> <li> <p>Siehe hierzu Kapitel 3.3 Datenbezug und Sicherung.\u00a0\u21a9</p> </li> <li> <p>Siehe Wikipedia:Sprachen, in: Wikipedia, 17.08.2020. Online: https://de.wikipedia.org/w/index.php?title=Wikipedia:Sprachen&amp;oldid=202859530.\u00a0\u21a9</p> </li> <li> <p>So zum Beispiel die Cebuanosprachige Wikipedia, die zwar Stand August 2020 fast 5,4 Millionen Artikel beinhaltet, aber nur etwa 172 aktive User. Hier kann davon ausgegangen werden, dass die Mehrzahl aller Bearbeitungen von Bots durchgef\u00fchrt wurden. Die Deutsche Wikipedia hat im Vergleich dazu knapp 2,5 Millionen Artikel bei 18.734 aktiven Benutzern. Siehe Cebuanosprachige Wikipedia, in: Wikipedia, 11.08.2020. Online: https://de.wikipedia.org/w/index.php?title=Cebuanosprachige_Wikipedia&amp;oldid=202699311.\u00a0\u21a9</p> </li> <li> <p>Siehe Wikipedia:About, in: Wikipedia, 17.07.2020. Online: https://en.wikipedia.org/w/index.php?title=Wikipedia:About&amp;oldid=968062551.\u00a0\u21a9</p> </li> <li> <p>Siehe Manual:Contents - MediaWiki, https://www.mediawiki.org/wiki/Manual:Contents, Stand: 14.08.2020 ; sowie Developer hub - MediaWiki, https://www.mediawiki.org/wiki/Developer_hub, Stand: 14.08.2020 ; und MediaWiki: Introduction, MediaWiki Class Reference, https://doc.wikimedia.org/mediawiki-core/master/php/index.html, Stand: 14.08.2020.\u00a0\u21a9</p> </li> <li> <p>Siehe MediaWiki: RevDelRevisionItem Class Reference, https://doc.wikimedia.org/mediawiki-core/master/php/classRevDelRevisionItem.html, Stand: 13.08.2020 ; sowie MediaWiki: RevisionItemBase Class Reference, https://doc.wikimedia.org/mediawiki-core/master/php/classRevisionItemBase.html, Stand: 13.08.2020.\u00a0\u21a9</p> </li> <li> <p>Siehe MediaWiki: Article Class Reference, l. 467 in Article.php, https://doc.wikimedia.org/mediawiki-core/master/php/classArticle.html#details, Stand: 13.08.2020. 120 Siehe MediaWiki: HistoryAction Class Reference, l. 333 in HistoryAction.php, https://doc.wikimedia.org/mediawiki-core/master/php/classHistoryAction.html#details, Stand: 13.08.2020.\u00a0\u21a9</p> </li> <li> <p>Siehe MediaWiki: EditAction Class Reference, https://doc.wikimedia.org/mediawiki-core/master/php/classEditAction.html#details, Stand: 13.08.2020 ; sowie MediaWiki: EditPage Class Reference, l. 1730 in EditPage.php, https://doc.wikimedia.org/mediawiki-core/master/php/classEditPage.html, Stand: 13.08.2020.\u00a0\u21a9</p> </li> <li> <p>Siehe MediaWiki: ContribsPager Class Reference, l. 595 in ContribsPager.php,https://doc.wikimedia.org/mediawiki-core/master/php/classContribsPager.html, Stand: 15.08.2020.\u00a0\u21a9</p> </li> <li> <p>Siehe Query: Advanced Search, Phabricator, https://phabricator.wikimedia.org/search/query/advanced/, Stand: 13.08.2020.\u00a0\u21a9</p> </li> <li> <p>Siehe auch Kapitel 2.3 Quellensicherung.\u00a0\u21a9</p> </li> <li> <p>API: Application Programming Interface, maschinenlesbare Schnittstelle zu einer Plattform wie z.B. Wikipedia. Einen Einstieg in die API des MediaWikis bietet die entsprechende Hilfe-Seite. Siehe: Hilfe:Versionen, in: Wikipedia, 10.05.2020. Online: https://de.wikipedia.org/w/index.php? title=Hilfe:Versionen&amp;oldid=199804860.\u00a0\u21a9</p> </li> <li> <p>Vgl. Sahle; Henny: Klios Algorithmen: Automatisierte Auswertung von Wikipedia-Inhalten als Faktenbasis und Diskursraum, 2015, S. 122.\u00a0\u21a9</p> </li> <li> <p>Mit der HTML Sprachversion 4.1 wurde die Kompatibilit\u00e4t zu XML strukturell verankert, der W3C-Standard hie\u00df fortan XHTML. Siehe: Extensible Hypertext Markup Language, in: Wikipedia, 27.05.2020. Online: https:// de.wikipedia.org/w/index.php?title=Extensible_Hypertext_Markup_Language&amp;oldid=200389260.\u00a0\u21a9</p> </li> <li> <p>Vgl. Sahle; Henny: Klios Algorithmen: Automatisierte Auswertung von Wikipedia-Inhalten als Faktenbasis und Diskursraum, 2015, S. 146.\u00a0\u21a9</p> </li> <li> <p>Die im Folgenden erw\u00e4hnten Quelltextausschnitte sind im Kapitel Quelltext angehangen.\u00a0\u21a9</p> </li> <li> <p>Siehe Quelltextdokumentation unter: DEF _ GET _ XML _ DATA ( SELF , URL , STYLESHEET ). Zur Dokumentation der Library siehe: Requests: HTTP for Humans TM \u2014 Requests 2.24.0 documentation,https://requests.readthedocs.io/en/master/, Stand: 28.06.2020.\u00a0\u21a9</p> </li> <li> <p>Die Schemata sind im Anhang dokumentiert. Siehe das Kapitel XSLT-Schemata.\u00a0\u21a9</p> </li> <li> <p>Siehe z.B.: lxml API, https://lxml.de/api/index.html, Stand: 29.06.2020.\u00a0\u21a9</p> </li> <li> <p>Siehe Quelltextdokumentation unter: DEF ADD _ ARTICLE _ DATA ( SELF , URL ).\u00a0\u21a9</p> </li> <li> <p>Siehe auch Kapitel 2.4.3 Relationen.\u00a0\u21a9</p> </li> <li> <p>Siehe Quelltextdokumentation unter: DEF COMPUTE _ LANGUAGE ( SELF ).\u00a0\u21a9</p> </li> <li> <p>Siehe Quelltextdokumentation unter: DEF ADD _ USERCONTRIBUTIONS ( SELF , DEPTH = \"100\", OFFSET = \"\", USERS = N ONE ).\u00a0\u21a9</p> </li> <li> <p>Siehe Quelltextdokumentation unter: DEF DELETE _ NODES _ BY _ COUNT ( SELF , EDGE C OUNT = 2, USER = F ALSE ).\u00a0\u21a9</p> </li> <li> <p>Siehe Quelltextdokumentation unter: DEF RETURN _ INTERVAL ( SELF , BEGIN , END ).\u00a0\u21a9</p> </li> <li> <p>Quadratische Knotenpunkte stellen in den Netzwerkillustrationen stets Sprachversionen dar, Punkte stehen f\u00fcr User und Sterne f\u00fcr Artikel.\u00a0\u21a9</p> </li> <li> <p>Die Auswahl der Sprachversionen wird im Kapitel 3.1 Heuristik diskutiert.\u00a0\u21a9</p> </li> <li> <p>Dies ist rein im Sinne der Beteiligung der User zu verstehen. Den Usern aus der Autor*innengruppe zh0 konnten im Vergleich zu en0 weniger Bearbeitungen in anderen Sprachversionen zugewiesen werden. Weiterhin muss hierbei auch bedacht werden, dass die Auswahl der untersuchten Wikipedia-Sprachversionen durch die Anzahl der jeweils aktiven Bearbeiter getroffen wurde und somit insbesondere die europ\u00e4ischen Sprachversionen in dieser Untersuchung st\u00e4rker repr\u00e4sentiert sind. Die explizite Analyse von regional verbreiteten Sprachversionen k\u00f6nnte zu einem etwas ver\u00e4nderten Bild f\u00fchren.\u00a0\u21a9</p> </li> <li> <p>Siehe zh.wikipedia.org is 100% blocked in China - GreatFire Analyzer, https://en.greatfire.org/zh.wikipedia.org, Stand: 21.06.2020.\u00a0\u21a9</p> </li> <li> <p>Siehe Quelltextdokumentation unter: DEF ADD _ USERCONTRIBUTIONS ( SELF , DEPTH = \"100\", OFFSET = \"\", USERS = NONE ).\u00a0\u21a9</p> </li> <li> <p>Die Benutzernamen sind im interaktiven Netzwerk nur bei hohen Vergr\u00f6\u00dferungsstufen sichtbar und deshalb in der Illustration nicht zu erkennen. Die Datei befindet sich im Unterverzeichnis zum Testfall.\u00a0\u21a9</p> </li> <li> <p>Siehe Quelltextdokumentation unter: DEF ADD _ USERCONTRIBUTIONS ( SELF , DEPTH = \"100\", OFFSET = \"\", USERS = NONE ).\u00a0\u21a9</p> </li> <li> <p>Siehe Wikipedia: \u7ba1\u7406\u54e1\u89e3\u4efb\u6295\u7968 / \u4e4c\u62c9\u8de8\u6c2a , in: Wikipedia, the free encyclopedia, 07.08.2020. Online:https://zh.wikipedia.org/w/index.php?title=Wikipedia: \u7ba1\u7406\u54e1\u89e3\u4efb\u6295\u7968 / \u4e4c\u62c9\u8de8\u6c2a &amp;oldid=61040597.\u00a0\u21a9</p> </li> <li> <p>Siehe CentreLeftRight: User contributions, in: Wikipedia, 02.06.2020. Online; siehe Wwbread: User contributions, in: Wikipedia, 15.06.2009. Online; siehe 202.40.139.164: User contributions, in: Wikipedia, 11.06.2009. Online.\u00a0\u21a9</p> </li> </ol>"},{"location":"Kapitel_4.html","title":"Fazit und Ausblick","text":"<p>Die in dieser Arbeit vorgestellte Methodik zeigt, wie fl\u00fcchtige Quellen und anonyme Autor*innengruppen im Rahmen einer strukturierten, digital-historischen Quellenkritik analysiert werden k\u00f6nnen. Bei der Bewertung der Validit\u00e4t der untersuchten Quellen im Kontext der \u00e4u\u00dferen Quellenkritik hat sich die Orientierung an den die digitalen Quellen erzeugenden Prozessen als zielf\u00fchrend erwiesen. In Anlehnung an Methoden aus der Softwareentwicklung und Qualit\u00e4tssicherung konnten fundierte Aussagen \u00fcber die Validit\u00e4t von genuin digitalen Quellen getroffen werden. So konnte durch die Identifikation der an der Erzeugung der Benutzerbeitr\u00e4ge und Artikelhistorien beteiligten Programmteile spezifisch nach gemeldeten oder bereits behobenen Fehlern im \u00f6ffentlich zug\u00e4nglichen Bugtracking-System gesucht werden. Die \u00dcberpr\u00fcfung im Rahmen des Fallbeispiels lies darauf schlie\u00dfen, dass die verantwortlichen Programmteile fehlerfrei und die zu untersuchenden Daten somit keine Abweichungen vom erwarteten Zustand aufweisen. Weiterhin vermittelte die technische Analyse der zugrunde liegenden Software einen tieferen Einblick in die Datenstrukturen und f\u00fchrte somit zu einem besseren Verst\u00e4ndnis des Quellengegenstandes.</p> <p>Diese grunds\u00e4tzlich prozesskritische Haltung sollte jedoch nicht nur auf genuin digitale Quellenbest\u00e4nde angewandt werden. Auch Retrodigitalisate sind zwangsl\u00e4ufig das Ergebnis von digitalen Verarbeitungsprozessen. Die kritische Analyse der dabei eingesetzten Technologien k\u00f6nnte dabei helfen, Probleme wie den Xerox-Bug fr\u00fchzeitig identifizieren zu k\u00f6nnen. <sup>1</sup> Diese Herangehensweise ist prinzipiell auf jedes informationstechnische System \u00fcbertragbar, jedoch variiert der Aufwand und die Komplexit\u00e4t je nach System enorm. Transparente Systeme im Sinne von Open Source erscheinen hierbei weitaus forschungs\u00adfreundlicher als propriet\u00e4re Systeme.</p> <p>Das Problem der Autorenkritik einer anonymen Autor*innengruppen in einem kollaborativem System konnte im gleichen Ma\u00dfe durch die Analyse der zugrunde liegenden Relationen zwischen Autor*innen und Schreibakten in Form von Artikel\u00adversionen gel\u00f6st werden. Durch die sprach\u00fcbergreifende Erhebung der Schreibakte eines Users k\u00f6nnen rudiment\u00e4re Profile auf Grundlage der benutzten Sprachversionen erstellt und der User in einem gewichteten Netzwerk aus Sprach- und Artikelversionen eingeordnet werden. Dieses Vorgehen umgeht das Problem der Anonymit\u00e4t durch die Darstellung der tats\u00e4chlichen Beteiligung am kooperativen Prozess. Durch die Visualisierung bestimmter Autor*innengruppen \u00fcber die Auswahl spezifischer Artikelabschnitte l\u00e4sst sich die Entwicklung der Autorschaft eines Artikels zu verschiedenen Zeitpunkten in dessen Chronologie bewerten. Weiterhin erlaubt der Vergleich der Autor*innengruppen verschiedener Artikel Schnittmengen zwischen diesen Gruppen bzw. deren Abwesenheit zu ermitteln. Aus diesen Untersuchungen lassen sich Schlussfolgerungen zum sich ver\u00e4ndernden Einfluss verschiedener Gruppen auf einzelne Artikel ziehen. Schlie\u00dflich konnte \u00fcber die Kleingruppen\u00adanalyse gezeigt werden, dass auch individuelle Akteure oder kleine Gruppen von Akteuren unabh\u00e4ngig von Artikelhistorien auf deren Wirken untersucht werden k\u00f6nnen. Am vorliegenden Beispiel konnte eine Beteiligung chinesischer Autor*innen am englischen Artikel der Tiananmenplatz-Proteste zu den Jahrestagen 2009, 2019 und 2020 ausgeschlossen werden. Weiterhin wurde durch die Akteursanalyse ein auff\u00e4llig hoher Anteil international agierender Autor*innen kurz vor der Sperrung der chinesischen Wikipedia innerhalb der Volksrepublik China identifiziert. Dieser zeitweilige Anstieg des internationalen Einflusses k\u00f6nnte dabei ein wichtiger Faktor f\u00fcr die Sperrung selbst gewesen sein. Diese aus der Quellenkritik hervorgegangenen Befunde w\u00e4ren in einer anschlie\u00dfenden Untersuchung des Quelleninhaltes zu \u00fcberpr\u00fcfen.</p> <p>Gleichwohl ist zu vermerken, dass die Wikipedia als beinahe idealtypischer Quellenkorpus betrachtet werden kann. Die l\u00fcckenlose Nachvollziehbarkeit der Artikelversionen, der ungehinderte Zugriff auf die zu untersuchenden Daten sowie die Offenheit der zugrunde\u00adliegenden Software bieten eine bemerkenswerte Grundlage f\u00fcr die Anwendung der hier vorgestellten Methoden. Durch die Art der Datenerhebung \u00fcber das Webinterface und die modulare Gestalt der entwickelten Software sollten die vorgestellten Ans\u00e4tze jedoch auf eine Vielzahl unterschiedlicher genuin digitaler Quellenkorpora \u00fcbertragbar sein.</p> <p>Auch Abseits der eigentlichen Autorenkritik sowie historischen Forschung k\u00f6nnten derartige Akteursanalysen hilfreiche Werkzeuge sein. So k\u00f6nnten von den vorgestellten Analysem\u00f6glichkeiten auch Methoden zur Identifikation von Manipulationsversuchen abgeleitet werden. Weiterhin ist durch die Ausweitung der Kleingruppenanalyse die Visualisierung komplexer Autor*innennetzwerke \u00fcber eine Vielzahl von Artikeln und Sprachversionen m\u00f6glich. Schlie\u00dflich k\u00f6nnten auch andere Arten der Visualisierung die Auswertung der erhobenen Datens\u00e4tze bereichern. So k\u00f6nnte die Darstellung der Sprachverteilung eines Artikels in regelm\u00e4\u00dfigen Zeitabschnitten in einem Balkendiagramm der Identifikation von \u00c4nderungen in der Zusammensetzung der Autor*innengruppe zutr\u00e4glich sein. Die gew\u00e4hlte Darstellung und Auswertung der Autor*innengruppen mittels Netzwerkanalysen ist somit nur als erster Schritt in der Analyse der erhobenen Datens\u00e4tze zu verstehen.</p> <ol> <li> <p>David Kriesel identifizierte 2013 einen Fehler in der Bildkompression der weit verbreiteten Xerox-Kopierer, die zu fehlerhaften Ziffernangaben in den digitalisierten Dokumenten f\u00fchrte. Siehe Kriesel, David: Xerox-Scankopierer ver\u00e4ndern geschriebene Zahlen, 05.09.2017, http://www.dkriesel.com/blog/2013/0802_xerox-workcentres_are_switching_written_numbers_when_scanning, Stand: 18.09.2020.\u00a0\u21a9</p> </li> </ol>"},{"location":"ReadMe.html","title":"ReadMe","text":"Dokument Beschreibung index.md Titel und Einleitung Kapitel_1.md \"Digital History und Wikipedistik - Diskurse und Fehlstellen\" Kapitel_2.md \"Ans\u00e4tze einer Digitalen Quellenkritik\" Kapitel_3.md \"Fallbeispiel: 1989 Tiananmen Square protests\" Kapitel_4.md Fazit und Ausblick Anhang_Literatur.md Anhang: Literatur Anhang_Quelltext.md Anhang: Quelltext Krug_2020_FluechtigAnonymDigital.pdf Urspr\u00fcngliche Fassung der Masterarbeit vom 20.09.2020. Abbildungen Verwendung im Text Abb 1 Titelleiste und Reiter der englischsprachigen Wikipedia Kapitel 2.1 Abb 2 Werkzeugleiste in der deutschsprachigen Wikipedia Kapitel 2.4.1 Abb 3 Ausschnitt aus der Zitierhilfe zum Artikel Mehrautorenschaft Kapitel 2.4.1 Abb 4 Urheberanteile unter einer Artikel\u00fcberschrift Kapitel 2.4.1 Abb 5 Suchmaske des Trackingtools Phabricator Kapitel 3.2 Ill 1 Fall 1a. Schnittstellenvergleich von en0 und zh0 Kapitel 3.4.1 Ill 2 Fall 1b. Sprachverteilung zwischen en0 und zh0 Kapitel 3.4.1 Ill 3 Fall 2a. Schnittstellenvergleich von zh1 und zh2 Kapitel 3.4.2 Ill 4 Fall 2b. Sprachverteilung zwischen zh1 und zh2 Kapitel 3.4.2 Ill 5 Fall 2c. Sprachverteilung zwischen zh1a und zh1b Kapitel 3.4.2 Ill 6 Fall 2d. Sprachverteilung zwischen zh2 a und zh2b Kapitel 3.4.2 Ill 7 Fall 3a. Detailansicht der Sprachverteilung von zh1 b Kapitel 3.4.3 Ill 8 Fall 3b. Detailansicht der international agierenden Autorengruppe in zh1 b Kapitel 3.4.3 Ill 9 Fall 4a. Schnittmengenvergleich von en1, en2 und en3 mit zh1 und zh2 Kapitel 3.4.4 Ill 10 Fall 4b. Sprachverteilung zwischen en1, en2 und en3 Kapitel 3.4.4"}]}