# Kapitel 1 - Digital History und Wikipedistik – Diskurse und Fehlstellen

Die Untersuchung digitaler Quellen fällt recht eindeutig in den Zuständigkeitsbereich der *Historischen Fachinformatik*, die heute häufig das Alias *Digital History* benutzt. Die vorsichtige Relativierung der Zuständigkeit ist hierbei mit Bedacht gewählt, da im Gegensatz zu den meisten anderen Fachbereichen die Digital History bis heute keine finale Definition erfahren hat. Im spärlich belegten deutschen Wikipediaartikel werden ihr formale Verfahren sowie öffentliche Wirksamkeit zugeordnet, während der englische Artikel auch explizit digitale Medien erwähnt und zwischen einer öffentlichkeitswirksamen und forschungsorientierten Ausrichtung unterscheidet. [^3] Diese Definitionsschwierigkeiten lassen sich jedoch auch auf die übergeordneten Digital Humanities übertragen, von denen ebenfalls unklar ist, ob diese eine Quellenart, einen Methodenkanon oder gar ein eigenes Fach bezeichnen. [^4] Das vorliegende Kapitel widmet sich daher der Diskussion der Digital History selbst in zwei Schritten. Zunächst wird die Funktion des Fachbereichs innerhalb der Geschichtswissenschaft anhand des 18. Historischen Forums betrachtet und anschließend der Forschungszweig der Wikipedistik vorgestellt und diskutiert.

## 1.1 Historische Grundwissenschaften und die digitale Herausforderung

Das Historische Forum mit dem Untertitel *Historische Grundwissenschaften und die digitale Herausforderung* tagte von November 2015 bis Januar 2016 und folgte der Fragestellung, welche Kompetenzen zu einer geschichtswissenschaftlichen Ausbildung im 21. Jahrhundert gehöre und welche Rolle die Digital History dabei spiele. [^5] Angesichts seit Jahren schwindender grundwissenschaftlicher Lehrangebote war hierbei die mögliche Eigenständigkeit der Digital History und ihr Potential zur Wiederbelebung der Hilfswissenschaften neben der Digitalisierung der Quellen das zentrale Thema. Weiterhin illustriert es die Findungsphase, in der sich die Digital History nach wie vor befindet.
So vergleicht Rehbein die Digital History mit der Paläographie, da beide uns erst den Zugriff auf die jeweiligen Quellen ermöglichten und fordert, dass eine basale technische Kompetenz bereits zu Beginn des Studiums gelehrt werden solle. [^6] Ganz ähnlich sieht es Krajewski, der diesen ‚letzten Neuzugang historischer Grundwissenschaften‘ insbesondere auch als Schnittstelle zu anderen Wissenschaften versteht. [^7] Hiltmann argumentiert hingegen, dass man der Digitalisierung der Quellenbestände mit der Digitalisierung der Hilfswissenschaften begegnen sollte. Hierbei würde die Vermittlung grundlegender digitaler Kompetenzen die notwendige grundwissenschaftliche Ausbildung ergänzen. [^8] Ähnlich sieht es auch Keupp, der fordert, dass die Digital History „auf die breiten Schultern aller historischen Teildisziplinen gelegt und aus den Fragestellungen möglichst aller Fachkolleg/innen gespeist werden [müsse].“ [^9]
Jedoch erscheint die Digital History, in Anbetracht der Vielzahl an unterschiedlichen Aufgaben, Schwerpunkten und Ausprägungen, die ihr zugewiesen werden, hier als eine Art Projektionsfläche. So schließt Schmale seinen Beitrag zum Forum mit der Einschätzung, dass die Debatte vorrangig als Hebel diene, um vernachlässigte Fragen an das Selbstverständnis des Faches zu stellen. [^10] Einig sind sich die am Forum Beteiligten jedenfalls, dass die Digital History, in welcher Gestalt auch immer, eine Zukunft haben wird und haben muss. Gleichwohl gibt es diesbezüglich durchaus auch ablehnende Haltungen. So schreibt Hafner fern des Historischen Forums in der NZZ im Mai 2016:

> Die Digitalisierung der Geschichte, wie die Digital History sie propagiert und praktiziert, führt zu ihrer Trivialisierung. Die Revolution ist eine Regression. [...] Gegen die Vergänglichkeit fährt die Digital History ihren zeitblinden, unsensiblen Szientismus auf. [^11]

Hafner ignoriert hierbei jedoch, ebenso wie viele Teilnehmende des Historischen Forums, vollständig die Existenz und zeitgeschichtliche Relevanz der genuin digitalen Quellen. Während die Geschichtswissenschaft nach wie vor über die Digitalisierung diskutiert, ist diese in vielen anderen Bereichen, in Forschung, Wirtschaft und Politik, seit Jahren gelebte Praxis. Folglich werden viele der heute erzeugten, zukünftigen historischen Quellen niemals dem Prozess der Retrodigitalisierung unterworfen werden – denn sie sind ihrem Wesen nach digital. Die von Schmale geforderte grundwissenschaftliche Begleitung dieser genuin digitalen Quellen verlangt dementsprechend größere Aufmerksamkeit und ist daher das Kernthema der vorliegenden Arbeit. Eine sehr aktive Umgebung und entsprechend wichtiges Beispiel für die Arbeit mit genuin digitalen Quellen ist der Fachbereich der *Wikipedistik*, also die wissenschaftliche Auseinandersetzung mit der Wikipedia.

## 1.2 Wikipedistik und genuin digitale Korpora

Sie ist ein exzellentes Beispiel für einen Wissensraum im Big Data und für ein offenes, leicht zugängliches Informationsnetz. Sie verhält sich heute schon so, wie es für alle Informationsressourcen der Geschichtswissenschaften wünschenswert wäre. [^13]

So euphorisch beschreiben Sahle und Henny diesen Vertreter einer neuen Quellengattung und zählen anschließend dessen Qualitäten detailliert auf: So bestehe sie aus offenen und frei nachnutzbaren sowie gleichmäßig strukturierten Inhalten, deren Lizenzstatus geregelt sei und deren Datenobjekte, die eigentlichen Artikel, mit klaren Adressen dauerhaft angesprochen und ausgewertet werden könnten. [^14]

Es erstaunt somit kaum, dass sich um die Wikipedia und die ihr verwandten Projekte eine Subkultur der Forschung etabliert hat, die Wikipedistik. Unter diesem relativ unscharfen Begriff werden wissenschaftliche Untersuchungen verschiedenster Art und Weise subsumiert, die sich in irgendeiner Art und Weise mit der Wikipedia beschäftigen. Den frühen Fragen nach der Belastbarkeit der Wikipedia als alltägliches Nachschlagewerk folgten kurze Zeit später Untersuchungen aus verschiedensten Fachbereichen. Eine Folge der guten Zugänglichen und des hohen Interesses ist die daraus resultierende Masse und Breite der mittlerweile verfügbaren Untersuchungen. Um die bereits durchgeführte Forschung im Ansatz erfassen und sortieren zu können, benötigen wir zunächst eine basale Systematik. Auf Basis der umfassenden Bibliografie zum Sammelband Wikipedia und Geschichtswissenschaft schlägt Wozniak hierzu eine feingliedrige Einteilung der Wikipediaforschung vor und baut dabei auf der Einteilung durch Haber und Hodel von 2008 auf. [^15] Wozniaks Aufstellung umfasst zwölf Kategorien und beinhaltet die Themen: Literatur zur chronologischen Entwicklung der Wikipedia, Enzyklopädistik, kollaborative Schreibprozesse, Biases, Rezeption und Zitierfähigkeit, Erfahrungsberichte aus Lehre, Politik und Forschung, Untersuchungen zu Autorschaft, Motivation und Genderproblemen, Analysetools, Unterschiede zwischen Sprachversionen sowie weitere, nicht klar zuzuordnende Analysen. [^16] Diese inhaltlich fokussierte Einteilung gewährt zwar einen unmittelbaren Überblick über die verschiedenen Forschungsinteressen, gleichwohl ist die Einsortierung einzelner Untersuchungen in dieses spezifische Raster determinierend. Komplexere Untersuchungen werden hier möglicherweise auf einen Teilaspekt beschränkt.

Die Wikipedia-Community selbst hat sich ebenfalls mit der Wikipedistik auseinandergesetzt. Sowohl die User als auch die Wikimedia Foundation zeichnen sich durch eine positive Grundhaltung zur Erforschung der Wikipedia sowie damit verknüpfter Projekte aus. So existiert neben eher bibliografisch ausgerichteten Seiten, die eine primär sammelnde Funktion erfüllen, [^17] auch ein eigenes Portal für Forschungsvorhaben mit Bezug zur Wikipedia. [^18] Projekte erhalten auf Antrag eine eigene Seite zur Dokumentation des Forschungsprozesses und werden chronologisch in einem offiziellen Verzeichnis geführt.

> This is the canonical directory of Wikimedia research projects that are planned, underway or have recently been completed. This list includes projects run or hosted by the Wikimedia Foundation as well as projects run by the research and editor community. [^19] [sic]

Diese Listen und Verzeichnisse sind dabei üblicherweise nur chronologisch, nicht aber gemäß wissenschaftlicher Tradition oder Methodik unterteilt. Einzig eine basale Gruppierung nach dem Verhältnis zum Untersuchungsgegenstand hat sich etabliert: Die Forschung zur Wikipedia [^20] sowie die Forschung mit Hilfe der Wikipedia. [^21] Auf diese Einteilung einigten sich auch die User Ghilt und Christianvater in einer kurzen Kommentarserie vom 26. und 27. Februar 2019 auf der deutschen Projektseite Wikipedistik/Arbeiten. [^22] Fortan sollte die Bibliografie je Jahr in Arbeiten über Wikipedia sowie Arbeiten unter Verwendung der Wikipedia aufgeteilt werden, jedoch wurde diese Trennung zumindest dort noch nicht implementiert. [^23] Dieser Ansatz, die Untersuchungen gemäß ihres Forschungsgegenstandes zu unterteilen, erscheint sowohl pragmatisch als auch hilfreich in der Bewertung von Arbeiten für die vorliegende Untersuchung und wird dementsprechend vom Autor übernommen.

Auf die Kategorisierung von Wozniak übertragen, wären die Themenfelder Literatur zur chronologischen Entwicklung der Wikipedia, Enzyklopädistik, kollaborativen Schreibprozessen, Biases, Rezeption und Zitierfähigkeit sowie Erfahrungsberichten aus Lehre, Politik und Forschung der ersten Kategorie zuzurechnen. Ihr können etwa drei Viertel der untersuchten Bibliografie zugerechnet werden. Mit der Wikipedia als zentralen Untersuchungsgegenstand beschäftigen sich diese Untersuchungen insbesondere mit den soziokulturellen Auswirkungen der freien Enzyklopädie, ihrer Rolle in Digitalisierung des Alltags und den in Folge dessen auftretenden urheberrechtlichen Herausforderungen. Die zweite Kategorie umfasst dagegen Untersuchungen zu Autorschaft, Motivation, Genderproblemen, Analysetools, Unterschieden zwischen Sprachversionen sowie nicht klar zuzuordnende Analysen. [^24] Im Fokus der Analysen stehen hier die eigentlichen Inhalte der Artikel (insbesondere bei komparativen Untersuchungen von Sprachversionen) oder aber die Autoren und deren Dynamiken. Die klare Mehrheit der vorgestellten Forschung beschäftigt sich also mit dem Phänomen Wikipedia als solches, während Untersuchungen, die die Wikipedia als Quelle verwenden aktuell vergleichsweise selten sind.

Dies deckt sich in etwa mit den verschiedenen Bibliografien der Forschungsseiten der Wikipedia. [^25] Für die Digital History ist dies jedoch eine ernüchternde Feststellung, da somit viel von dem Potential, das Sahle und Henny im eingangs angeführten Zitat erkannten, noch nicht ausgeschöpft wurde. Um diesen vielversprechenden Bereich zu illustrieren, werden im Folgenden einige Arbeiten vorgestellt, die als Beispiele und Inspirationen für künftige historiographische Untersuchungen mit Hilfe der Wikipedia sowie anderer, genuin digitaler Quellen gelten können.

### 1.2.1 Technische Zugänge

Die erste Hürde zur Nutzung der Wikipedia in einem digital historischen Kontext ist der Zugriff auf die Daten selbst. Zwar können praktisch alle Inhalte der Enzyklopädie ohne große Vorbereitung mittels eines gebräuchlichen Browsers eingesehen werden, jedoch eröffnet erst der automatisierte Abruf und die folgende Weiterverarbeitung von Informationen den Zugang zu allen Eigenheiten dieser Quellengattung.

Ein solcher Zugang ist Verarbeitung der HTML-Seiten analog zu XML-Dokumenten, wodurch ein einfacher Zugriff auf die Strukturen der Seiten möglich wird. Einen derartigen pragmatischen Ansatz verfolgen Sahle und Henny in ihrem 2015 erschienen Aufsatz und erkunden dabei die Wikipedia als Quellenkorpus. [^26] Sie diskutieren die Eignung einzelner Bestandteile von Wikipeda-Artikeln für die Forschung. Der Artikeltext selbst eigne sich beispielsweise für computerlinguistische und -philologische Analysen, insbesondere auch wegen der guten Verfügbarkeit sowie des umfangreichen Korpus. Die Gliederung der Artikel durch Überschriften, die zum Beispiel über das HTML der Seite eindeutig identifiziert werden könnten, erlauben eine spezialisierte Suche in verschiedenen Artikeln. Bilder und Links wiederum sind leicht zu identifizierende Merkmale, die auch ohne eine Auswertung des eigentlichen Texts Informationen zum Artikel preisgeben können. [^27] Zudem ermöglichen sie die Analyse der Verknüpfung von Artikeln. Die links zu anderssprachigen Artikelversionen ermöglichen darüber hinaus eine sprachübergreifende Analyse von Artikeln. Die Zuordnung zu Kategorien erweitert die Auswertungsmöglichkeiten zusätzlich. Da die Verschlagwortung durch Kategorien idealerweise einer Systematik folgt, können somit weitere Metadaten zum Artikel ermittelt werden. Letztlich betonen Sahle und Henny die Nützlichkeit der weit verbreiteten Infoboxen. Diese besonders formalisierten Übersichtsdarstellungen, üblicherweise am Rand eines Artikels positioniert, können mittels einer entsprechend angepassten Auswertungsmethodik ähnlich einer Datenbank benutzt werden. [^28]

Den Zugriff via HTML und X-Technologien begründen sie sowohl pragmatisch, als auch quellenkundlich. So wäre ein Zugriff auf die Daten über das API nicht nur aufwendiger, sondern würde zudem keine wirklichen Vorteile bieten. Zudem würden Forschende bei einem Abruf der Quellen über das Webinterface dieselben Schnittstellen nutzen, wie sie von den Usern im Alltag genutzt werden. Gleichwohl behandeln Sahle und Henny die Wikipedia in ihrem Beispielen zunächst eher als eine simple Faktenquelle, denn als ein historisches Objekt. So zeigen Sie auf, wie aus den oben genannten Infoboxen mit relativ simplen Mitteln standardisierte Informationen abgerufen werden können. Die Autoren führen das am Beispiel von Zugängen und Verlusten deutscher U-Boote im Zweiten Weltkrieg vor. [^29]

In einem zweiten Teil erweitern Sie diesen Ansatz um die Analyse des Diskursraums Wikipedia. Hierzu werten Sie die Beziehung zwischen 28.589 Artikeln zum Schlagwort Historiker aus, indem sie die Verknüpfungen durch Kategorisierungen visualisieren. Folgend diskutieren Sie die Praxis der Kategorisierung, führen weitere Analysen mit den Daten durch und schließen mit der Darstellung eines Historiker-Erwähnungsnetzwerkes, ausgehend von Theodor Mommsen. [^30]

Die aufgezeigten Beispiele sind eine hilfreiche Einführung in verschiedene Ansätze der Datenerhebung und Auswertung, sowie die Nützlichkeit der Wikipedia als Sekundärquelle. Die erhobenen Informationen sind dabei jedoch nicht charakteristisch für die Wikipedia, denn diese wurden dort nur strukturiert zusammengeführt. Insbesondere das Auslesen der Infoboxen wäre durch einen direkten Zugriff auf die zugrundeliegenden Wikidata-Objekte eleganter zu lösen. Durch eine leichte Verschiebung des Fokus lassen sich aber die vorgestellten Ansätze weiter entwickeln und für eine Fragestellung verwenden, bei welcher der Datensatz in der Wikipedia die eigentliche Quelle wäre. Der Aufsatz zeichnet sich durch einen fast schon handbuchartigen Charakter aus und kann als Anleitung und Inspiration zur technischen Auswertung der Wikipedia verstanden werden. Die Autoren verstehen die vorgeführten Analysen zudem als Vorlage für folgende Untersuchungen und fordern im Fazit, dass die vorgestellten Ansätze nicht nur genutzt, sondern stattdessen weiterentwickelt und anderen Forschenden zur Verfügung gestellt werden sollen. [^31]

### 1.2.2 Schwerpunkt: Sprachversionen

Ein vielversprechender Ansatz für mögliche Herangehensweisen sind die Sprachversionen der Wikipedia. Das Nebeneinander von kooperativ verfassten Texten aus unterschiedlichen Sprachräumen zu übereinstimmenden Themen verspricht enormes Potential für die geschichtswissenschaftliche Forschung. [^32] Nach Wozniak waren 2015 derartige Untersuchungen mit mageren drei Prozent noch selten vertreten, jedoch betont er auch, dass sich dort zukünftig ein bemerkenswertes Forschungspotential fände. [^33]

So bewiesen zum Beispiel Hecht und Gergle bereits 2010, dass verschiedene *global consensus hypotheses* als nicht haltbar betrachtet werden müssten. Laut diesen führe die internationale Zusammenarbeit unter dem Diktat eines *Neutral Point of Views* zwangsläufig dazu, dass sich eine international einheitliche Auffassung zu einzelnen Themen herausbilden würde. Ein globaler Konsens. Um diese Hypothese zu prüfen, untersuchten sie 25 verschiedene Sprachversionen der Wikipedia auf Unterschiede in ihren Wissenskonzepten und der Präsentation derselben. Dabei kamen sie jedoch zum Schluss, dass zwischen den einzelnen Sprachversionen eine signifikante Wissensdiversität herrsche. Sie fordern daraus folgend einen kulturbewussten Umgang mit dieser Ressource und bekräftigen hyperlinguale Anwendungen. [^34]

Diese Diversität aufgreifend, untersuchte Richter 2015 die unterschiedlichen Darstellungen der Stadt Vilnius/Wilno in der polnischen und litauischen Wikipedia. Die Texte beider Versionen wichen dabei kaum von ihren jeweilig prägenden hegemonialen und ethnozentrischen Narrativen ab. Richtet mutmaßt, dass der Editionsprozess möglicherweise zu Territorialisierungsprozessen beitragen könne. Er betont den Wert derartiger Untersuchungen für die Nationalismusforschung, da die Quellen hier, trotz eines hohen Grades an information asymmetry, standardisiert vorlägen. Weiterhin verweist er auf die Diskussionsseiten als mögliche Quellen, die auch abweichende Narrationen aufwiesen und damit von besonderem Interesse für die Forschung sein könnten. [^35]

Ähnlich verfahren Kleinke und Schulz bei ihrer Untersuchung, jedoch betrachten diese im Rahmen einer qualitativen Mikroanalyse die Konstruktion des Konzepts Nation in der englischen sowie deutschen Wikipedia. Sie verglichen die Artikel dabei auf Grundlage manueller Analysen der kulturvergleichenden Wikipedistik sowie Kategorien der kognitiven Semantik und der kognitiven kritischen Diskursanalyse. Sie kommen zum Schluss, dass der englische Artikel nation eher sozialwissenschaftlich geprägt sei und sich insbesondere die Entwicklung von Nationen im englischen Sprachraum auf dessen Begriffsbestimmung auswirkten. Der deutsche Artikel Nation hingegen sei vorrangig von einer wissenschaftstheoretischen Auseinandersetzung geprägt. [^36]

Die vorgestellten Untersuchungen bieten einen Einblick in die Potentiale vergleichender Analysen auf Grundlage der Wikipedia Sprachversionen. Gleichwohl wirft die Identität der edierenden User hier Fragen auf. So wird die implizierte Homogenität der Usergruppen in den jeweiligen Sprachversionen unglücklicherweise weder geprüft noch thematisiert und auch auf andere Faktoren, wie zum Beispiel die Rolle von Bots im Prozess der Definitionsfindung, wird nicht weiter eingegangen.

### 1.2.3 Schwerpunkt: Akteure

Die Datenbasis der Wikipedia erlaubt es weiterhin, die Autoren der Artikel selbst ins Zentrum der Untersuchung zu stellen. So analysierte Ford 2011 die Dynamik zwischen internationalen Beiträgern und der englischsprachigen Wikipedia am Beispiel spezifisch kenyanischer Inhalte, beigetragen durch kenyanische User. Sie bemerkt, dass es zwar für kenyanische User einfacher sei, der swahilisprachigen Wikipedia beizutragen, doch sei für viele User die englischsprachige Wikipedia attraktiver, insbesondere wegen deren Reichweite und der Möglichkeit, die eigene Kultur international darzustellen. [^37]

Ausgehend vom Artikel *Kosovo and Metohija*, dem zum Zeitpunkt der Analyse einzigen Artikel zum Kosovo in serbischer Sprache, analysierten Bilic und Bulian 2014 die Benutzerinteraktion unter anderem durch die Auswertung von Diskussions- und Benutzerseiten sowie durch Interviews mit Editoren. Sie zeigen auf, dass zwischen den Sprachversionen politische sowie kulturelle Konflikte und Unterschiede nicht nur reproduziert, sondern um online Identitäten erweitert werden. Weder Konsens noch Konflikt seien folglich stabile Muster
innerhalb der Wikipedia. [^38]

Die einer möglichen Konsensbildung zugrunde liegenden Aushandlungsprozesse untersuchten Heinrich und Gilowsky 2018. Sie übertragen dabei die wissenssoziologische Struktur von kommunikativem und kulturellem Gedächtnis auf den Wikipediaartikel zur Weißen Rose. [^39] Die Autoren verorten hierzu den eigentlichen Artikeltext auf der Makroebene und definieren ihn somit als das Ergebnis eines Aushandlungsprozesses, der in Form der Diskussionsseite auf der Mesoebene stattfände. [^40] Sie kommen jedoch zum Schluss, dass die untersuchten Beiträge nur in wenigen Fällen eine direkte Auswirkung auf die Makroebene, also den Artikeltext selbst, hätten und dass nur eine Minderheit der Diskussionen die historiographische Interpretation selbst behandelten. [^41] Es ist somit anzunehmen, dass der Großteil der Aushandlungsprozesse im Artikeltext selbst stattfindet und die Diskussionsseite nur als ergänzende Quelle herangezogen werden kann, was Richters Vermutung widerlegt.

Yasseri et al. unterstützen die Annahme zentraler Unterschiede in sozialräumlichen Prioritäten, Interessen und Präferenzen in ihrer 2014er Untersuchung. Sie untersuchten dazu Unterschiede und Überschneidungen in kontroversen Themen in 12 Sprachversionen der Wikipedia. Dazu analysierten sie die Artikelhistorien und bewerteten insbesondere Reverts, also wiederhergestellte ältere Versionen eines Artikels. Hierzu generierten die Autoren zunächst MD5 Hashes der Artikeltexte und konnten somit Duplikate innerhalb einer Artikelhistorie identifizieren. Sie bestätigen dabei frühere Untersuchungen in der Feststellung, dass die Wikipedia als Werkzeug durchaus unterschiedliche Gruppen von Individuen zusammenbringt, jedoch lokale und kulturelle Charakteristiken keinesfalls ignoriert werden dürfen. [^42]

Diese exemplarischen Untersuchungen stützen die naheliegende Hypothese, dass die Zusammensetzung der Autorengruppen eine relevante Rolle im Meinungsbildungsprozess einnimmt. Für zukünftige Untersuchungen gilt es, Methoden zu etablieren, um diese Gruppen besser untersuchen und beschreiben zu können.

### 1.2.4 Digitale Werkzeuge

Neben dem Zugang zu Artikeln über deren Artikeltext oder der Autorenbeteiligung bieten die verwendeten Bilder einen dritten Zugriffsvektor. Bilder haben hierbei den Vorteil, direkt und sprachunabhängig interpretierbar und vergleichbar zu sein. Das Projekt *Wikipedia Crosslingual Image Analysis* der Digital Methods Initiative Amsterdam greift diesen Ansatz auf und ermöglicht einen direkten Vergleich verschiedener Sprachversionen eines Artikels anhand der zugehörigen Bilder. [^43] Das Tool ist online erreichbar und zeichnet sich durch ein minimalistisches Interface aus. [^44]

Einen quellenkritisch didaktischen Ansatz verfolgt dagegen die Seite Wikibu. [^45] Wikibu erweitert das Layout der Wikipedia um eine Seitenleiste, in der anhand von Kennzahlen die Vertrauenswürdigkeit des vorliegenden Artikels bewertet wird. Dieser Ansatz dient zwar vorrangig der Sensibilisierung von Schülern im Umgang mit der Wikipedia, illustriert dabei jedoch die Möglichkeiten einer unterstützenden automatischen Datenauswertung. [^46]

Mit den XTools steht Forschenden schließlich eine ganze Reihe an hilfreichen Statistikauswertungen zur Verfügung, die analog zur Wikipedia selbst von Freiwilligen erstellt und gepflegt werden. [^47] Eines des gebräuchlichsten Tools der Sammlung ist dabei sicherlich die Page History, die eine Vielzahl an statistischen Informationen zu einem Artikel anzeigt und zudem über einen Direktlinkt aus der englischen Artikelhistorie aufrufbar ist. [^48]

Der Nutzen der einzelnen Werkzeuge ist je nach Forschungsabsicht natürlich sehr unterschiedlich zu bewerten, jedoch erleichtern sie üblicherweise einen ersten Einblick in die komplexeren Zusammenhänge der Daten. Individuelle Anpassungen oder Eigenentwicklungen sind jedoch naheliegend, wohingegen ein grundlegend methodenkritischer Umgang mit solchen Tools zwingend erforderlich ist.

---

[^3]: Siehe Historische Fachinformatik, in: Wikipedia, 05.09.2018. Online: <https://de.wikipedia.org/w/index.php?title=Historische_Fachinformatik&oldid=180649364>; sowie Digital history, in: Wikipedia, 27.04.2020. Online:<https://en.wikipedia.org/w/index.php?title=Digital_history&oldid=953529232>. Beiden Artikeln mangelt eszudem an Belegen und Aktivität. Der englische Artikel wurde seit 2008 kaum 350 Änderungen unterzogen,während der bereits 2003 angelegte deutsche Artikel auf nicht einmal 50 Änderungen kommt. Siehe Digital history - Page History - XTools, <https://xtools.wmflabs.org/articleinfo/en.wikipedia.org/Digital_history>, Stand: 06.08.2020; sowie Historische Fachinformatik - Page History - XTools, <https://xtools.wmflabs.org/articleinfo/de.wikipedia.org/Historische_Fachinformatik>, Stand: 06.08.2020.
[^4]: Vgl. Dogunke, Swantje: Was heißt »Digital Humanities«?, Blog | Klassik Stiftung Weimar, 17.06.2015, <https://blog.klassik-stiftung.de/digital-humanities/>, Stand: 06.08.2020.
[^5]: Vgl. Prinz, Claudia; Schlotheuber, Eva; Hohls, Rüdiger: Vorwort der Redaktion, in: Historische Grundwissenschaften und die digitale Herausforderung, Bd. 18, 2016 (Historisches Forum), S. 4 f.
[^6]: Vgl. Rehbein, Malte: Digitalisierung braucht Historiker/innen, die sie beherrschen, nicht beherrscht, in: Historische Grundwissenschaften und die digitale Herausforderung, Bd. 18, 2016 (Historisches Forum), S. 45–51.
[^7]: Vgl. Krajewski, Markus: Programmieren als Kulturtechnik, in: Historische Grundwissenschaften und die digitale Herausforderung, Bd. 18, 2016 (Historisches Forum), S. 37–40.
[^8]: Vgl. Hiltmann, Torsten: Hilfswissenschaften in Zeiten der Digitalisierung, in: Historische Grundwissenschaften und die digitale Herausforderung, Bd. 18, 2016 (Historisches Forum), S. 79–83.
[^9]: Keupp, Jan: Die digitale Herausforderung: Kein Reservat der Hilfswissenschaften, in: Historische Grundwissenschaften und die digitale Herausforderung, Bd. 18, 2016 (Historisches Forum), S. 89–92.
[^10]: Vgl. Schmale, Wolfgang: Historische Grundwissenschaften international, in: Historische Grundwissenschaften und die digitale Herausforderung, Bd. 18, 2016 (Historisches Forum), S. 23–25.
[^11]: Hafner, Urs: Der Irrtum der Zeitmaschinisten | NZZ, Neue Zürcher Zeitung, 27.05.2016, <https://www.nzz.ch/feuilleton/zeitgeschehen/digital-history-historiografie-des-zeitpfeils-ld.85000>, Stand: 13.06.2020.
[^12]: Vgl. Schmale: Historische Grundwissenschaften international, 2016, S. 25.
[^13]: Sahle, Patrick; Henny, Ulrike: Klios Algorithmen: Automatisierte Auswertung von Wikipedia-Inhalten als Faktenbasis und Diskursraum, in: Wozniak, Thomas; Nemitz, Jürgen; Rohwedder, Uwe (Hg.): Wikipedia und Geschichtswissenschaft, Berlin/Boston 2015, S. 120.
[^14]: Vgl. ebd.
[^15]: Siehe Wozniak, Thomas; Nemitz, Jürgen; Rohwedder, Uwe (Hg.): Wikipedia und Geschichtswissenschaft, Berlin/Boston 2015, S. 257–299. Online: <https://doi.org/10.1515/9783110376357>.
[^16]: Vgl. Wozniak, Thomas: Wikipedia in Forschung und Lehre – eine Übersicht, in: Wozniak, Thomas; Nemitz, Jürgen; Rohwedder, Uwe (Hg.): Wikipedia und Geschichtswissenschaft, Berlin/Boston 2015, S. 41 f.
[^17]: So zum Beispiel die Bibliografie des deutschen Wikipedistik-Projekts, siehe Wikipedia:Wikipedistik/Arbeiten, in: Wikipedia, 19.06.2020. Online: <https://de.wikipedia.org/w/index.php?title=Wikipedia:Wikipedistik/Arbeiten&oldid=201125088>.
[^18]: Siehe Research:Index - Meta, <https://meta.wikimedia.org/wiki/Research:Index>, Stand: 06.07.2020.
[^19]: Research:Projects - Meta, <https://meta.wikimedia.org/w/index.php?title=Research:Projects&oldid=19872838>, Stand: 05.07.2020.
[^20]: Siehe zum Beispiel Wikipedia:Academic studies of Wikipedia, in: Wikipedia, 03.07.2020. Online: <https://en.wikipedia.org/w/index.php?title=Wikipedia:Academic_studies_of_Wikipedia&oldid=965824064>.
[^21]: Siehe zum Beispiel Wikipedia:Wikipedia as an academic source, in: Wikipedia, 28.11.2018. Online:<https://en.wikipedia.org/w/index.php?title=Wikipedia:Wikipedia_as_an_academic_source&oldid=871051852>.
[^22]: Siehe Wikipedia:Wikipedistik/Arbeiten, in: Wikipedia, 19.06.2020. Online: <https://de.wikipedia.org/w/index.php?title=Wikipedia:Wikipedistik/Arbeiten&oldid=201125088>.
[^23]: Siehe Wikipedia Diskussion:Wikipedistik/Arbeiten, in: Wikipedia, 27.02.2019. Online: <https://de.wikipedia.org/w/index.php?title=Wikipedia_Diskussion:Wikipedistik/Arbeiten&oldid=186086510>.
[^24]: Vgl. Wozniak: Wikipedia in Forschung und Lehre – eine Übersicht, 2015, S. 41 f.
[^25]: Siehe auch Fußnoten [^20] und [^21].
[^26]: Vgl. Sahle; Henny: Klios Algorithmen: Automatisierte Auswertung von Wikipedia-Inhalten als Faktenbasis und Diskursraum, 2015.
[^27]: Beispielsweise lassen sich durch widerstreitende Löschungen und Einfügungen Rückschlüsse auf einem Artikel zu Grunde liegenden Diskurs ziehen. Diese Methode funktioniert dank der sprachunabhängigen Aussagekraft von Bildern selbst in fremdsprachigen Korpora. Vgl. Krug, Stefan: Zensur in Bildern. Verlauf der Zensur der chinesischen Wikipedia in den 2010er Jahren in Bildern, in, 28.02.2020. Online:<https://github.com/krugbuild/zensur-in-bildern>, Stand: 15.03.2020.
[^28]: Vgl. Sahle; Henny: Klios Algorithmen: Automatisierte Auswertung von Wikipedia-Inhalten als Faktenbasis und Diskursraum, 2015, S. 116 f.
[^29]: Vgl. ebd., S. 122–136.
[^30]: Vgl. ebd., S. 136–145.
[^31]: Vgl. ebd., S. 148.
[^32]: Die technischen Details der Strukturen Sprachversion und Artikel werden im Kapitel [2.1 Zur Struktur des digitalen Objekts Artikel]() erläutert. <!-- TODO -->
[^33]: Vgl. Wozniak: Wikipedia in Forschung und Lehre – eine Übersicht, 2015, S. 42.
[^34]: Vgl. Hecht, Brent; Gergle, Darren: The tower of Babel meets web 2.0: user-generated content and its applications in a multilingual context, in: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, Atlanta, Georgia 2010, S. 291–300. Online: <https://doi.org/10.1145/1753326.1753370>.
[^35]: Vgl. Richter, Klaus: Wikipedia als Objekt der Nationalismusforschung – das Beispiel der Stadt Vilnius/Wilno, in: Wozniak, Thomas; Nemitz, Jürgen; Rohwedder, Uwe (Hg.): Wikipedia und Geschichtswissenschaft, Berlin/Boston 2015, S. 149–154.
[^36]: Vgl. Kleinke, Sonja; Schultz, Julia: Ist „Nation“ gleich „nation“? Zwei Wikipedia-Artikel im Sprach- und Kulturvergleich, in: Diskurse – digital 1 (1), 19.02.2019, S. 62–97. Online: <https://doi.org/10.25521/diskurse-digital.2019.61>.
[^37]: Vgl. Ford, Heather: The Missing Wikipedians, in: Lovink, Geert; Tkacz, Nathaniel (Hg.): Critical Point of View: A Wikipedia Reader, Amsterdam 2011, S. 258–268. Online: <https://networkcultures.org/blog/publication/critical-point-of-view-a-wikipedia-reader/>.
[^38]: Vgl. Bilic, Pasko; Bulian, Luka: Lost in Translation: Contexts, Computing, Disputing on Wikipedia, in, Berlin 2014. Online: <https://doi.org/10.9776/14027>.
[^39]: Das Modell besagt, dass Wissen und Erinnern sozial bedingt seien und geteilte Interpretationen der Vergangenheit durch kommunikative Prozesse erreicht werden. Darin wird zwischen der Mirkoebene (persönliche Erfahrungen), der Mesoebene (Kommunikation) und der Makroebene (kulturelles Gedächtnis) unterschieden.<br/>Vgl. Heinrich, Horst-Alfred; Gilowsky, Julia: Wie wird kommunikatives zu kulturellem Gedächtnis? Aushandlungsprozesse auf den Wikipedia-Diskussionsseiten am Beispiel der Weißen Rose, in: Sebald, Gerd; Döbler, Marie-Kristin (Hg.): (Digitale) Medien und soziale Gedächtnisse, Wiesbaden 2018 (Soziales Gedächtnis, Erinnern und Vergessen – Memory Studies), S. 146 f. Online: <https://doi.org/10.1007/978-3-658-19513-7>.
[^40]: Vgl. ebd., S. 145.
[^41]: Vgl. ebd., S. 163 f.
[^42]: Vgl. Yasseri, Taha; Speorri, Anselm; Graham, Mark u. a.: The Most Controversial Topics in Wikipedia. A Multilingual and Geographical Aalysis, in: Global Wikipedia: International and Cross-Cultural Issues in Online Collaboration, Lanham 2014, S. 25–48. Online: <http://arxiv.org/abs/1305.5566>.
[^43]: Vgl. Gredel, Eva: Digitale Diskurse und Wikipedia. Wie das Social Web Interaktion im digitalen Zeitalter verwandelt, Tübingen 2018, S. 77 f.
[^44]: Siehe Wikipedia Cross-lingual Image Analysis, DMI Tools, <https://tools.digitalmethods.net/beta/wikipediaCrosslingualImageAnalysis/>.
[^45]: Siehe Wikibu, <https://www.wikibu.ch/index.php>.
[^46]: Vgl. Gredel: Digitale Diskurse und Wikipedia. Wie das Social Web Interaktion im digitalen Zeitalter verwandelt, 2018, S. 83–85.
[^47]: Siehe XTools, <https://xtools.wmflabs.org/> ; sowie Welcome to XTools! — XTools 3.10.16 documentation, <https://xtools.readthedocs.io/en/stable/>.
[^48]: Siehe Page History - XTools, <https://xtools.wmflabs.org/articleinfo> ; sowie 1.2. Page History — XTools 3.10.16 documentation, <https://xtools.readthedocs.io/en/stable/tools/articleinfo.html#articleinfo>.